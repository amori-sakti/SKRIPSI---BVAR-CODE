{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd743abd-b0c5-4184-970c-f3fea7ce3c1b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Platinum Price Forecasting: BVAR Analysis ===\n",
      "\n",
      "1. Preparing data...\n",
      "Data prepared: 33 training observations, 5 test observations\n",
      "VAR variables: ['Price_Growth', 'GDP_Growth_Rate', 'Industrial_Growth']\n",
      "BVAR data prepared: 30 observations, 3 variables\n",
      "Number of parameters per equation: 7\n",
      "\n",
      "2. Training BVAR model...\n",
      "Building and training BVAR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 434 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVAR model training completed!\n",
      "\n",
      "3. Generating forecasts...\n",
      "Generating BVAR forecasts for 40 years...\n",
      "BVAR forecast generation completed!\n",
      "\n",
      "4. Exporting forecast results...\n",
      "\n",
      "Forecast results saved to: platinum_price_forecast.csv\n",
      "\n",
      "=== PLATINUM PRICE FORECAST CSV CONTENT ===\n",
      " Year  Platinum_Price_USD_oz\n",
      " 2021                 796.57\n",
      " 2022                 898.94\n",
      " 2023                 918.84\n",
      " 2024                 930.25\n",
      " 2025                 931.79\n",
      " 2026                 930.61\n",
      " 2027                 937.49\n",
      " 2028                 935.80\n",
      " 2029                 935.04\n",
      " 2030                 938.40\n",
      " 2031                 939.67\n",
      " 2032                 939.47\n",
      " 2033                 946.09\n",
      " 2034                 948.56\n",
      " 2035                 955.59\n",
      " 2036                 966.81\n",
      " 2037                 974.99\n",
      " 2038                 975.27\n",
      " 2039                 976.19\n",
      " 2040                 974.27\n",
      " 2041                 978.43\n",
      " 2042                 974.44\n",
      " 2043                 985.31\n",
      " 2044                 993.03\n",
      " 2045                 999.85\n",
      " 2046                 999.81\n",
      " 2047                1004.44\n",
      " 2048                1011.81\n",
      " 2049                1014.91\n",
      " 2050                1018.62\n",
      " 2051                1029.95\n",
      " 2052                1030.98\n",
      " 2053                1033.26\n",
      " 2054                1034.90\n",
      " 2055                1033.19\n",
      " 2056                1036.00\n",
      " 2057                1044.21\n",
      " 2058                1051.13\n",
      " 2059                1056.39\n",
      " 2060                1061.14\n",
      "\n",
      "Detailed forecast results saved to: platinum_detailed_forecast.csv\n",
      "\n",
      "=== FORECAST SUMMARY ===\n",
      "Forecast period: 2021-2060\n",
      "Average forecasted price (2026-2060): $990.46\n",
      "Price range (2026-2060): $930.61 - $1,061.14\n",
      "\n",
      "=== KEY FORECAST YEARS ===\n",
      "Year    Price    Lower_CI  Upper_CI\n",
      "-----------------------------------\n",
      "2025    $931.79   $159.80   $5549.74\n",
      "2030    $938.40   $ 35.09   $26506.32\n",
      "2035    $955.59   $  7.97   $120580.84\n",
      "2040    $974.27   $  1.74   $569582.30\n",
      "2045    $999.85   $  0.39   $2692038.39\n",
      "2050    $1018.62   $  0.09   $13058745.96\n",
      "2055    $1033.19   $  0.02   $61709296.47\n",
      "2060    $1061.14   $  0.00   $292673313.33\n",
      "\n",
      "==================================================\n",
      "ANALYSIS COMPLETE!\n",
      "Files generated:\n",
      "1. platinum_price_forecast.csv (simple format)\n",
      "2. platinum_detailed_forecast.csv (with confidence intervals)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PlatinumBVARForecast:\n",
    "    def __init__(self, base_year=2017, lags=2):\n",
    "        self.base_year = base_year\n",
    "        self.lags = lags\n",
    "        self.model = None\n",
    "        self.idata = None\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.forecast_df = None\n",
    "        self.var_names = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare platinum price and economic indicator data\"\"\"\n",
    "        # Platinum price data with economic indicators\n",
    "        data = [\n",
    "            [1988, 523, 59.5, 4.6, 85.2], [1989, 507, 62.3, 3.7, 87.1],\n",
    "            [1990, 466, 65.6, 2.9, 88.3], [1991, 372, 68.4, 1.4, 86.9],\n",
    "            [1992, 357, 70.5, 2.2, 88.7], [1993, 373, 72.3, 2.6, 90.1],\n",
    "            [1994, 405, 74.8, 3.0, 92.4], [1995, 425, 76.8, 2.7, 94.2],\n",
    "            [1996, 397, 79.0, 3.4, 95.8], [1997, 394, 80.8, 3.8, 97.1],\n",
    "            [1998, 372, 81.5, 2.7, 95.3], [1999, 377, 83.4, 3.4, 96.8],\n",
    "            [2000, 544, 86.3, 4.8, 98.2], [2001, 533, 88.1, 2.5, 97.1],\n",
    "            [2002, 540, 89.6, 3.1, 98.9], [2003, 692, 91.8, 4.0, 101.3],\n",
    "            [2004, 844, 94.7, 4.5, 104.8], [2005, 897, 97.1, 4.3, 107.2],\n",
    "            [2006, 1142, 99.8, 4.5, 110.1], [2007, 1304, 102.6, 4.4, 112.8],\n",
    "            [2008, 1578, 104.2, 1.9, 108.9], [2009, 1205, 104.5, -1.3, 101.2],\n",
    "            [2010, 1613, 106.7, 4.3, 106.8], [2011, 1722, 109.7, 3.1, 109.4],\n",
    "            [2012, 1552, 111.4, 2.6, 108.7], [2013, 1487, 112.8, 2.8, 107.3],\n",
    "            [2014, 1385, 114.1, 2.9, 105.9], [2015, 1054, 115.4, 3.2, 102.1],\n",
    "            [2016, 990, 117.1, 3.1, 101.8], [2017, 954, 119.3, 3.0, 100.0],\n",
    "            [2018, 879, 121.7, 2.9, 98.7], [2019, 863, 124.0, 2.8, 97.9],\n",
    "            [2020, 883, 126.3, -3.5, 95.4], [2021, 1077, 129.6, 5.6, 98.2],\n",
    "            [2022, 1016, 133.8, 3.1, 99.1], [2023, 1077, 136.9, 2.9, 100.3],\n",
    "            [2024, 960, 139.5, 2.8, 99.8], [2025, 1020, 142.1, 2.7, 100.5]\n",
    "        ]\n",
    "        \n",
    "        df = pd.DataFrame(data, columns=[\n",
    "            'Year', 'Nominal_Platinum_Price_USD_oz', 'US_CPI_2017_100', \n",
    "            'Global_GDP_Growth_pct', 'Industrial_Production_Index'\n",
    "        ]).set_index('Year')\n",
    "        \n",
    "        # Removing the CPI impact\n",
    "        df['Real_Platinum_Price'] = (df['Nominal_Platinum_Price_USD_oz'] / df['US_CPI_2017_100'] \n",
    "                                   * df.loc[self.base_year, 'US_CPI_2017_100'])\n",
    "        \n",
    "        # Log transform variables for stationarity\n",
    "        df['Log_Real_Price'] = np.log(df['Real_Platinum_Price'])\n",
    "        df['Log_Industrial_Production'] = np.log(df['Industrial_Production_Index'])\n",
    "        \n",
    "        # Create growth rates (first differences of logs)\n",
    "        df['Price_Growth'] = df['Log_Real_Price'].diff()\n",
    "        df['GDP_Growth_Rate'] = df['Global_GDP_Growth_pct']  # Already in percentage\n",
    "        df['Industrial_Growth'] = df['Log_Industrial_Production'].diff()\n",
    "        \n",
    "        # Select variables for VAR model\n",
    "        self.var_names = ['Price_Growth', 'GDP_Growth_Rate', 'Industrial_Growth']\n",
    "        \n",
    "        # Create training and test sets\n",
    "        self.train_df = df[df.index <= 2020].copy()\n",
    "        self.test_df = df[df.index > 2020].copy()\n",
    "        \n",
    "        print(f\"Data prepared: {len(self.train_df)} training observations, {len(self.test_df)} test observations\")\n",
    "        print(f\"VAR variables: {self.var_names}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_bvar_data(self):\n",
    "        \"\"\"Prepare data for BVAR estimation\"\"\"\n",
    "        if self.train_df is None:\n",
    "            raise ValueError(\"Must call prepare_data() first\")\n",
    "        \n",
    "        # Get clean data (remove NaN values)\n",
    "        var_data = self.train_df[self.var_names].dropna()\n",
    "        \n",
    "        n_obs, n_vars = var_data.shape\n",
    "        \n",
    "        # Create lagged variables\n",
    "        Y = []  # Dependent variables\n",
    "        X = []  # Lagged independent variables\n",
    "        \n",
    "        for t in range(self.lags, n_obs):\n",
    "            # Current period values (dependent variables)\n",
    "            Y.append(var_data.iloc[t].values)\n",
    "            \n",
    "            # Lagged values (independent variables) + constant\n",
    "            x_t = [1.0]  # constant term\n",
    "            for lag in range(1, self.lags + 1):\n",
    "                x_t.extend(var_data.iloc[t - lag].values)\n",
    "            X.append(x_t)\n",
    "        \n",
    "        self.Y = np.array(Y)  # Shape: (T-lags, n_vars)\n",
    "        self.X = np.array(X)  # Shape: (T-lags, 1 + n_vars*lags)\n",
    "        \n",
    "        # Store last observations for forecasting\n",
    "        self.last_obs = var_data.iloc[-self.lags:].values\n",
    "        \n",
    "        print(f\"BVAR data prepared: {self.Y.shape[0]} observations, {self.Y.shape[1]} variables\")\n",
    "        print(f\"Number of parameters per equation: {self.X.shape[1]}\")\n",
    "        \n",
    "    def build_and_train_bvar(self):\n",
    "        \"\"\"Build and train the BVAR model\"\"\"\n",
    "        if not hasattr(self, 'Y'):\n",
    "            raise ValueError(\"Must call prepare_bvar_data() first\")\n",
    "        \n",
    "        print(\"Building and training BVAR model...\")\n",
    "        \n",
    "        n_obs, n_vars = self.Y.shape\n",
    "        n_params = self.X.shape[1]\n",
    "        \n",
    "        with pm.Model() as self.model:\n",
    "            # Minnesota prior parameters\n",
    "            lambda1 = 0.1  # Overall tightness\n",
    "            lambda2 = 0.5  # Cross-variable relative to own variable\n",
    "            lambda3 = 1.0  # Higher lag relative to lower lag\n",
    "            \n",
    "            # Coefficient matrices for each equation\n",
    "            coefficients = []\n",
    "            sigma_diag = []\n",
    "            \n",
    "            for i in range(n_vars):\n",
    "                # Priors for coefficients in equation i\n",
    "                coef_prior_std = []\n",
    "                \n",
    "                # Constant term\n",
    "                coef_prior_std.append(1.0)\n",
    "                \n",
    "                # Lagged coefficients\n",
    "                for lag in range(1, self.lags + 1):\n",
    "                    for j in range(n_vars):\n",
    "                        if i == j:  # Own lag\n",
    "                            if lag == 1:\n",
    "                                std = lambda1  # First own lag\n",
    "                            else:\n",
    "                                std = lambda1 * (lambda3 ** (lag - 1))\n",
    "                        else:  # Cross-variable lag\n",
    "                            std = lambda1 * lambda2 * (lambda3 ** (lag - 1))\n",
    "                        coef_prior_std.append(std)\n",
    "                \n",
    "                # Coefficient vector for equation i\n",
    "                beta_i = pm.Normal(f'beta_{i}', mu=0, sigma=coef_prior_std, shape=n_params)\n",
    "                coefficients.append(beta_i)\n",
    "                \n",
    "                # Error variance for equation i\n",
    "                sigma_i = pm.HalfNormal(f'sigma_{i}', sigma=0.1)\n",
    "                sigma_diag.append(sigma_i)\n",
    "            \n",
    "            # Stack coefficients\n",
    "            beta_matrix = pm.math.stack(coefficients, axis=0)  # Shape: (n_vars, n_params)\n",
    "            \n",
    "            # Predictions\n",
    "            mu = pm.math.dot(self.X, beta_matrix.T)  # Shape: (n_obs, n_vars)\n",
    "            \n",
    "            # Likelihood for each variable\n",
    "            for i in range(n_vars):\n",
    "                pm.Normal(f'y_{i}', mu=mu[:, i], sigma=sigma_diag[i], \n",
    "                         observed=self.Y[:, i])\n",
    "            \n",
    "            # Sample from posterior\n",
    "            self.idata = pm.sample(1000, tune=500, chains=2, cores=1,\n",
    "                                 target_accept=0.85, random_seed=42,\n",
    "                                 progressbar=True)\n",
    "        \n",
    "        print(\"BVAR model training completed!\")\n",
    "        return self.idata\n",
    "    \n",
    "    def generate_forecasts(self, forecast_years=None):\n",
    "        \"\"\"Generate forecasts using the trained BVAR model\"\"\"\n",
    "        if forecast_years is None:\n",
    "            forecast_years = list(range(2021, 2061))\n",
    "        \n",
    "        if self.idata is None:\n",
    "            raise ValueError(\"Must train model first\")\n",
    "        \n",
    "        print(f\"Generating BVAR forecasts for {len(forecast_years)} years...\")\n",
    "        \n",
    "        # Extract posterior samples\n",
    "        posterior = self.idata.posterior\n",
    "        n_vars = len(self.var_names)\n",
    "        \n",
    "        # Initialize forecast arrays\n",
    "        forecasts = {var: [] for var in self.var_names}\n",
    "        forecast_intervals = {var: {'lower': [], 'upper': []} for var in self.var_names}\n",
    "        \n",
    "        # Current state (last observations)\n",
    "        current_state = self.last_obs.copy()\n",
    "        \n",
    "        for year_idx, year in enumerate(forecast_years):\n",
    "            # Forecast distributions for this period\n",
    "            forecast_dist = {var: [] for var in self.var_names}\n",
    "            \n",
    "            # Sample from posterior predictive\n",
    "            for chain in range(len(posterior.chain)):\n",
    "                for draw in range(len(posterior.draw)):\n",
    "                    # Get parameters for this draw\n",
    "                    coeffs = []\n",
    "                    sigmas = []\n",
    "                    for i in range(n_vars):\n",
    "                        beta_i = posterior[f'beta_{i}'].values[chain, draw]\n",
    "                        sigma_i = posterior[f'sigma_{i}'].values[chain, draw]\n",
    "                        coeffs.append(beta_i)\n",
    "                        sigmas.append(sigma_i)\n",
    "                    \n",
    "                    # Construct X vector for prediction\n",
    "                    x_pred = [1.0]  # constant\n",
    "                    for lag in range(1, self.lags + 1):\n",
    "                        if lag <= len(current_state):\n",
    "                            x_pred.extend(current_state[-lag])\n",
    "                        else:\n",
    "                            x_pred.extend(np.zeros(n_vars))\n",
    "                    \n",
    "                    x_pred = np.array(x_pred)\n",
    "                    \n",
    "                    # Predict each variable\n",
    "                    for i in range(n_vars):\n",
    "                        mu_pred = np.dot(x_pred, coeffs[i])\n",
    "                        y_pred = np.random.normal(mu_pred, sigmas[i])\n",
    "                        forecast_dist[self.var_names[i]].append(y_pred)\n",
    "            \n",
    "            # Calculate point forecasts and intervals\n",
    "            for i, var in enumerate(self.var_names):\n",
    "                point_forecast = np.median(forecast_dist[var])\n",
    "                lower_ci = np.percentile(forecast_dist[var], 2.5)\n",
    "                upper_ci = np.percentile(forecast_dist[var], 97.5)\n",
    "                \n",
    "                forecasts[var].append(point_forecast)\n",
    "                forecast_intervals[var]['lower'].append(lower_ci)\n",
    "                forecast_intervals[var]['upper'].append(upper_ci)\n",
    "            \n",
    "            # Update current state for next period\n",
    "            new_obs = np.array([forecasts[var][-1] for var in self.var_names])\n",
    "            current_state = np.vstack([current_state, new_obs])\n",
    "            if len(current_state) > self.lags:\n",
    "                current_state = current_state[-self.lags:]\n",
    "        \n",
    "        # Convert price growth back to price levels\n",
    "        last_log_price = self.train_df['Log_Real_Price'].iloc[-1]\n",
    "        price_levels = []\n",
    "        price_lower = []\n",
    "        price_upper = []\n",
    "        \n",
    "        current_log_price = last_log_price\n",
    "        for i in range(len(forecast_years)):\n",
    "            current_log_price += forecasts['Price_Growth'][i]\n",
    "            price_levels.append(np.exp(current_log_price))\n",
    "            \n",
    "            # For confidence intervals, apply cumulative growth\n",
    "            cumulative_growth = sum(forecasts['Price_Growth'][:i+1])\n",
    "            lower_growth = sum(forecast_intervals['Price_Growth']['lower'][:i+1])\n",
    "            upper_growth = sum(forecast_intervals['Price_Growth']['upper'][:i+1])\n",
    "            \n",
    "            price_lower.append(np.exp(last_log_price + lower_growth))\n",
    "            price_upper.append(np.exp(last_log_price + upper_growth))\n",
    "        \n",
    "        # Create forecast dataframe\n",
    "        self.forecast_df = pd.DataFrame({\n",
    "            'Year': forecast_years,\n",
    "            'Forecasted_Price': price_levels,\n",
    "            'Lower_CI': price_lower,\n",
    "            'Upper_CI': price_upper,\n",
    "            'GDP_Growth_Forecast': forecasts['GDP_Growth_Rate'],\n",
    "            'Industrial_Growth_Forecast': forecasts['Industrial_Growth']\n",
    "        }).set_index('Year')\n",
    "        \n",
    "        print(\"BVAR forecast generation completed!\")\n",
    "        return self.forecast_df\n",
    "    \n",
    "    def save_forecast_to_csv(self, filename='platinum_price_forecast.csv'):\n",
    "        \"\"\"Save forecast results to CSV file\"\"\"\n",
    "        if self.forecast_df is None:\n",
    "            raise ValueError(\"No forecasts available. Run generate_forecasts() first.\")\n",
    "        \n",
    "        # Create a simplified CSV with Year and Platinum Price\n",
    "        csv_data = pd.DataFrame({\n",
    "            'Year': self.forecast_df.index,\n",
    "            'Platinum_Price_USD_oz': self.forecast_df['Forecasted_Price'].round(2)\n",
    "        })\n",
    "        \n",
    "        # Save to CSV\n",
    "        csv_data.to_csv(filename, index=False)\n",
    "        print(f\"\\nForecast results saved to: {filename}\")\n",
    "        \n",
    "        # Display the CSV content\n",
    "        print(\"\\n=== PLATINUM PRICE FORECAST CSV CONTENT ===\")\n",
    "        print(csv_data.to_string(index=False))\n",
    "        \n",
    "        return csv_data\n",
    "    \n",
    "    def save_detailed_forecast_to_csv(self, filename='platinum_detailed_forecast.csv'):\n",
    "        \"\"\"Save detailed forecast results to CSV file\"\"\"\n",
    "        if self.forecast_df is None:\n",
    "            raise ValueError(\"No forecasts available. Run generate_forecasts() first.\")\n",
    "        \n",
    "        # Create detailed CSV with confidence intervals\n",
    "        \n",
    "        detailed_csv = pd.DataFrame({\n",
    "            'Year': self.forecast_df.index,\n",
    "            'Platinum_Price_USD_oz': self.forecast_df['Forecasted_Price'].round(2),\n",
    "            'Lower_95_CI': self.forecast_df['Lower_CI'].round(2),\n",
    "            'Upper_95_CI': self.forecast_df['Upper_CI'].round(2),\n",
    "            'GDP_Growth_Forecast_pct': self.forecast_df['GDP_Growth_Forecast'].round(2),\n",
    "            'Industrial_Growth_Forecast_pct': self.forecast_df['Industrial_Growth_Forecast'].round(2)\n",
    "        })\n",
    "        \n",
    "        # Save to CSV\n",
    "        detailed_csv.to_csv(filename, index=False)\n",
    "        print(f\"\\nDetailed forecast results saved to: {filename}\")\n",
    "        \n",
    "        return detailed_csv\n",
    "    \n",
    "    def run_full_analysis_and_export(self):\n",
    "        \"\"\"Run complete BVAR analysis and export results\"\"\"\n",
    "        print(\"=== Platinum Price Forecasting: BVAR Analysis ===\\n\")\n",
    "        \n",
    "        print(\"1. Preparing data...\")\n",
    "        self.prepare_data()\n",
    "        self.prepare_bvar_data()\n",
    "        \n",
    "        print(\"\\n2. Training BVAR model...\")\n",
    "        self.build_and_train_bvar()\n",
    "        \n",
    "        print(\"\\n3. Generating forecasts...\")\n",
    "        self.generate_forecasts()\n",
    "        \n",
    "        print(\"\\n4. Exporting forecast results...\")\n",
    "        simple_csv = self.save_forecast_to_csv('platinum_price_forecast.csv')\n",
    "        detailed_csv = self.save_detailed_forecast_to_csv('platinum_detailed_forecast.csv')\n",
    "        \n",
    "        print(\"\\n=== FORECAST SUMMARY ===\")\n",
    "        print(f\"Forecast period: 2021-2060\")\n",
    "        print(f\"Average forecasted price (2026-2060): ${self.forecast_df.loc[2026:2060, 'Forecasted_Price'].mean():,.2f}\")\n",
    "        print(f\"Price range (2026-2060): ${self.forecast_df.loc[2026:2060, 'Forecasted_Price'].min():,.2f} - ${self.forecast_df.loc[2026:2060, 'Forecasted_Price'].max():,.2f}\")\n",
    "        \n",
    "        # Show key forecast years\n",
    "        key_years = [2025, 2030, 2035, 2040, 2045, 2050, 2055, 2060]\n",
    "        print(\"\\n=== KEY FORECAST YEARS ===\")\n",
    "        print(\"Year    Price    Lower_CI  Upper_CI\")\n",
    "        print(\"-\" * 35)\n",
    "        for year in key_years:\n",
    "            if year in self.forecast_df.index:\n",
    "                price = self.forecast_df.loc[year, 'Forecasted_Price']\n",
    "                lower = self.forecast_df.loc[year, 'Lower_CI']\n",
    "                upper = self.forecast_df.loc[year, 'Upper_CI']\n",
    "                print(f\"{year}    ${price:6.2f}   ${lower:6.2f}   ${upper:6.2f}\")\n",
    "        \n",
    "        return simple_csv, detailed_csv\n",
    "\n",
    "# Execute the analysis and export\n",
    "if __name__ == \"__main__\":\n",
    "    forecaster = PlatinumBVARForecast(lags=2)\n",
    "    simple_forecast, detailed_forecast = forecaster.run_full_analysis_and_export()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"Files generated:\")\n",
    "    print(\"1. platinum_price_forecast.csv (simple format)\")\n",
    "    print(\"2. platinum_detailed_forecast.csv (with confidence intervals)\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3035f4f4-6335-4ea8-8f6f-41d54a2c6c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter cross-validation...\n",
      "Testing 9 hyperparameter combinations.\n",
      "Testing combo 1/9: lambda1=0.05, lambda2=0.5, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 362 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 303 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 302 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 308 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 309 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 2/9: lambda1=0.05, lambda2=0.7, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 387 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 344 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 310 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 1701 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 332 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 3/9: lambda1=0.05, lambda2=0.9, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 464 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 430 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 364 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 353 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 397 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 4/9: lambda1=0.1, lambda2=0.5, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 522 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 503 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 410 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 423 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 436 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 5/9: lambda1=0.1, lambda2=0.7, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 556 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 522 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 394 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 401 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 423 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 6/9: lambda1=0.1, lambda2=0.9, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 550 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 516 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 403 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 410 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 432 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 7/9: lambda1=0.2, lambda2=0.5, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 559 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 529 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 430 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 476 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 507 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 8/9: lambda1=0.2, lambda2=0.7, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 595 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 547 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 453 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 431 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 495 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combo 9/9: lambda1=0.2, lambda2=0.9, lambda3=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 549 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 532 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 427 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 430 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 433 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation complete!\n",
      "Best hyperparameters found:\n",
      "lambda1    0.050000\n",
      "lambda2    0.500000\n",
      "lambda3    1.000000\n",
      "mse        0.016125\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/oAAAIjCAYAAACzoGDyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAA+cZJREFUeJzs3Qd4VFXaB/B/ek9ITwgJIXRI6EVQpJcEsKxtbSgq667rrq77uZa1rF137V0Ru659VSD0JtKLQEKHJISS3nsmM/M977mZkpBAAgkzk/x/+8yGnDvlzL134rz3vOc9Tkaj0QgiIiIiIiIi6hCcbd0BIiIiIiIiImo7DPSJiIiIiIiIOhAG+kREREREREQdCAN9IiIiIiIiog6EgT4RERERERFRB8JAn4iIiIiIiKgDYaBPRERERERE1IEw0CciIiIiIiLqQBjoExEREREREXUgDPSJiOi83HrrrYiNjW3Q5uTkhH/9619nfazcR+7bltauXaueU35SQx9//LHaNxkZGe36OocPH8a0adMQEBCgXu/HH39s19cjchQX6jNIRMRAn4ioFY4ePYo777wTcXFx8PT0hL+/Py6++GK89tprqKqqgj3buXOn+oL5yCOPnDFAk/vcd999sHdvv/22+tJsTyZMmKD2n+nm5eWFQYMG4dVXX4XBYEBn2Y+33HILUlJS8Mwzz+Czzz7DiBEj0F4kYJJ9/eKLL57xYlJ+fn679YHOX2VlpTpWF+oCXePPanO3llywJCKyR6627gARkaNYvHgxrrnmGnh4eGDOnDmIj49HbW0tfv31V9x///3Yu3cv3n//fdirYcOGoV+/fvjvf/+Lp59+usn7fPnll+rnTTfddF6vJRc9XF1d2z1ADQkJURkF1i699FL1+u7u7rCFbt264bnnnlP/luBS9unf/vY35OXlqcDX3jS3H8+V7PtNmzbhn//8J+6+++42eU7qHIH+E088YQ7C25ucn3fccYf5923btuH111/Hww8/jP79+5vb5UJdW7r55pvx+9//Xv13hIioPTHQJyJqgfT0dPXlrHv37li9ejUiIyPN2/785z/jyJEj6kJAc2Q0Vy4KSBaALd1444149NFHsXnzZlx00UWnbZeLAHIxQC4KnA9bvk9nZ2ebvr6kq1tfKPnjH/+o9ukbb7yBJ598Ei4uLujI5IKG6NKlS5s9Z0VFBXx8fNAR1dXVqb8PF+rCVEfel615v1OnTm3wu/zNkEBf2tvzQoN8/jv63wAisg9M3SciaoF///vfKC8vx4IFCxoE+Sa9evXCPffcY/5dUj5lNPOLL77AwIED1ejN0qVL1bbffvsNiYmJKu3f19cXkydPVoG3NZ1Op0a3evfurb6ABgcH45JLLsGKFSvM98nOzsbcuXPVCLI8v/Tr8ssvP+PcTwn0rUfure3YsQMHDx403+enn37CzJkz0bVrV/X8PXv2xFNPPQW9Xn/W/dVUyqtkPowcOVK9H3mu9957r8nHfvTRR5g0aRLCwsLU6w4YMADvvPNOg/tITQDJoFi3bp05xdb05by5Ofrffvsthg8frtLpZQRbgvGTJ082uI+MassxkfYrrrhC/Ts0NBT/93//16L33RR5v/K+y8rKkJub22Db559/bu5TUFCQuph0/Pjx06ZTXHXVVYiIiFDPJcdb7ldSUtIgdb2p9PuzpR6faT+25BxsTF5LLoYJyXKR57Ou39CSc980h1n6dNddd6nzQN5zW3n88cfh5uZmviBh7Q9/+IO6QFFdXW3eP7NmzcLy5csxZMgQtR/kfPzhhx9Oe2xxcTHuvfdeREdHq/NW/ia88MILDaZsWE8zkOkc8jmQ++7bt8983n799ddqVFmOtwSol1122WnnxPr161V2UUxMjHq8vKZkjTSePmQ6n2XKUVJSEvz8/Myf79Y+R2ZmptoX8u+oqCi89dZbartM0ZDPq/RVjn1Tf1vOtm9kv8jnTMg511Ta/IEDB3D11Verz4kcB5kO8vPPP7frudNU/ZHmaouY/uZLPQrJ9pL3KX/7TX/3G/fR+u+06TyTv5GjRo1S70+mh3366aenvfaePXswfvx49TdD3ptkZ8nfTM77J6LGOKJPRNQCCxcuVF+8xo4d2+LHyMj/N998o778SWBpCqrGjRunAp1//OMfKuCQgFeCK/lyOnr0aPMXSUn/ltRS+eJXWlqK7du3q3n2ppEoCf7k+f7yl7+o55YgUoIw+ULe1JdT0aNHD/UepF+vvPJKg5El0xf0G264wfyFVL7Uy3x9+Snv57HHHlN9+c9//tOq/SfBgBRnky/z8t5kFFMCrvDw8NPuK0G9fEGWAEfS/2Xfy5d2CQoke0JIkCTvW/olKbiiqecykfciF0Uk4Jb9mpOTo+oqbNiwQQWf1qPPEtBPnz5dHQsJyFauXImXXnpJBWV/+tOfcC5MAZ7160gav2RXXHvtteo4S+Apo/4y9cDUJ8kCkb7U1NSo9yvBn1yEWLRokQqeJHvgfJxpP7bkHGzsd7/7neq3BIzXX3+9Ci7luUVLz30TOeZyvsg5J6OyLUn9bmoevrQ3Tp2WzAoJqK2nFsi+/u6779TnyjojRC60XHfddSozQ2oPSFAlAbIEcKb9IK8hwZccG6nhIcHzxo0b8dBDDyErK0vtZ2vyHHIxQS4sSEAowascT9N5IefKAw88oD7T8tgpU6Zg165dKrgzXbSS15TzUS7AbN26VZ07J06cUNusyWdNziG5SCPns7e3d6ufQz4TcoFGzk256CkXMGXfSXAv541cPJBj/+6776ppTWPGjFF/a1q6b+Q4y+de+nLllVeq57JOm5dzR2qhyAWGBx98UL2u/A2Ti3Hff/+9esz5nDttRQJ1uQgkry8XVSRDQM4n+Zss+/hMJCtMLmTcfvvt6jz78MMP1YUGuRAofw+F7MOJEyeq80P2n+yHDz74gNMAiKhpRiIiOqOSkhKj/Lm8/PLLW/wYub+zs7Nx7969DdqvuOIKo7u7u/Ho0aPmtlOnThn9/PyMl156qblt8ODBxpkzZzb7/EVFReo1/vOf/7T6/bz11lvqscuWLTO36fV6Y1RUlHHMmDHmtsrKytMee+eddxq9vb2N1dXV5rZbbrnF2L179wb3k+d//PHHG7xvT09P47Fjx8xt+/btM7q4uKj7WmvqdadPn26Mi4tr0DZw4EDj+PHjT7vvmjVr1HPKT1FbW2sMCwszxsfHG6uqqsz3W7RokbrfY4891uC9SNuTTz7Z4DmHDh1qHD58uPFspD/9+vUz5uXlqduBAweM999/v3pO6+OZkZGh3vszzzzT4PEpKSlGV1dXc/tvv/2mHvvtt982+5rp6enqPh999NFp2xofB7mPtMljzrYfz3YOnq0/jc/Nlp77pj5ecsklxrq6uha/3tlucjxM5DwfPXp0g+f54YcfGpw3Qs5rafv+++8b/D2IjIxU54TJU089ZfTx8TEeOnSowXM++OCD6jhnZmY26Ku/v78xNze3yfNWPoelpaXm9m+++Ua1v/baa2f8jDz33HNGJyenBp8x0/ks/Wistc/x7LPPNvj74+Xlpe771VdfmdvlfG98zrV038jxafxYk8mTJxsTEhIa/N0xGAzGsWPHGnv37n3O5441+Yw1Pv5N/W0T0sfGf7fkdzm/jxw5Ym7bvXu3an/jjTfO+Bk0nWe//PKLuU3ODw8PD+Pf//53c9tf/vIXtc/l74JJQUGBMSgo6LTnJCJi6j4R0VnISKaQEZrWkFEsSfO1HhWTFGAZhZLsABNJuZdRdBkNMr2WjIrKKJaMJjZFRvZkTq+k+xYVFbWqXzI6KaOp1im2MqIqo0WmtF7Ta5hI2rmMlsqIrIzQSRptS8n7XrZsmXrfMppnIgWvZKSxqfdmIunp8rqyL9PS0szp6q0ho9AyMiqjbNYjtTItQebON1VbQUZvrcn7ltdvCdk3MpooN3l+yX6Q7ATr1HoZ9ZMMBRnNl/dnusmIvaTKr1mzRt3PNGIv+6/xyHR7O9s52BqtOfdN5s2b16q5zDI6LhktjW8ygt+YjDpv2bJFpbSbyCi1pJbLuWZNpq5YjxhLRoI8XrIuZPqMkBFwOUcCAwMbHE8ZiZf3/ssvvzR4ThnlNaWqN9U36781Msor+yk5ObnJz4iMWMtrSaaOxJvSr8aaykRp7XNYF66Tc6Nv375qRFnOYRNpk23Wn5XW7pvGCgsLVTaRvI7p75DcCgoK1N8POT8bT8Fp7bnTVuQ9SeaPiWQkyPnSkr8d8t8K2U8mcn7I/rR+rGSRSLaETCMxkWwQ67/bREQmDPSJiM5CvqgJ+ZLZGqbUVRNJzZZgTb68NSZBrwR+prm4klosqbx9+vRBQkKCmu8sczNNJFVT5rguWbJEpVqbUmpNgYeQoFh+N93kC7OQFFL5gvy///3PPBdZgn5Jk7f+0i5BngQ4EmzKPpAvnqYic60JuOV9y7xfCWAba2pfSDq9fGGWIEKCBnldmbPc2tc1OXbsWLOvJYG4abuJXAxoHIRJkNLSCyoybUICTAnOpaK9pBvLPmicDi4BlewT00UB023//v3mufxyDsnUCUnPlekfctxkbvS57IfWOts52BqtOfeb+/ycjexLOW8a36wvLFhf7JLPkAT3QvanTIeQgKnx3GuZT964TfaJMM2JluMpQVjjYymvLxrXZjjTe2v8OZHXlj5Yz7+WVHBJ65Ygz1RHwnSBovG5IZ/rpuapt+Y5mvpMyN8Fed7G+0barT8rrd03TaW0y2dFprk0fg6Z/tPUc7T23Gkr1hcyW/u3oyWPlb9Vci401lQbERHn6BMRnYUEuTKql5qa2qrHWY+YtZYE7jLaKAXxZCRUAj2ZUy9zYE0ja1Lcavbs2ar4kwSV8kVY5lTL6NfQoUNVccBPPvnE/JzyJd5UoE4Cdgls5CajzTLP1TSHXkiAJ/eX9y4Bn4xSyZd9mZ8tc4fba014ec9SoE0C8JdfflmNsErmgoxmyvu/EGvRn+9IoFygMAUxQuYWyyoGcrFC5uwKeR8SIMmFmqZezzSvXUh9AAnITOfCX//6V3WcpYhdU4GWybkWD2zNOdiezufzczYSQEnxMwn0ZR63zM2XOgjnuqykHE+Zry+1B5piujDQFu9Njqu8lly4k8+ifFbknJNRbTlPGn9G5IKGrERxPs/R3GeiuXYtk/3c9k1jpr5IQcymMoCaCnTb6txp7WerJfujOefzWCKipjDQJyJqAQkK3n//fbU+uKROngsJoqUQllS2byrdW76MS2BrIiNtUkBOblLxXwIvKZBmHWRJAP73v/9d3WTkTFI6JTCUau7yxdo6cJHgxkSCe0kPlpF8SeOXUSPr9E+5ICCpsZJiLq9rvczgubxv+eLdVAp4430hhfck4JJq2tYjXKZU9pZ8CW/MVAVeXkuqgzd+fdP29iLpu3IcpPCcBCvyvuS4yRd4GXk8W6AjZERdbo888ogqZCYXDyTglorbpuNqKuZm0jhToTln2o8tOQfb49y/ECRFXlapkPXTJeCXi2OmomdNjShb76dDhw6pn6ail3I8Zf9YX+A5V40/J/La0gdTYTopbCmvLxfx5D2YnGk1hMba4jlaqqX7prnz0JSRIX+n2mL/toZ8thp/rlrz2Wpr8rdKzoXGmmojImLqPhFRC0jQLCNeEuBIxfbGZORTqrifbcRGRs1lhNQ6DVeeTwJuqYptmiYgQXbjEV4ZtZIgWEgatCnt3voLtQTvpvvInE/rFGap3mwigbek5ctIuVS7lvcmQY91XxuPJklVcklFby15LhmJk8wDSRc2kRR1yURofN/GrytpxFKlvDHpc1NfwhuTZbhkmS0JjE37RshouvRB5upfiPNHlquTLAUhVcXlvcpSYo1H7OR30/GXeetSNd2aBPwSGJvei5wzktbfeK5zS49Vc/vxbOdga7Tm3L9QpIq87DeZAiM1KpobzT916pSa5mIix0SWPZOLalJTQciUF7kI2Ph8FrJvGx/DM5Hntp4mJNkGUp1e+tvcZ0T+fba/P9ba4jlaqqX7xrQaQONzUT67sjKDXCiT/dBYU8skthX5myp/f6ynrEgfrM+HC0n+jsq+lBUYTCQrwzQFhYjIGkf0iYha+IVPAhKZ2ytzimUUTNZKluBXRlil4JSkvJ6NjMDKqJkENlIcTubPyhdYCZ5kjr2JBOny5VaCcxlVlYJy8oXftByYjMZJirt8iZb7yvPIl08JnGSN9ZaQwEaCCvkCLqP5EvCZSFEuGc2SZZ4kVVxG2z777LNzTiOVgFbm6UqxKXnf8uVelvKSEVTrL9ESDEqqvkxJkKW4ZCRw/vz56st+4y/5sm/kIoXsUwlA5T6NR+xNI4ESzMmotExHkGXfTMvryYisLAXX3uQYyVJzkv4uUyzkfJJ+yxJZEvhKkTq5SCMZE3IcpbCcjP7LNAw55rKcm4z8y36T4yCBmhR0M5ELUM8//7z6KRc2JOg3jTqfTXP78WznYGu19Ny/UOS8kM/Km2++qfannBdNkf0uS57JyL/Uw5Blz+T8sb74JPULJAtFMn9MS6JJgTsZOZd9JsdYLiq0hOxr2UdyvsrryPJzclykwJyQNHs5f+T8kFR7uUAiU29aU5SzLZ6jpVq6b+Tio5xzsuyh7HPZD/I3Vm5Sl0L2iVzkkv0go/yybyToleUAd+/ejfYg54dMbZCLovJ3UC6wymdF+ifTmC40uWAo2VoyFUKWxTQtrydZQhLwtzTLiYg6CVuX/SciciSyRNS8efOMsbGxaiklWRrs4osvVssnWS/9JH9e//znPzf5HDt37lTLxfn6+qql6iZOnGjcuHFjg/s8/fTTxlGjRhm7dOmilrGSJdtkyTVZKk7k5+er55d2WboqICBALRcmS3G1lCw/JcuESV+Tk5NP275hwwbjRRddpF6/a9euxn/84x9qSb6WLEHV1DJZ69atU0vUyX6TpfLefffdJpep+vnnn42DBg1Sy/HJfn7hhReMH3744WnLR2VnZ6vl3+QYyDbTEnGNl9cz+frrr9WSaLJklSxHdeONNxpPnDjR4D7yXmR/NtZUP5sifZDl6pqydu3a0/aLLNsmS4HJa8pNjqcc14MHD6rtaWlpxttuu83Ys2dPtT+k33K+rFy58rSl0m6//XZ1Hsj+uPbaa9XyXC1ZXq+5/Xi2c7C1y+u19Nw39XHbtm1n2dtnfz3rY2e9vJ7J1q1b1bZp06Y1+Vg5r2XfyHkv56ScO7IfmlrusKyszPjQQw8Ze/Xqpc7xkJAQtfzbiy++aN5nZ+qr6bz973//q55HloSU/S6vb73cnWlpyilTpqj9KK8jf5NMS7lZL7PY3PncFs/R3Llu2met3TdCzgXT34jG564syzhnzhxjRESE0c3NTS1DOGvWLON33313zufO2ZbXE8uXL1dLc0qf+vbta/z888+bXV6vqb/5sj9kH55teb2mlrKUfdx46UtZWm/cuHHqXOzWrZtaEvH1119XzymfZSIiEyf5P1tfbCAiIiK60GQkWFLwJbOlqWX4JONDRpSlaGV7k7oYEydOVNlBsqQeUUtJYVbJjpEMKFssK0hE9olz9ImIiKhTkmkhUntAaiYQOQJZqrRxLQ2ZziNTGxjkE5E1ztEnIiKiTkVWd9i3b59aSUNqDljXpyCyZ7Lqi9TOkFoxUqdgwYIFqkCk1P4gIrLGQJ+IiIg6FSlkJkGSFEiUQpFEjkLOWSliKBeppPjesGHDVLBvvQwqEZHgHH0iIiIiIiKiDoRz9ImIiIiIiIg6EAb6RERERERERB0I5+ifI4PBgFOnTsHPz0/NkSIiIiIiIiJqTzLzvqysDF27doWzc/Pj9gz0z5EE+dHR0bbuBhEREREREXUyx48fR7du3ZrdzkD/HMlIvmkH+/v727o7nZpOp8Py5csxbdo0uLm52bo71Eo8fo6Px9Dx8Rg6Nh4/x8dj6Ph4DB2fzkGOoSypKQPOpni0OQz0z5EpXV+CfAb6tv9Qent7q+Ngzx9KahqPn+PjMXR8PIaOjcfP8fEYOj4eQ8enc7BjeLbp4yzGR0RERERERNSBMNAnIiIiIiIi6kAY6BMRERERERF1IHYxR/+tt97Cf/7zH2RnZ2Pw4MF44403MGrUqGbv/+233+LRRx9FRkYGevfujRdeeAFJSUnm7f/617/w1VdfqUJ57u7uGD58OJ555hmMHj1abZfHPfXUU1i9erV6TVma4KabbsI///lPdf+2XPqgrq4Oer2+zZ6Tmp5P4+rqiurq6k6zr2XekIuLi627QUREREREdsjmgf7XX3+N++67D++++64KxF999VVMnz4dBw8eRFhY2Gn337hxI66//no899xzmDVrFr788ktcccUV2LlzJ+Lj49V9+vTpgzfffBNxcXGoqqrCK6+8oqonHjlyBKGhoThw4AAMBgPee+899OrVC6mpqZg3bx4qKirw4osvtsn7qq2tRVZWFiorK9vk+ejMF1QiIiLUhZ2zFaXoKOR9ynIavr6+tu4KERERERHZGZsH+i+//LIKsufOnat+l4B/8eLF+PDDD/Hggw+edv/XXnsNM2bMwP33369+l5H5FStWqMBeHituuOGG015jwYIF2LNnDyZPnqweLzcTuSAgFxbeeeedZgP9mpoadbNe1sA0miw3a3IRIT09XY24RkZGqtHXzhKA2oIE+nKRxsfHp1PsZ3m/BQUF6sJGjx49HH5k3/T5afw5IsfBY+j4eAwdG4+f4+MxdHw8ho5P5yDHsKX9s2mgL6PeO3bswEMPPWRuc3Z2xpQpU7Bp06YmHyPtkgFgTTIAfvzxx2Zf4/3330dAQICaFtCckpISBAUFNbtdMgieeOKJ09plrUVZhsGapJHLCLOMuDrCydIRyJSLzrSfPTw8kJeXh1WrVqnpIR2BXLAjx8Zj6Ph4DB0bj5/j4zF0fDyGjm+FnR/DlmaM2zTQz8/PV3Oqw8PDG7TL75Je3xSZU9/U/aXd2qJFi/D73/9e7QgZVZcDFhIS0uRzSkq/1AU4U9q+XIywvsAgI/rR0dFqSoCstWhN5orLaKufnx88PT3PsAeorUa4y8rK1P7uDCP6pnPMy8sLl156qcOfY3KBRj6fU6dOdYg1S+l0PIaOj8fQsfH4OT4eQ8fHY+j4dA5yDE2Z5Xafut9eJk6ciF27dqmLCfPnz8e1116LLVu2nDbv/+TJkyqN/5prrlFTCM40giq3xuQkaHwiyMULCTglO0Fu1L5kqoQw7fPOQN6nvN+mzj9H1ZHeS2fFY+j4eAwdG4+f4+MxdHw8ho7Pzc6PYUv7ZtOoSEbYZX5xTk5Og3b5XVLfmyLtLbm/zNeWQnsXXXSRmp8v6fTy09qpU6fUBYGxY8eq9H4iIiIiIiIiR2fTQN+09J3MM7YenZXfx4wZ0+RjpN36/kJSLJq7v/XzWhfTk5H8CRMmqNf/6KOP7HIkWG8wYtPRAvy066T6Kb+3J9kf9957b7u+xvm8TmxsrFqVgYiIiIiIiJpn8+hW5r1Lav0nn3yC/fv3409/+pOqoG6qwj9nzpwGxfruueceLF26FC+99JKax/+vf/0L27dvx9133622y2MffvhhbN68GceOHVPF/m677TYV2Et6vnWQHxMTo+blS1EzmePfeJ6/LS1NzcIlL6zG9fM3456vdqmf8ru0U8usXbsWl19+uarRIBkeQ4YMwRdffNHur5uZmYmZM2eqIo0yVURWiDhbwTy5iCGp+Na3559/vt37SkREREREHY/N5+hfd911KtB+7LHHVKAtwZgE8qaCexI0WY+2S5r9l19+iUceeUQF9L1791YV9+Pj49V2mQogFwDkwoHMzw8ODsbIkSOxfv16DBw40JwBIAX45GaqjG9d2M3WJJj/0+c70bgn2SXVqv2dm4ZhRnykjXrnODZu3IhBgwbhgQceUOeTFGiUC0eyAsOsWbPa5TWlPoME+TKVRF4/KytLvabMpXn22WfP+Ngnn3yyQZ0IKS5IRERERETkcCP6QkbjZfRdUuulYN7o0aMbjMp+/PHHDe4vI/Oy7r3cPzU1FUlJSeZtUoH8hx9+UKP2sl3m4f/0008q2De59dZbVUDf1K09yPNW1ta16FZWrcPjP+89LchXz1P/818/71P3a8nznc97+uyzzzBixAgVcErgesMNNyA3N7fBsZGR52XLlmHo0KGqCvykSZPUfZYsWYL+/furFQnkcY2XgZARbjnuEnRLrYZHH320QV/lOWbPnq2eU9aKb2ok/uWXX0ZCQoLqn1zE+fOf/4zy8nLzdrkQ9NRTT6mLQz179lTZIFJ4Uc6P9iLLLe7btw+ff/65umiVmJio+vDWW2+ppR7PxLSfTTfJQiAiIiIiovalN+ixPWc7dtfuVj/ld0dn8xH9zqBKp8eAx5a1yXNJKJxdWo2Efy1v0f33PTkd3u6u57zEhASpffv2VYG3TLOQiyTJyckN7ifTJ958802Vqi6rG8hNViiQzAsJvK+88kq1fKGMrJtIxsXtt9+OrVu3qqkXf/jDH9RUCtOItryOXKRZs2aNGg3/61//2uAig5BMj9dffx3du3dXF3z+8Y9/qNvbb7/d7HsqKSlRFyDOxNfX94zbb7rpJrz77rtNbtu0aZO6+GC9BOT06dPVlJS9e/eqCyLNkVR92d+yH+TiyN/+9jdVRJKIiIiIiNrHymMr8fzW55FTqRV8/3bVtwj3DseDox7ElO5T4KgYRVCzpLaBSVxcnAqqJTNCgnfrYPjpp5/GxRdfrP4twbvUVDh69Kh6jLj66qtVwG4d6EdHR+OVV15RGQFyISElJUX9LoH+oUOHVEaAXAQwZWLIigmNA3RTQT8ptBgUFKRS3++6665mA/1vvvkG27Ztw3vvvXfG9y3LMp6JZCk0R6afWAf5wvT7mWpAyIWMYcOGqfchKf+yDyXtX7IWiIiIiIiofYL8+9beB2OjfOrcylzV/vKElx022GegfwF4ubmokfWW2JpeiFs/2nbW+308dyRG9Qhq0WufKylkKKP1u3fvRlFRkXm9eqmbMGDAAPP9ZB68dVArI/umIN/UJkG7NVn2UIJ8E1k1QQosyhx3KcooI9myIoJJv3790KVLlwbPsXLlSjz33HOqJkNpaamaDlBdXa2mCUgfrMmFBinwKIUfTbUamiPLMl5oki1hvT9lRYo777xTvT/JjiAiIiIiorajN+jVSH7jIF9ImxOc8MLWFzAxeiJcnM89purUc/Q7OgloJX2+JbdxvUMRGeAJp+aeC1Db5X4teT7rYLo1ZPUCSTmX0WuZHy8j4f/73//UtsZzzSW13vq9Wv9uajNdJGgrGRkZqqCeBMXffvutCuRlekBT/Vu3bp2a7y8ZA1IY72wkW+FMtz/+8Y/NPlbm1ufkaGk/JqbfZVtLSZ0KuXAh75OIiIiIiNrWtuxt5nT9pkiwn12ZjZ25O+GIOKJvZ1ycnfD47AGqur6E6NbXl0whu2yX+7UnGSUvKChQ88YlzV7IXPq2IkUXrclyiLKCgqyaIKP3EuRKRoEpdV+KLxYXF5vvL9vk4oFkAQgZ0Zd0/8akYKBcEHjhhRdUHYCWOJ/UfclMeOaZZ1Q9AVlaz7TKgzzGOguiJX2QGgSm5yAiIiIiovN3qOgQFh1dhO8Pf9+i++dV5sERMdC3Q7J0niyh98TCfcgqqTa3RwR4qiD/QiytJwXhJH1cRsllBFuK3UmhuLYi6f+Sri7p6Tt37lSvYwraZc6+VMeXbe+8845K45f5+FKB3zq9XooFyuNkOTtJ4288915G+SXIl2r7V111lXmOvLwvmQvfHqn706ZNUwH9zTffjH//+9/qNWUpSFkRwJSCL9MYJLNg1apViIqKUgX85MLHxIkTVeV9+V0K8UnRv8DAwHPuCxERERERATkVOViSvgQL0xaqQL81Qr1D4YgY6NspCeanDohQc/Zzy6oR5uep5uS390i+SWhoqFrWUJaokyJ8UijuxRdfxGWXXdYmzy+BblVVFUaNGqVG8SUYtx5x/+ijj3DHHXdg/Pjxao6/FPyTJfhMBg8erArVyUi9FK6TJfRkJF2q9VtX9pf5+jLPXW4m8pwy0t8e5L0sWrRIVdmX0X1ZIu+WW25RhQJNpE+SoSAXKoRcAPjqq69UPQRZElKWE5RA33rePhERERERtVyFrkIV21uUtghbsraY5+K7OrtifLfxSOqRhBe2vaBG7Juapy9z9KX6/rCwYXBETsb2Wjy+g5NUcVkDXpZra5zKLQXh0tPTVcDm6elpsz52FpLCL8dDjoOku3cGHekckwsesmRjUlLSafUdyDHwGDo+HkPHxuPn+HgMHR+PoX2oM9Rh06lNauR+TeYaVOst2dFDw4ZiVtwsTI+djgCPgAZV94V1sC9BvrDHqvtnikOtcUSfiIiIiIiIHJKMW+8r2KdG7pPTk1FYXWjeFusfi5lxM9Ut2k+rO2ZNgngJ5qX6vnVhPhnJf2DUA3YX5LcGA30iIiIiIiJyKCfLT2Jx2mIV4KeXpJvbAz0CkdgjUY3ex4fEn3UVMgnmZQm9rae2YsWmFZg6ZipGdR3lkEvqWWOgT0RERERERHavpKYEK46twMKjCxsse+fh4qGC9dk9Z2NM1zFwc27d9AkJ6keEj0Cue6766ehBvmCgT0RERERERHapVl+L9SfXqyXx1p1YB51BZ55HPypiFGb1nIUpMVPg6+5r667aFQb6REREREREZFfz7nfl7VLB/dKMpSitLTVv69Wllxq5l6r5ET4RNu2nPWOgT0RERERERDaXUZKh5tzL3PsT5SfM7aFeoaqgnsy77xvU16Z9dBQM9ImIiIiIiMgmpEr+0vSlKsBPyU8xt3u5emFq96kquJcU/Y4wb/5CYqBPREREREREF0x1XTXWHl+rgvsNJzegzlin2l2cXFQxPQnupbiet5u3rbvqsBjoExERERERUbsyGA3Ylr1NBfdSOb9CV2HeNjB4oAruZ/SYgRCvEJv2s6NgoG/PDHrg2EagPAfwDQe6jwXaMWVlwoQJGDJkCF599dV2e43zeZ3Y2Fjce++96kZERERERPbvcNFh87z7nMocc3tXn67mefdxXeJs2seOiIG+vdr3M7D0AaD0lKXNvysw4wVgwGW27JnDWLt2LV555RVs3boVpaWl6N27N+6//37ceOON7fq6mZmZ+NOf/oQ1a9bA19cXt9xyC5577jm4uro228+JEyc2uU36PnLkyHbtLxERERFRW8qtzMWS9CVqvfuDRQfN7X5ufpgWO01VzR8aNhTOTs427WdHxkDfXoP8b+bIwhIN20uztPZrP2Ww3wIbN27EoEGD8MADDyA8PByLFi3CnDlzEBAQgFmzZrXLa+r1esycORMRERHq9bOystRrurm54dlnn23yMWPHjlX3s/boo49i1apVGDFiRLv0k4iIiIioLVXqKrEyc6VaEm9L9haVqi9cnV1xadSlar37S7tdCg8XD9gdgx5Ox35FVOEmOB3zB+IubddM6guBl1AuBKMRqK1o2a26FFjyj9ODfO2JtB8y0i/3a8nzyWufo88++0wFmn5+fipwveGGG5Cbm9tgJNrJyQnLli3D0KFD4eXlhUmTJqn7LFmyBP3794e/v796XGVlZYPnrqurw913362C7pCQEBXYynqZJvIcs2fPVs/Zo0cPfPHFF6f17+WXX0ZCQoLq38CBA/HnP/8Z5eXl5u0PP/wwnnrqKRVI9+zZE/fccw9mzJiBH374Ae1l+fLl2LdvHz7//HM1PSExMVH14a233kJtbW2Tj3F3d1f713QLDg7GTz/9hLlz56r9S0RERERkj+oMdfj15K944JcHMOGbCfjnr//EpqxNKsgfEjoEj170KNZcswavTXpNVdC3yyB/38/Aq/Fw/fwKjDj2jvopv6t2B8YR/QtBVwk827WNnsyopfM/H92yuz98CnD3OadX0ul0Kkjt27evCrzvu+8+3HrrrUhOTm5wv3/9619488034e3tjWuvvVbdPDw88OWXX6rA+8orr8Qbb7yhRtZNPvnkE9x+++0qNX379u34wx/+gJiYGMybN09tl9c5deqUSn+X0fC//vWvDS4yCGdnZ7z++uvo3r07UlNT8Y9//EPd3n777WbfU0lJiboAcSaSbn8mN910E959990mt23atEldfJAMApPp06erVP69e/eqCyJn8/PPP6OgoEAF+kRERERE9kQG5/YV7lMj95KeX1BdYN7W3b+7Nu++xyxE+7cwXrGlfR03k5qBPjXrtttuM/87Li5OBdUyX1yCd+tg+Omnn8bFF1+s/i3B+0MPPYSjR4+qx4irr75aBezWgX50dLSaPy8j1nIhISUlRf0ugf6hQ4dURoD1/PQFCxacFqCbivIZDAYEBQXhySefxF133dVsoP/NN99g27ZteO+99874vnft2nXG7ZKl0Jzs7OwGQb4w/S7bWkLeq1wc6NatW4vuT0RERETU3k6Vn1IF9aSwXlpJmrk90CNQVcuXonoJIQmOk5Fq0GuZ0s1mUjsBSx8E+s10yDR+BvoXgqz/KCPrLSFV9r+4+uz3u/E7rQp/S177HO3YsUON1u/evRtFRUUqoDYVmxswYID5fjIP3jqolZF9U5BvapOg3dpFF13U4I/AmDFj8NJLL6k57vv371eF64YPH27e3q9fP3Tp0qXBc6xcuVIVuTtw4IAqtifTAaqrq9U0AemDNbnQICPk8+fPV2n+Z9KrVy/YyokTJ9RUCLkoQURERERkS6W1pViesVwF9ztydpjbJQVf1rmX4H5s1Fi4ObvB4Rzb2LDweZOZ1Ce1+/UYB0fDQP9CkIC2penzPSdp1fUlXaTJq0tO2na5XzteWaqoqFCjynKT+fGhoaEqwJffG881l9R6c++cnBr8bmozXSRoKxkZGaqgnqTEy/QCmecuI/GSESD9sw70161bp+b7S8aAFMY7m/NJ3Zc59o0vauTk5Ji3nc1HH32k5uhfdpljpggRERERkWPT6XVYf3K9Cu7XHV+HWoP23d8JThgZMVIF91O6T4Gfux8c1okdwJqmC2WfRpY6d0AM9O2NBO+yhJ6aK+LUKNivHwGf8Xy7p4/IKLnME3/++edVmr2QufRtZcuWLQ1+37x5s1r+zsXFRY3ey+i8ZBSYUvcPHjyI4uJi8/1lm1w8kCwAISP6ku7fmBQMlAsCL7zwgqoD0BLnk7ovmQnPPPOMqicQFham2lasWKEeY50F0dx8Jwn0TVX6iYiIiIguBPkeujtvtwrul2YsRUlNiXlbry69VHAvc+8jfM4+cGW3dFVA6g/AtvnAqd9a/jjfhtNyHQUDfXskBR+k8IPMGbFOJ5GRfAnyL0BBCCmMJ6PkUkTvj3/8oyp2JyPnbUWyA6S435133omdO3eq1zEF7TJnX6rjy7Z33nlHpfHLfHypwG+dXi/FAuVxspydpPE3nnsv6foS5Eu1/auuuso8R17el8zpb4/U/WnTpqmA/uabb8a///1v9ZqPPPKIWhFAChQKGfGXYF6Wz4uKijI/dvXq1UhPT8cdd9xxzq9PRERERNRSx0qPqeBeCuudKD9hbg/1CkVSjyS1JF7fwL6OM+++KUUZwLYFwG+fAVVFWpuLOzDgCiBtDVCRf+ZM6pZMl7ZDDPTtlQTzUvhB5oRIuohcSZKT7AIVgpBU/Y8//lgtUSdF+IYNG4YXX3yxzVLKJdCtqqrCqFGj1Ci+BOPWI+4ysi0B7/jx49Ucfyn4J0vwmQwePFgtrycj9VL8T5bQk5F0qdZvXdlf5uvLPH65mchzykh/e5D3smjRIjWlQEb3fXx8cMstt6hCgSbSJ8lQkAsVjYvwyfuQjAYiIiIiovZQVF2kRu0luN+Tv8fc7uXqpZbAk5H70RGj4eKABejMDAbgyEpt9P7wCksgHxADjJgLDJsD+IRYVd23XSZ1e3EyWi9eTi0mqeKyBrws19Y4lVsKwsnIrKz/7unpabM+dhaSwi/HQ46DLLnXGXSkc0wueMiSjUlJSZyy4KB4DB0fj6Fj4/FzfDyGjs/ej2F1XTXWnliLxUcXq3Xv64x1qt3ZyRljuo5RqfmToifB+zwKeduFykLgt8+B7Qu0kXyTnpOBUfOA3tNOD9wl2D8tkzrqgmVSt2Ucao0j+kRERERERB2MwWjA9uztKjV/xbEVKNeVm7cNCB6ggvvEHokI8QqBw5M591s/AFK/A+qqtTbPAGDITcDI24HgnmfNpK5L+wW71i/DkHHT4Rp3qcOO5Jsw0CciIiIiIuogjhQdwcK0hWrN+5xKS8X4SJ9Ic1G9nl3OEPg6Cl01sO9HYOt84KRV0fCIBGDkPCDhGsC9hRkKzi4wdr8EJ/eWYnD3Sxw+yBcM9ImIiIiIiBxYXmUektOT1ej9gcID5nY/Nz9Mi52mAvxh4cNUqr7DKzoG7PgI2PkpUFmgtTm7AQOvBEbeAUSP0pY37+QY6BMRERERETmYSl0lVmWuUsH95qzNKlVfuDq7YlzUOBXcj48eDw8XbeUnhybF9dJWa+n5h5cB9e8V/t3qi+vdAviG2rqXdoWBPhERERERkQOoM9RhS9YWlZq/OnM1quqqzNsGhw7G7LjZmB47HV08u6BDkOXwdn2pLY9XeNTSHjdBS8/vMwNwYUjbFO4VIiIiIiIiOyWLpO0v3I+FRxdiSfoSFFTXp6sDiPGLUWvdz+oxC9H+0egwsvZoS+Pt+RYwXczw8AeG3KCl54f0tnUP7R4DfSIiIiIiIjtzqvyUNu/+6CIcLbGMZnfx6IIZsTMwu+dsJIQkwKmjzEevq9GWupMA//gWS3vYQGDUHUDCtYCHry176FAY6BMREREREdmB0tpSrMhYoebdb8+xVJJ3d3bHxJiJat79xV0vhpuLGzqMkhPA9g+14noVeVqbsysw4HJt9D5mDIvrnQMG+kRERERERDai0+vw68lf1bz7dcfXodZQa942MmKkmnc/pfsU+Ln7ocMwGoG0tcC2D4CDyZbien5dLcX1/MJt3UuHxkDfjukNeuzM3amWywj1DsWwsGFwacc1HSdMmIAhQ4bg1VdfbbfXOJ/XiY2Nxb333qtuRERERESOPO9+d95uNXK/LGMZimuKzdt6BvRU8+5n9piJSN9IdCjVJcCu/2oBfsFhS3vsOGDUPKBvEtCRshVsiIG+nVp5bCWe3/o8cipzzG3h3uF4cNSD6ooend3atWvxyiuvYOvWrSgtLUXv3r1x//3348Ybb2zX183MzMSf/vQnrFmzBr6+vrjlllvw3HPPwdW1+Y/bzp078cADD2Dbtm1wcXHBVVddhZdfflk9noiIiIg6hszSTBXcy+142XFze4hXCJJ6JKnU/H5B/TrOvHuT7NT64nrfALpKrU0yFAb/XkvPD+tn6x52OAz07TTIv2/tfTDC2KA9tzJXtb884WUG+y2wceNGDBo0SAXQ4eHhWLRoEebMmYOAgADMmjWrXV5Tr9dj5syZiIiIUK+flZWlXtPNzQ3PPvtsk485deoUpkyZguuuuw5vvvmmuighWQu33norvvvuu3bpJxERERFdGEXVRViasVQF93vy9pjbvVy9MDlmskrNHxU5Cq4yL70jqasF9ktxvQ+AzE2W9tB+WnAvQb5HB5qOYGecbd2BzpKaU6mrbNGtrKYMz2197rQgXz1P/f9kpF/u15Lnk9c+V5999hlGjBgBPz8/FbjecMMNyM3NbTBiLlcbly1bhqFDh8LLywuTJk1S91myZAn69+8Pf39/9bjKyvord/Xq6upw9913q6A7JCQEjz76aIO+ynPMnj1bPWePHj3wxRdfnNY/GfFOSEhQ/Rs4cCD+/Oc/o7y83Lz94YcfxlNPPYWxY8eiZ8+euOeeezBjxgz88MMPaC/Lly/Hvn378Pnnn6vpCYmJiaoPb731FmprLfOtrMkFCLkQIPfp27cvRo4ciXfffRfff/89jhw50m59JSIiIqL2UV1XrVLy/7LqL5j0zSQ8u+VZFeQ7OzmrYnrPjXsOa69dq36OjRrbsYL80lPA6meAV+OB72/XgnxVXO8K4NbFwF2btTR9BvntqgOdUfarqq4Ko78c3WbPJ+n8Y78a26L7brlhC7zdvM/pdXQ6nQpSJfiUwPu+++5To8zJyckN7vevf/1LjUR7e3vj2muvVTcPDw98+eWXKvC+8sor8cYbb6iRdZNPPvkEt99+u0qr3759O/7whz8gJiYG8+bNU9vldWSkW9LfJQj+61//2uAig3B2dsbrr7+O7t27IzU1Ff/4xz/U7e233272PZWUlKgLEGdytnT5m266SQXiTdm0aZO6+CAZBCbTp09Xqfx79+5VF0Qaq6mpgbu7u3o/JnKBQ/z666/o1avXGftDRERERLZnMBpUpfylmUuxPGM5ynWWAaj+Qf1VWn5SXJJK0+9wZMAuYz2wdT5wYDFg1GvtvhHA8Fu1m38Hqzdg5+wi0JeRzP/85z/Izs7G4MGDVVA4atSoZu//7bffqhHgjIwMNe/6hRdeQFJSUoPA86uvvsLx48dVADV8+HA888wzGD3aEmwXFhbiL3/5CxYuXKgCLJkT/dprr3FOtJXbbrvN/O+4uDgVVMtoswTv1vvp6aefxsUXX6z+LcH7Qw89hKNHj6rHiKuvvloF7NaBfnR0tJo/LxkBciEhJSVF/S6B/qFDh1RGgFwEkNcTCxYsOC1ANxXlMxgMCAoKwpNPPom77rqr2UD/m2++UXPg33vvvTO+7127dp1xu2QpNEfOYesgX5h+l21NkSwIuYginwHJOqioqMCDDz6otknqPxERERHZr6PFR/HT4Z/wQ+kPKFlVYm6P8IlQwb3cenbpiQ6puhTY87WWnp93wNLe/RJg5O1A/9ksrtdZA/2vv/5aBTkyQiqBuFRilxHQgwcPIiws7LT7y7zn66+/XhU3k3nWMmp8xRVXqGJm8fHx6j59+vRRI8wSaFZVVakActq0aSoNOjQ0VN1HCrJJELVixQo1cj137lw1qizP19Zk/o2MrLfEjpwduGvVXWe939uT38bw8OEteu1ztWPHDnXRZPfu3SgqKlIBtanY3IABA8z3k3nw1kGtjOybgnxTmwTt1i666KIGRUbGjBmDl156Sc1x379/vypcJxdoTPr164cuXbo0eI6VK1eq8+DAgQNqXrtMB6iurlbTBKQP1uRCgxzj+fPnqzT/M7nQI+jSH8lwkM+BXCSRYnySwSD7zXqUn4iIiIjsg6yKtSR9iZp3v79wv7nd180X02KnqeBevqtLqn6HlLtfG72XIL+2PnPBzcdSXC/cEitQJw30ZZ61jOJKECYk4F+8eDE+/PBD86imNRl1l3nWUj1dSGq5BOsS2JvSqWVOeOPXkBHhPXv2YPLkySqQXLp0qRrdlTnoQrIIJCvgxRdfRNeuXdv0PUpA29L0+bFdx6rq+lJ4r6l5+k5wUtvlfu251J6MKssFF7nJ/Hi5QCIBvvzeeK65pNab++fk1OB3U5vpIkFbkWwOudAjKfFyDkjmhozEy7kk/bMO9NetW6fm+8sFHymMdzbnk7ovtQwaX9TIyckxb2uOnLNyk/v6+PiofSbnrfUFEyIiIiKyHal/tSpzlQruN2dtVqn6wtXJVc27jyyKxD2z74GvZwfNENbrgAOLgK0fAMd+tbSH9AFGztOCfM/mM1+pEwX6EpDJqLGMYprICKZUIJe5zk2Rdhn5tCbB548//tjsa7z//vuq6JtMCzA9h4wOm4J8Ia8pr71lyxY1p7ypedRyM5ERZCHZAHKzJr9LYTkJblsb4Eog/4+R/8D/rfs/9W/rYF9+F/ePvF/9u62DZ2HqtxSUKygoUJXiJc1emAJY0/syvX7jf1v/ND1n4zbZz9a/yzGRaRgS4EpGhozOy4UYU+q+ZHgUFxeb+yfb5Keku8tjysrKzLUDrPsjBQMvu+wyPP/887jjjjtatM8kO+RsqfvNPY9kpcg0EUnTN2WkSLFCeYxkJZzt9U0ZJ3Khy9PTU12Yauox0ib7Qs41yQBwZKbPT+PPETkOHkPHx2Po2Hj8HB+Pof2qM9Rha/ZWJGckY82JNar2lklCcIJa635qzFT4uviqwUdng3PHO45l2XD+7VN1cyrXpqIanVxg7JMIw4jbYOw+Tkb2tPs68HvXOcjnsKX9s2mgn5+fr1K1m5rTLOnYrZkD3Xj+s1Qy//3vf6/SuCMjI9UHT6q7m56j8bQASRWXed7NzaOWFPEnnniiySrrjdPE5blk9FbmsjdXaf1MRnUZhadGPoXXUl5DXnWeuT3UKxR/jf+r2m660NCWJLiW/spzBwYGqlFySaeXufoS+MvIuWm0X+5jqqQvQbYpxVxS5yUAte6fXCCR42xqk9eR7ACpkSBF92RqgGRkyPPLfeR4SYArUynk9WV/ysUgKVAnzy/3kf0rJ7lkYEiGx+bNm81z7039Wb9+vToH7rzzTkydOhWHDx9W2+V9yftrTlNTRhprbv/LlASpOSBTQ2TagxQQlHoSUrvAdLFILm5JJoJcnDJlj8jFKLlIIKP5Ms3g8ccfVzd5H029lhwnmZbyyy+/qP3ZEchnlBwbj6Hj4zF0bDx+jo/H0D7Id9ksfRZ26XZhT+0elBstRfWCnIMw2G0whrgPQbA+GDgCbDqyqeMdQ6MRwRUH0SNvJSKLd8AZWnG9atcAHAsej4yQSah2DwL2lQP7lqAjWWHnx7DxamZ2m7rfXiZOnKhSueVigszLlkrwMorckiCuKRJoWmcSSPAlI90y979xcTYJRqUQoKSAy6jsuZjtPxtJfZKwM3cn8qvyVXXOYWHD2jVdXwJqCYLl/chNRpUfeeQRFYQOGzZMBdVSD0GCUdluusAhy9uZ9oG8Xxlht94nUoFfRp1NbfI6N998swr+JZPCNCddbqZ5+59++qlKw5f0fLmQI4X2JPCV55fnkeJ/chFA+iTbZAk9yT6QCwem/sga9PJBkJR9uZmMHz8eq1evbrf9KFNPpCigZJrIvpLpAnKhSN63kPcoFx1M70VIMUIpKikXh2Tk/5133lH7qDlyjsmFj0svvfSczzF7IRds5A+qXIxpPO2DHAOPoePjMXRsPH6Oj8fQPmRVZKn17hdnLEZaeZq5vYtHFzVqL6P3MopvXWeqwx3D2nI4p3wD5x0fwSnPUnvAEH0RDMNvg0u/WYhzcUdHnFyqc5Bj2NIBX5sG+jLCLkGeaQ6zifze3HxmaW/J/SXAkqJqcpNRVkkLl3n6ErDLfRsv1SajolKJv7nXlWBVbo3JSdD4RJAAVv4AyGjs+RRTk8eO7tp2y/KdjaS5W5NRablZs17rXqrFW/8uZPTfulq/kEwI62wI69dpbq67jHRLwGztlltuafC7XHiRm6SxywkvQbP1faTAndwutB49eqhVA5rT1H777LPPWn1umOoh2PMfotboSO+ls+IxdHw8ho6Nx8/x8RheeGW1ZVhxbIWad78te5u53d3ZHROiJ6iiepdEXQK3FlaOd9hjmHdQq5y/679AbZnWJjXGBl2rius5RySgg5YVdLhj2NK+2TTQNy19t2rVKjVSLCRok9/vvvvuJh8j1dllu2lpNSFXXqT9TOR5TXPs5b4y31tSqE2V3WWEV+5jvQQfERERERF1LDq9DhtObcDCowux9vha1BosU21HhI/A7J6zMaX7FPi7d/DCcvo64GAysG0+kP6LpT24l1Y5f/D1gFfDVa/Icdg8dV9GZGUUVgrjjRo1Si2vJ3PATVX4Je05KipKpT4LWWdcUq8lbXvmzJn46quvsH37dpVeLuSxUgxNCrDJXG9J3X/rrbdw8uRJXHPNNeo+sh67zOuW1HAZUZY0DbmwIPO527riPhERERER2ZZkU+7J34NFRxep9PzimmLztriAOBXcS2p+pG8kOryyHGDnp8COj4DSk1qbLAPYJxEYdQfQY4Kkj9q6l+Togf51112HvLw8PPbYY6oQ3pAhQ9TSd6aCe1K0zTr9XeZiy1r3Mnf84YcfVin5UtQsPj5ebZepAFLIT1K2JcgPDg5WldulMJv1+umyZJwE91L0TZ7/qquuwuuvv26DPUBERERERO0hszQTi9MWq9T8zLJMc3uwZzCS4pJUan7/oP5NzrvvUGTaaOZmbfR+38+Aob5yu3cIMGwOMOI2oIu20hZ1DDYP9IUE3M2l6jeeNy5kZN40Ot+YFCb74YcfzvqaUmFfLhgQEREREVHHUVxdrEbtJbjfnbfb3O7l6oXJMZNVcD86cjRcne0iFGpftRXAnm+0+fc5qZb2bqOAUfOAAZcDrqfXISPH1wnObttpXHCNqK3w3CIiIiKyqNHXYN3xdViYthC/nvwVdQZt+WFnJ2dcFHmRCu4lyPeWAnOdQf6R+uJ6XwI1JVqbqxeQcLU2/77rEFv3kNoZA/12rIQoS7vJEmhEba22ttY8VYWIiIioMzIYDdiRs0Ol5i/PWI4yXX21eKnJFdQfM+NmIqlHEkK9Q9EpSHG9w8uArfOBtDWW9qA4YMTtwNAbAa9AW/aQLiAG+u1Agq8uXbqYl/CT9eY7/LwfG5LVEiTwlbXlz2c5Q0d6v1LXQs4rV1d+hImIiKhzOVp8VKXlS4CfVZFlbo/wiVAF9WT0vldgL3Qa5XnAzk+AHR8DJcfrG52APjO04npxk1hcrxNilNBOIiIi1E9TsE/tm8ZeVVWlsic6ywUVuaARExPTad4vERERdW75VflITktWAf7+wv3mdl83X0ztPlVVzR8ePlyl6ncKMo3zxDZt9H7fj4C+folAryBLcb3A7rbuJdkQA/12IgGYLO8XFhamlu+j9iP795dffsGll15qnjbR0bm7u3eK7AUiIiLqvCp1lVh9fLUK7jed2qRS9YWrkysuiboEM3vOxIRuE+Dp6olOo7YSSP1OC/Cz91jao4YDI+cBA68E3DrR/qBmMdC/AGn8nEfdvmT/1tXVqRUXOkugT0RERNQR6Q16bMnaooL7lZkrUVVXZd42KHSQSsufHjsdQZ5B6FQKjgLbPwR++xyoLtba5AJH/FVacb2oYbbuIdkZBvpERERERGTTaZgHiw5i4dGFWJK+BHlVeeZt0X7RKriXwnrd/TtZKrpBDxxerlXPP7LS0h4YW19c7ybAu5Nd8KAWY6BPREREREQXXHZFtiqoJ6P3R4qPmNsDPAIwI3aGCvAHhw7ufDWJKgqA3z7VRvCLM+sbnYDeU7X0/F5TWFyPzoqBPhERERERXRBltWVYeWylCu63ZW+DEUbV7u7sjvHR41VwPy5qHNxcOuF0zBM7gG3zgdQfAH2N1ibL4cnIvRTXk2XyiFqIgT4REREREbUbnUGHDSc3qOB+7fG1qDEFsYCqlD87bjamxk6Fv7s/Oh1dlRbYS4B/6jdLe+QQYNQ8bQ6+m5cte0gOioE+ERERERG1+bz7lPwUNe9+WcYyFNUUmbfFBcSp5fCSeiShq29XdEqF6fXF9T4Dqur3jYs7MPB3WoAvVfQ725QFalMM9ImIiIiIqE0cLz2ORemL1Nz7Y6XHzO3BnsFI7JGoAvz+Qf0737x7YTBoRfVk9P7wCrkcorUHxAAjbwOG3gz4hNi6l9RBMNAnIiIiIqJzVlxdrEbtJTV/V94uc7uXqxcmxUxS8+4virwIrs6dNPSoLNSWxdu+ACjKsLT3nKyN3veeBjhzOW5qW53000ZEREREROdK5tn/cuIXlZq//uR61BnqVLuzkzNGR4xWI/cS5Pu4+aDTkjn3Wz8AUr8D6qq1Ns8AYMhNwMjbgeCetu4hdWAM9ImIiIiI6KwMRgN25uxUI/fLM5ajTFdm3tYvqJ8auZf0/DDvMHRaEtDv/U5Lzz+5w9IeMai+uN7VgLu3LXtInQQDfSIiIiIialZaSRoWHdXm3Z+qOGVuD/cOx8y4mSrA7x3YG51acSYGnPwarm/8DagssBTXG3CFFuB3G8nienRBMdAnIiIiIqIG8qvysSR9iRq931ewz9wuqfhTu09VS+KNiBihUvU7LSmul7Zapee7HlqK3qbiev7dgBFzgWG3AL6htu4ldVIM9ImIiIiICJW6Sqw5vgYL0xZi86nN0Bv1qt3VyRUXR12MWT1nYUK3CfB09USnJsvh7foS2PYBUJimmmSsPtdvIIKmPwDX/jMBF4ZZZFs8A4mIiIiIOim9QY8t2VtUWv7KYytRWVdp3jYoZJBKzZ/RYwaCPINs2k+7kLVbC+73fAvUVWltHlJc7wbohs7Bpi2HkdQ3iUE+2QWehUREREREnYjRaMShokOqYn5yejLyqvLM27r5dlMj9zN7zERsQKxN+2kX6mqAfT8BW+cDJ7Za2sPjgZF3AIOuBdx9AJ0OwGFb9pSoAQb6RERERESdQHZFtgrsJcA/UnzE3O7v7o8ZsTPUkniDQwfDiUXjgOLjwI6PgJ2fAhX1F0KcXYEBlwMj5wExF7G4Htk1BvpERERERB1UeW05VhxboYrqbcveBmN9wTg3ZzdMiJ6gUvMvjboUbi5utu6q7RmNQNpaLT3/YDJgNGjtfl0txfX8wm3dS6IWYaBPRERERNSB6Aw6bDq1SY3cS3G9Gn2NeduwsGFq5F4q5wfI/HICqkuAXf/VAvwCq/T72HHa0nh9WVyPHA/PWCIiIiKiDjDvPjU/VVXMX5q+FEU1ReZtPQJ6qOXwkuKSEOUbZdN+2pXsVGDbfGDPN4Cuvgihux8w5Hpt/n1oX1v3kOicMdAnIiIiInJQx8uOq4r5cssozTC3S5X8pB5JqrDegKABnHdvUlcL7P9ZG73P3GRpD+0PjJLietcBHn627CHZgN5gxJb0QuzId0JweiHG9AqDi7Njf2YY6BMREREROZCSmhIsy1im5t3/lvubud3TxROTYiZhVtwsjOk6Bq5SPI40JSeBHR9rt4pcrU32T79ZWnp+94tZXK+TWpqahScW7kNWSTUAF3x6eDsiAzzx+OwBmBEfCUfFTz8RERERkZ2r1dfilxO/qHn3v5z8BXWGOtXuBCeMjhyt5t1PjpkMHzcfW3fVvorrpf+ipecfkOJ6eq3dN8JSXM/fcQM5apsg/0+f76wvUWmRXVKt2t+5aZjDBvsM9ImIiIiI7JDBaFAj9jJyLyP4ZbVl5m19A/uqkfvEHokI92El+AaqS4HdX2np+fkHLe3dL9HS82UUn6sMdHp6g1GN5DcO8oW0SX6HbJ86IMIh0/gZ6BMRERER2ZG0kjQsOrpIrXl/svykuT3MO0wthycBfp/APjbto13K3Q9sleJ6XwO15Vqbu682716K64UPsHUPyY5sTS+sT9dvmgT7sl3uN6ZnMBwNA30iIiIiIhsrN5Tjvwf/i+SMZOwt2Gtul1T8KTFTVGr+iPARcHF2sWk/7Y5eBxxYBGz9ADj2q6U9pK8W3A/+PeDpb8sekp2prTPg1yN5eHddWovun1vW/MUAe8ZAn4iIiIjIBqrqqrAmcw1+PvIzNpVugmGHQbW7OLng4qiL1ZJ446PHw8vVy9ZdtT+lWcDOT7TiemVZWpuTC9Bvphbg97iUxfXIrFqnx6+H85GckoUV+3NQVq3VuGiJMD9POCIG+kREREREF4jeoMfW7K1q3v3KYytRWVe/fjuA+OB4tRzejNgZCPZyvFThC1Jc79gGLT1fRvHrCxLCJwwYfqt2C4iydS/JjoL7dYfyVHC/an8uymsswX24vwemD4zAoj1ZKKqobXKevlwmigjwxKgeQXBEDPSJiIiIiNrZwcKDKrhPTktGblX98m4AonyjkBSbBO9j3rhl+i1wc2ORuNPUlGnz7rctAHL3Wdpjxmij9/0vA1zdbdlDshNVtXqsPZiL5NRsrN6fg4ra+pUWJGj390RiQgRmJkRiWEwgnJ2dMLZnsKquL0G9dbBvygWRJfYcsRCfYKBPRERERNQOsiuysSR9CRamLcThosPmdn93f0yPna7m3Q8JHYK6ujokn0i2aV/tUt5BrXL+rv8CphUH3LyBQddqAX5Egq17SHagsrYOqw/kYklKtvpZpbME91FdvJAYH4GkQZEY0q2LCu6tydJ5soSeVNe3LswnI/kS5Dvq0nqCgT4RERERURspry3HysyVavR+a9ZWGOvHCd2c3TC+23hVMX9ct3Fwd+EIdJP0dcDBZGDbfCD9F0t7cK/64nrXA15dbNlDsgOShi9BffKeLKw9lItqnVbfQnQL9FKj9okJkRjcLQBOZ6nVIMG8LKG36Ugulq/fgmnjRmNMrzCHHck3YaBPRERERHQedAYdNp3apJbEW3N8Dar1lpHBYWHD1Lz7ad2nIcAjwKb9tGtlOVpxve0fAWWntDYnZ6BvUn1xvfGAs7Ote0k2VFatU3PtZc69zL2vqbME9zFB3khKiFQBfnyU/1mD+8YkqB/dIwgF+43qp6MH+YKBPhERERFRKxmNRrUM3sKjC7E0YykKqwvN22L9Y1VaflKPJHTz62bTftp9cb3Mzdro/b6fAYNOa/cOAYbfAgyfC3SJtnUvyYZKqnRYuS8HS1Kz8MuhfNTqLcF9jxAfJCVEIDE+EgO7tj647+gY6BMRERERtdCJshNYnLZYpeZnlGaY24M8g5DYI1EtiTcgeACDjjOprQD2fKPNv89JtbR3GwWMmgcMuBxw9bBlD8mGiitrsWJfjhq5//VIPnR6S5m8nqE+5rT8fhF+/JydAQN9IiIiIqIzKKkpwbKMZSrA35m709zu6eKJiTET1bz7MV3HqHn4dAb5h+uL630J1JRqba5eQMLVWoAfOdjWPSQbkSXulu/LRnJKNjYcyUedwRLc9wn3VWn5cusT7mfTfjoSBvpERERERI3U6mvxy4lf1Mi9/JR5+MIJThgdOVoF95NjJsPX3dfWXbX/4nqHlmrp+WlrLe1Bcdrc+yE3AF6Btuwh2UhBeQ2W7dXS8jceLYDeKriX0XotuI9ArzAG9+eCgT4RERERUf28+99yf1PL4ckIfplpSTcZVQzso4J7mXcf7hNu0346hPI8S3G90hP1jU5AnxnAqDuAuEksrtcJ5ZVJcC8j91nYnFYAq9geAyL9MXNQpFoOLy6UF9DOFwN9IiIiIurU0kvS1ci9pOafLD9pbg/zCsPMuJnq1jeor0376BCkuN6JbcBWKa73I6Cv1dq9goBhc4ARtwGB3W3dS7rAckursbQ+uN+aXtgguE+IClAj9xLcx4b42LKbHQ4DfSIiIiLqdAqqClS1fFkSL7XAUhDO29UbU7tPVUvijQwfCRdnF5v20yHUVgIp32rz77P3WNqjRmjp+QOvBNw8bdlDusCyS6pVSv6SlGxsO1aorgGZDI7ugqT4CBXgRwd527KbHZpdBPpvvfUW/vOf/yA7OxuDBw/GG2+8gVGjRjV7/2+//RaPPvooMjIy0Lt3b7zwwgtISkpS23Q6HR555BEkJycjLS0NAQEBmDJlCp5//nl07drV/ByHDh3C/fffjw0bNqC2thaDBg3CU089hYkTJ16Q90xEREREF1ZVXRXWHl+rlsTbeGoj9Ea9andxcsHYrmPVkngToifASwrE0dkVHAW2LQB2fQ5Ul2htrp5AvBTXuwPoOtTWPaQL6FRxFZakaiP3O44VNdg2LKaLCuxnxEegWyCD+04R6H/99de477778O6772L06NF49dVXMX36dBw8eBBhYWGn3X/jxo24/vrr8dxzz2HWrFn48ssvccUVV2Dnzp2Ij49HZWWl+rdcCJCLBkVFRbjnnntw2WWXYfv27ebnkcfKRYLVq1fDy8tLva60HT16FBERERd4LxARERFRe9Ab9NiWs02N3K/MXIkKXYV5W3xwvBq5nxE7A8FewTbtp8Mw6IHDy7X0/KOrLO2BscCI24GhNwHeQbbsIV1AxwsrsTQ1G4tTsrDreHGDbSO6B5qD+65dePGs0wX6L7/8MubNm4e5c+eq3yXgX7x4MT788EM8+OCDp93/tddew4wZM9RovJBR+BUrVuDNN99Uj5URfPndmmyTDIHMzEzExMQgPz8fhw8fxoIFC9RIvpAR/7fffhupqakM9ImIiIgc3KGiQyq4X5y+GLmVueb2KN8o87z7uIA4m/bRoVQUAL99Cmz/ECjOrG90AnpPBUbOA3pNYXG9TiKzoBLJKi0/C7tP1GdyyNngBIyMDVJp+TPiIxERwOkanTbQl5T5HTt24KGHHjK3OTs7q1T7TZs2NfkYaZcMAGuSAfDjjz82+zolJSVwcnJCly5d1O/BwcHo27cvPv30UwwbNgweHh547733VAbB8OHDm3yOmpoadTMpLS01TxWQG9mOaf/zODgmHj/Hx2Po+HgMHRuPn4UE9EsyliA5IxmHiw+b2/3c/DCt+zQkxSZhcOhgODs529U+s+dj6HRyJ5x3LIDTvh/hpNe+Cxu9AmEYfAMMw+ZqI/lCr9dunZQ9H8O2cKygEktlKby92dh7yrIahbMTMCo2EDMGhmPqgHCE+XmYtznavtA5yDFsaf9sGujLyLper0d4eMMlSuT3AwcONPkYmcff1P2lvSnV1dV44IEHVLq/v7+/apOgf+XKlSrl38/PT11ckCB/6dKlCAxseh1PmSrwxBNPnNa+fPlyeHtznok9aJzJQY6Fx8/x8Rg6Ph5Dx9ZZj1+NsQZ7dXuxq3YX0uvSYYRW9csFLujr1heD3Qarn675rsjKz4L8z17ZyzF0NtSiW9FmxOavQmBlurm9yLsH0kOm4GTgaBhq3IFN+wDIjeztGLaFnCpgd4ETdhU442Slk7ndCUb0DjBiSLARCYFG+LvnAQV52L7eUtTSka2w82MoU9UdInW/va92XHvttWpN1HfeecfcLr//+c9/VsH9+vXr1Rz9Dz74ALNnz8a2bdsQGRl52nNJ1oF1JoGM6EdHR2PatGnmCwhku+MsH8ipU6fCzc3N1t2hVuLxc3w8ho6Px9CxdcbjV2eow+aszWrkfu2JtajWV5u3DQkdokbup8ZMRYBHAByB3RzDogw47/wIzru/hFOVVkzN6OIB44ArYBh+O3yjhiFBlkSzXQ/tlt0cw/N0JLccS/bmYNneHBzMKTe3uzg7YUxckBq5n9I/DME+7uhodA5yDE2Z5XYd6IeEhMDFxQU5OTkN2uX35ubJS3tL7m8K8o8dO6YK7lkH4/L7okWLVKE+U7vMz5cD+8knnzRZG0DS++XWmJwE9nwidCY8Fo6Nx8/x8Rg6Ph5Dx9bRj58M1Owr2IeFaQuxJH0JCqsLzdti/WMxK24WkuKSEO0XDUdlk2NoMABHVgLb5gOHZSSzfh20gBhg5G1wGjoHTj7B4Oz7jvk5lM/VoZxyVUxP5twfzrUE967OTrikdwiS4iNVWn5gBwzuHfEYtrRvNg303d3d1Zz4VatWqTR6YTAY1O933313k48ZM2aM2n7vvfea2yRAl/bGQb4U3FuzZo2ak99UuoOk7FuT3+X1iYiIiMg+nCw/icVpi9WSeBmlGeb2IM8gVS1flsQbGDxQTc2kVqgsBH77HNi+QI3km/WcDIyaB/SeBji72LKH1I7B/f6sMrXOvQT4aXmWlSjcXJwwrneoqpY/tX84ArztN+AlO0/dl3T4W265BSNGjFCV8WWZu4qKCnMV/jlz5iAqKkrNkReyVN748ePx0ksvYebMmfjqq6/Usnnvv/++Oci/+uqr1RJ7MmovNQBM8/eDgoLUxQW5KCBz8eV1H3vsMZW6P3/+fKSnp6vnJCIiIiLbKakpwfJjy1XV/J25O83tHi4emBQ9SS2JN6brGLg5MwhptZM7gW0fAKnfA3X1Ux48A4AhNwEjbweCe9q6h9ROwf3eU6VqjXtZ6z493xLcu7s649LeoZg5KAKT+4fD35Ofq47A5oH+ddddh7y8PBVwS0A+ZMgQVRTPVHBPlsSzHnkfO3YsvvzySzzyyCN4+OGH0bt3b1VxPz4+Xm0/efIkfv75Z/VveS5rMro/YcIENWVAXuOf//wnJk2apC4ODBw4ED/99BMGDx58Qd8/EREREQG1+lqsP7Eei9IWYd2JddAZtMrSTnDCqIhRKrifEjMFvu6+tu6q49FVA3v/p6Xnn9xhaY8YpI3ex18NuLO4dEcM7lNOltSn5Wcjs9BSxM3D1RkT+moj95P6hcGPwX2HY/NAX0iafnOp+mvXrj2t7ZprrlG3psTGxqqT+mwkg2DZsmXn0FsiIiIiagvynW1X3i6Vlr8sYxlKay1FpnoH9sbsuNlI7JGICJ+mazfRWRQd09a9/+0zoLJAa3NxBwZcoQX43UZqi59Tx/pMHS9Wo/Yyen+iqMq8zdPNGRP7hqngfmK/MPh62EUoSO2ER5eIiIiILqiMkgw1ci83mYNvEuYVpgrqSWG9vkF9bdpHhyX1po6u1tLzDy21Kq4XDYyYCwydA/iG2rqX1IYMBiN+O16speWnZOFUiWUVCi83F0zqH6YK6k3sFwpvd4Z/nQWPNBERERG1O6mSL9XypbBeSn6Kud3b1RtTuk9Rwb2k6LuwANy5keXwfvtCK65XmGZpj5tYX1xvOuDCr/4dKbjfkVmExXuysDQ1G9mlluDex91FzbVPSojA+D5h8HLnZ6oz4qediIiIiNpFdV011h5fq5bE23ByA/RGvWp3cXJRxfQkNX9C9AR4u3F++DnL2g1snQ+kfAfU1adpe0hxvRu04nohvW3dQ2ojeoMR2zIK1ci9BPe5ZTXmbX4erpgyIByJ8RG4tE8oPN0Y3Hd2DPSJiIiIqM3oDXpsz9mu5t2vzFyJCp2lurcsgycj9zN6zECIV4hN++nQ6mqAfT9pAf6JrZb28Hhg5B3AoGsBdx9b9pDaSJ3egK3phUhOleA+B/nlVsG9p6ta335mQqRa797DlcE9WTDQJyIiIqLzdqjokJpzL6n5uZW55vauPl0xM26mqpofFxBn0z46vOLjwI6PgB2fAJX5WpssMTjgMmDkPCDmIhbX6yDB/ea0QlUtf/nebBRU1Jq3BXi5YdoAScuPxMW9QtTSeERNYaBPREREROdEAvrktGQV4B8sOmhu93P3w/TY6Wr0fmjYUDg7MRg5Z7KaVNoaYKsU11sCGA1au19XYMRtwLA5gJ+2LDU5Lp3egI1HC1QxvWV7s1FUqS0vKQK93TB9YAQSEyIxtmcw3Fz4eaKzY6BPRERERC0mqfirMlep1PwtWVtgrK/q7ursikujLsXsnrMxrts4eLh42Lqrjq2qGNj9X616fsERS3uPS7XR+75JLK7n4GrrDNhwJF/NuV++LwclVZbgPsjHXQX3kpY/Oi6IwT21Gv86EBEREdEZ1RnqsOnUJjVyvzpzNar1lgrfMmIvI/cygh8gReDo/GSnAtvmA3u+AXSVWpu7HzDkem3+fSiXHXRkNXV6/Ho4X6Xlr9iXg7LqOvO2EF8PzIgPV0vhjeoRBFcG93QeGOgTERER0WmMRiP2Fe7DoqOLkJyerJbHM+nu310F9zL3Ptov2qb97BD0tYgq2gyXT98Gjm+2tIf2B0ZJcb3rAA8/W/aQzkO1To9fDuVhSWo2VkpwX2MJ7sP8PFSlfEnLHxkbBBdn1ligtsFAn4iIiIjMTpafVPPuZUm89JJ0c3ugR6Cqli9L4sWHxMOJRd/OX8lJVVzPdccnGFFRX8DQ2RXoNwsYNQ/ofjGL6zlwcL/2YC6SU7Kxan8OKmq1pSVFhL8nZsRHYOagSAyPCYQzg3tqBwz0iYiIiDq5kpoSrDi2Qs2735m709wu8+wnRk9Uo/djo8bCTSq80/kX10v/RUvPP5AMGPWQMK/atQvcxvwBLiNvA/wjbd1LOgc1eqhR+2X787DmQC4qrYL7rgGeatRequUPje7C4J7aHQN9IiIiok5Ip9fhl5O/qOXw1h5fC51BKwTmBCeMihil0vKndp8KX3dfW3e1Y6guBXZ/pRXXy7esUIDul6Bu+FwsT3NC4qWXwcWNF1McSUVNHVYfyMWi3Sex+oALdFv3mLdFdfFSo/aSmj8kuguzYOiCYqBPRERE1Inm3e/O261G7pcdW6ZG8k16demlKuYn9UhChE+ETfvZoeTs04L7PV8DteVam1w8Gfx7YMTtQPgAGHU6GNOTbd1TaqGyap0K7qVa/tqDeaipq1/yEE6IDvRC0qBIVS0/ISqAwT3ZDAN9IiIiog7uWOkxVTFfCuudKD9hbg/1ClWBvQT4fQL7MChpK3odsH+hFuAf22BpD+mrzb2X4nqe/rbsIbVSabVOzbVfvCcbvxzOU0vjmcQGe2PGwHD4FR/GvKsvgbu7u037SiQY6BMRERF1QFIlf2n6UpWavyffkk7s5eqlUvIlNX90xGi4OLvYtJ8dSmkWsONj7VaerbU5uQD9ZmoBfuw4FtdzICWVOqzYn6NG7mVJvFq9JbiPC/VRo/aJ8ZHoH+mHuro6JCcf5sUyshsM9ImIiIg6iOq6aqw9sVaN3G84uQF1Rm0ZLxcnF4zpOkYV1ZPiet5u3rbuascqriej9luluN4iwFC/dJpPGDD8Vu0WEGXrXlILFVXUqvXtk1OzsOFIPnR6o3lb7zBfVUxPbn3CfRnUU8cN9GtqauDh4dF2vSEiIiKiVjEYDUjTpeGJzU9g1fFVKNfVzwMHMCB4gAruE3skIsQrxKb97HBqyrR591s/APL2W9pjxgAj7wD6Xwa4MoXbERRW1GLZ3mw1cr/paAHqDJbgvl+Enxq1T0qIQO9wP5v2k6jdAv0lS5bgq6++wvr163H8+HEYDAb4+Phg6NChmDZtGubOnYuuXbu2qgNERERE1HqHiw6refeSmp9TmQOkae2RPpEquJdbXJc4W3ez48k7qI3eSwX92jKtTTIkZN69BPgR8bbuIbVAfnmNObjfnFYIvVVw3z/SHzMTItRyeD1DueoEdeBA/3//+x8eeOABlJWVISkpSf1bAnovLy8UFhYiNTUVK1euxFNPPYVbb71V/QwNDW3/3hMRERF1InmVeUhOT1YB/oHCA+Z2T3gisWciLut1GYaFD4Ozk7NN+9nh6OuAg4u1AD9jvaU9uLcW3A+5HvAMsGUPqQVyy6qxLFWC+2xsSS+AVWyP+Ch/lZIvo/c9Qnxs2U2iCxfo//vf/8Yrr7yCxMREODuf/h+Oa6+9Vv08efIk3njjDXz++ef429/+1jY9JCIiIurEKnWVWJW5Si2JtyV7i0rVF67OrhgXNQ5J3ZNQnlKOy0dfDjeuwd62ynKAnZ8A2z8Cyk5pbXIRpW+SFuDHTWBxPTuXU1qNJSlZSE7NxraMQlVSwWRwtwA1ap8UH4mYYNatoE4Y6G/atKlFTxYVFYXnn3/+fPtERERE1KnVGeqwOWuzGrlfnbkaVXVV5m1DQoeotPzpsdPRxbMLdDodklO5BnubkUgwczOwbT6w72fAoNPavUOA4bcAw+cCXaJt3Us6g6ySKixJ0dLyd2QWNQjuh8Z0UYH9jPgIRAcxuKeOi1X3iYiIiOyA0WjEvsJ9qmL+kvQlKKguMG+L8YvBrJ6zMKvHLET7M8hsFzXlQMq3wLYPgJxUS3v0aG30fsDlgCuLUNurE0WVWKrS8rOwM7O4wbbh3QNVWr4E91FdvGzWRyK7DPQHDBiAX3/9FUFBQer3u+66C08++SRCQrQKrrm5uYiNjUVlZWX79ZaIiIiogzlVfkoV1JPR+7SS+op6AAI9AjGjxww1ep8QksClvNpL/mEtuN/1JVBTqrW5egGDrtEC/MjBtu4hNeN4YaUK7CUtf/dxS3AvH5WR3YOQKAX14iMREeBp034S2XWgf+DAAdTV1a8LCqh5+P/3f/9nDvTlKnR1dXX79JKIiIioAymtLcWKjBUquN+es93c7u7sjokxEzE7bjbGRo2FmzPn3Ldbcb1DS7X0/LS1lvaguPriejcAXoG27CE141hBhSqmJwF+yskSc7uzEzCqR5A2cj8wAmH+DO6pczvn1H0J7BvjlWYiIiKipun0Oqw/uV4F9+uOr0OtoVa1O8EJIyNGqpH7Kd2nwM+da3W3m/I8S3G90hOW4np9ZgAjbwfiJgFNFJ4m20rLK8eS1Gws3pOFfVmlDYL7i+KCVXA/fWAEQv04tYLIhHP0iYiIiNqJDIzsztutgvulGUtRUmMZgezVpZcK7mfGzUSET4RN+9mhyeDU8a3a6P3eH62K6wUDw+ZoxfUCu9u6l9TIkdxyLS0/JQsHssvM7S7OThjbM1il5E8fGI5gXwb3ROcV6MtofeMRe47gExEREZ3uWOkx87z742XHze0hXiFI6pGE2T1no29gX36Xak+1lfXF9eYD2SmW9qgRwKh5wIArADemd9uTQzll5uD+UE65ud3V2QkX9wpBUkIEpg2IQKCPu037SdShAn25Ij158mS4umoPqaqqwuzZs+Hurn3QrOfvExEREXU2RdVFatRegvs9eXvM7V6uXpgSM0WN3o+OHA0XZxeb9rPDKzgKbFsA7PocqK7PoHD1BOKvBkbdAXQdauseklV8IaP1pnXuZRTfxM3FCZeo4D4SUweEo4s3g3uidgn0H3/88Qa/X3755afd56qrrmqbXhERERE5gOq6aqw9sRaLjy7Gryd/RZ1RG/hwdnLGmMgxakm8SdGT4O3G9brblUEPHF4ObJ0PHF1laQ+MBUbcDgy9CfDWVo4i2wf3e0+VYklqllrrPi2/wrzN3cUZl/bRgvvJ/cMR4MVilEQXPNAnIiIi6owMRgN25OzAwqMLseLYCpTrLKOQ/YP6q7T8xB6JKk2f2llFPrDzU624XklmfaMT0Hualp7fczKL69lJcJ96shSLU7JUgH+swLIct7urMyb0Ca0P7sPg58ngnsguivGtW7cOFRUVGDNmDAIDuQwJERERdUxHio6otPzF6YuRXZFtbo/0iVQF9SQ1v2eXnjbtY6cprndyhzZ6v/d/gL5Ga5fl8IbeDIy4DQjqYetednqqEOWJkvq0/CwcL6wyb/NwdcbEvmFIGhSJSf3C4OvB+uBEba3Fn6oXXngB5eXleOqpp8wf3sTERCxfvlz9HhYWhlWrVmHgwIFt3kkiIiIiW8irzENyerIqrLe/cL+53c/ND9Nip6kAf3j4cJWqT+1MVwWkfq8F+Fm7LO0y537kPCD+d4Cbly172OkZDEbsOlGM5D0ycp+Nk8WW4N7LzUUF9YkJESrI92FwT9SuWvwJ+/rrr/HAAw+Yf//uu+/wyy+/YP369ejfvz/mzJmDJ554At9880179ZWIiIio3VXqKrEqc5Uavd+ctVml6gtXJ1dc0u0SzI6bjfHR4+HhwmW9LojCdGD7AuC3z4GqIq1N9r0E9hLgdxtu6x6iswf3OzOLVFr+0tRsZJVUm7d5u7uoufZJ8RGY0DcMXu4sRElkd4F+eno6Bg0aZP49OTkZV199NS6++GL1+yOPPIJrrrmmfXpJRERE1I7qDHXYkrUFC9MWYnXmalTVWUYiB4cOVmn502OnI9CT0xQvCIMBOLJSWxrv8ArJJdXaA2KAkbcBQ+cAPsG27mWnpTcYsT2jUI3ay5z7nNL66ROASsOf0l9G7iMxvk8oPN0Y3BPZdaAvy+d5eFiuXG/atAn33nuv+feuXbsiPz+/7XtIRERE1A5kGqKk48vI/ZL0JcivsnyPifaLViP3EuBH+0fbtJ+dSmUh8Ntn2vJ4xccs7b2maKP3vacCXJ7QZsH9lvQCVSl/6d5s5JVZgns/D1e1BJ4U1LukdwiDeyJHCvR79uypUvXj4uKQmZmJQ4cO4dJLLzVvP3HiBIKDeWWViIiI7FtWeZYqqLfo6CIcLTlqbu/i0QUzYmeoJfEGhQyCk5OTTfvZqZzcCWz7QJuDX1ef+u0ZYCmuF8wih7ZQpzdgS3qhSstfvjcb+eW15m3+nq6YNjACSQkRuLhXCDxcGdwTOWSg/+c//xl33323mpO/efNmVWV/wIAB5u2rV6/G0KFD26ufREREROestLYUK4+tVEvibc/Zbm53d3bHhOgJakm8i7teDDcXLu11weiqtar5kp4vVfRNIgZpS+PFXw24e9uyh52STm/ApqMFKiV/2d4cFFZYgvsu3m6YPiBCFdQb2zNELY1HRA4e6M+bNw8uLi5YuHChGsl//PHHG2w/deoUbrvttvboIxEREVGr6fQ6/HryV5Wav/b4WtQaLAHLyIiRKi1/avep8HP3s2k/O52iY1pxvZ2fAVWFWpuLOzDgCi3A7zYSYDbFBVVbZ8CGo/lqKbzl+3JQXKkzbwvyccf0gVpa/kVxwXBzYXBP5Ahata6FBPLNBfNvv/12W/WJiIiI6Jzn3e/J36NG7pdlLENxTbF5W8+Aniotf2aPmYj0jbRpPztlcb2jq7XR+0PLrIrrRQMj5mrF9XxDbd3LTqWmTo8NR/KxeE82VuzLRml1nXlbiK8E95KWH4nRPYLgyuCeyOFwAUsiIiJyeJmlmWqtexm9zyzLNLcHewYjKS5JFdbrF9SP8+4vNFkO77cvtBH8wjRLe9xEbfS+zwwW17uAqnV6rD+sjdyv2J+DMqvgPtTPA4nxEUiMj8SoHkFwceZnhahTBPqStt8Ser3+fPpDRERE1CJF1UVq1F6WxNuTt8fc7uXqhckxk1VwPypyFFydOa5xwWXtBrbOB1K+A0xLFXoEAENuAEbeAYT0snUPO1Vwv/Zgnppzv2p/LsprLMF9uL8E95Fq5H5490AG90QdiGtrUuG6d++OW265hUX3iIiIyCZq9DVqvr2M3P964lfUGbWgxdnJGRdFXqTm3UuQ7+3GIm4XXF0NsPdHrXr+ia2W9vAEYNQdQMI1gLuPLXvYaVTV6rHmYC6SU7Kw+kAuKmstA3GRAZ4quJ85KAJDowPhzOCeqHMH+lu3bsWCBQvw2muvoUePHmqu/o033ojAwMD27SERERF1agajATtydqjgfkXGCpTpyszb+gf1V8F9Yo9EhHpzjrdNFB8Htn8I7PwUqMzX2pzdgAGXa+n50aNZXO8CqKipMwf3aw7koUpnCe6junipZfASEyIxpFsXBvdEnUCLA/0RI0ao2yuvvILvvvsOH330ER544AHMnj0bt99+O6ZOndq+PSUiIqJO5WjxURXcy9z7rIosc3uET4QqqCcBfq9ApoDbrLhe+lpg6wfAoSWA0aC1+0cBw+cCw+YAfuG27mWHJ2n4q/bnYElKNtYeykW1rv44AIgO8kJSfVr+oG4BrE9B1Mm0etKap6cnbrrpJnVLT09XQf6MGTOQl5eHoKCgc+rEW2+9hf/85z/Izs7G4MGD8cYbb2DUqFHN3v/bb7/Fo48+ioyMDPTu3RsvvPACkpKS1DadTodHHnkEycnJSEtLQ0BAAKZMmYLnn38eXbt2bfA8ixcvxpNPPok9e/ao9zV+/Hj8+OOP5/QeiIiI6PzlV+UjOS1ZBfj7C/eb233dfDEtdpoK7oeHD1ep+mQDVcXA7v9q6fkFRyztPS4FRs4D+iYBLqyJ0J5Kq3VYvT8Xi1OysO5Qnloaz6R7sLcK7GcmRGJgV38G90Sd2Dn9JT5x4gQ+/vhjdausrMT9998Pf3//c+rA119/jfvuuw/vvvsuRo8ejVdffRXTp0/HwYMHERYWdtr9N27ciOuvvx7PPfccZs2ahS+//BJXXHEFdu7cifj4eNUf+bdcCJCLBkVFRbjnnntw2WWXYfv27ebn+f777zFv3jw8++yzmDRpEurq6pCamnpO74GIiIjOXaWuEqsyV6mR+01Zm1SqvnB1csUlUZeoJfHGdxsPT1dPW3e188pO1ZbG2/MNoKvU2tz9gCHXa8X1QvvauocdWkmVDiv35ai0fKmaX6u3BPdxIT4quE9MiMCASAb3RNTKQL+2thb/+9//1Dz99evXIzExUQXl8rOlFfmb8vLLL6uAe+7cuep3CfhlpP3DDz/Egw8+eNr9pUaAZBDIxQXx1FNPYcWKFXjzzTfVY2UEX363JtskQyAzMxMxMTEqqJfgX7IIJCPBZMCAAc32s6amRt1MSktLzRkEciPbMe1/HgfHxOPn+HgMHZ8tjqHeoMfWnK1ITk/G6hOrUWWqzA4gITgBST2SMC1mGgI962sBGXmOXfDjp6+F04GFcN7+IZxPbDE3G0P7wzD8NhhUcT1fUyfa9rU7maaOYXGlDisP5GLp3hxsPFoAnd5o3tYz1AeJA8MxY2A4+oT7moN7+Y5LtsH/Fjo+nYMcw5b2z8ko5fRbIDg4GH5+fqrq/s0339zkaLtozci+XDzw9vZWc/5lVN5EXqO4uBg//fTTaY+RQF0yAO69915z2+OPP65S7nfv3t3k66xcuRLTpk1Tzyn9k8KCkj0gFxNef/11NWVgyJAhKvCXrICm/Otf/8ITTzxxWrtkFMh7ICIiojOTrxxZ+izs1u3G7trdKDeWm7cFOQdhsNtgDHEfgmCXYJv2s7PzrC1EbP5qdC9YB8+6EtVmgAuyugxHeugUFPj0ZXG9dlKuA1IKnbCrwAmHSp1gMFr2c6SXEYODDRgabEQEv3oSdVqVlZW44YYbUFJScsbYu8Uj+pICLzcZQX/66aeb/I+3XE3U6y0VPs8mPz9f3T88vGGxFvn9wIEDTT5GgvKm7i/tTamurlZFAyXd37QjZO6+KXiXjILY2Fi89NJLmDBhAg4dOtRkrYGHHnpIXWCwHtGPjo5WFxDOddoCtd1VLcnikIKQbm5utu4OtRKPn+PjMXR87X0MsyuysSRjCZIzknG0/Ki5PcA9ANO6T0NSbBIGhQxiyrEtj598jzu2Xo3eOx1aAiej9n3O6BsOw9BbYBh6M8L8ItH0MA+dj4LyGixNzcaXv+7H0VIX6K3G4PqF+2JGfIQauZdRfLJf/G+h49M5yDE0ZZafTYsD/TVr1sARD9a1116rLkK888475naDVIoF8M9//hNXXXWV+resItCtWzdV6O/OO+887bk8PDzUrTE5Cez5ROhMeCwcG4+f4+MxdHxteQzLasuw8thKLExbiO3Z22GU3HuZ1u3sjvHR4zE7braaf+/mwnPGpsevuhTY/ZVWXC//oKW9+yXAqDvg1G8WXFzccO6TNKkpuWXVWLZXquVnYXNaAQzq4yEFJo2qiJ6acx8fgbjQ+qkR5DD430LH52bnx7ClfWtxoC8V6dtaSEiImt+fk5PToF1+j4iIaPIx0t6S+5uC/GPHjmH16tUNRt0jIyNPm5MvQXxcXJyax09EREStpzPosOHkBlUxf+3xtajRW2rbjAgfoSrmT42dCn93ZsLZXM4+rbje7q8BXYXWJvPtB/8eGHE7EN583SI6N7ml1ViSmq0K6m3NKJQkCrOEKH/EuhThnqvGo1d4gC27SUQdRIsC/YqKCvj4tDxdqKX3d3d3x/Dhw7Fq1SrzHH0ZbZff77777iYfM2bMGLXdeo6+pFhIe+Mg//DhwyoTQeoLWJPXlMBeKvtfcskl5sfIcn3du3dv8fskIiLq7CRrbk/+Hiw6ughLM5aiuKbYvC0uIA6ze85WhfW6+jZc4pZsQK8D9i/URu+PbbC0h/QFRs0DBl0HePIiTFvKKqlSafkS3G8/VtQguB8S3QVJCRFIjI9EhJ+bWhq6exAn3xPRBQz0e/XqparUS5E802h4U/+hl6J3Muf90ksvVXPaW0LmvcvzjhgxQlXGl0r+cqHAVIV/zpw5iIqKUsvpCemHZBfInPqZM2fiq6++Usvmvf/+++aA/eqrr1ZL7C1atEjVADDN35e593JxQUb3//jHP6oifjLPXoJ7KcQnrrnmmhb1m4iIqDM7XnpcjdzLLbPMkg0X7BmMxB6JKsDvH9Sf8+7tQWkWsONj7VZeX9PIyQXoN1ML8GPHsbheGzpVXKUCexm933GsqMG2YTFd6pfCi0RUFy9zu71X+SaiDhror127Fg8//LAqXidr00tQ3rVrV3h6eqoCffv27cOmTZvg6uqqAvym5rg357rrrkNeXh4ee+wxc/X7pUuXmgvuSSq9s7PMWdKMHTtWVbp/5JFHVJ969+6tKu6bquWfPHkSP//8s/q3PJc1Gd2XgntCAnvpr6wgUFVVparwS4p/YGD9Mj5ERETUQHF1MZZlLFPz7nfnWVa68XL1wqSYSSo1/6LIi+Dq3OKZgdReZOg441ctPX//IqC+uB58w4HhtwLDbgEComzdyw7jeGEllqRmITklG7uOW7Ja5PrJiO6BatRe1rmPDLAE90RE7alF/yXu27cvvv/+exV0S7G69evXY+PGjSpAlnn2Q4cOxfz585GYmKjm3LeWpOk3l6ovFxkak1H35kbepYJ+S1YMlCIGL774oroRERFR02Se/brj69TI/fqT61Fn0NbpdnZyVkG9BPeTYybD240px3ahpqy+uN4CIG+/pT1mrCquh36zAVd3W/aww8gsqESyCu6zsOeEtgyhKbgfFRukRu6lYn64v6dN+0lEnVOrLrnLGvZ///vf1Y2IiIg6JoPRgJ05O1VwvzxjOcp0ZeZt/YL6qeBe0vPDvLnYmr3wqzoJ56UPACnfALX1x8vNBxh0LTDyDiBCy3yk85OeX6ECe7ntPWVZ4srZCRjdIxhJgyIxfWA4wvwY3BORbTG3joiIiJS0kjQsy1yGxWmLcarilLk93DscM+NmqgC/d2Bvm/aRrOjrgIOL4bLlfUw69qulPbi3FtwPuR7wZAX383U0rxzJe7KQnJqN/VmW4N7F2Qlj4oLVyP20geEI8T19GWYiIlthoE9ERNSJ5VflY9GRRfhv2X9xarEluPd188XU7lNVcD8iYoRK1Sc7UZYD7PwE2P4RUHaqfvV1Jxj7JMJ59B+AuAksrneeDueUqfn2MnJ/MMeS0eLq7ISxvUKQFB+BaQMjEOTDaRBEZJ8Y6BMREXUylbpKrD6+WqXmbz61Gfr6Qm2uTq64JOoSzOw5ExO6TYCnK9OP7YbUH8rcBGyV4no/A/W1EuATCv2Qm7GyOBqTrrgZzm5utu6pQ5L6TgetgvsjueXmbW4uTrhYgnsZuR8Qji7eDO6JyP4x0CciIuoE9AY9tmRvUevdr8xciaq6KvO2+OB4xFbG4m+Jf0OYH+fd25Wacm3evRTXy0m1tEePBkbOAwZcBoPRGdXJybbspcMG9/uzJLiXtPwspOVVmLe5uzhjXG8tuJ/SPxwB3ryAQkQdONCvq6vDs88+i9tuuw3dunVrv14RERFR24xSFh1UwX1yejLyqvLM27r5dsOsnrNUan5Xr65ITk5GoCeXmLUb+YeBbR8Au74Eaurnhbt6AYOu0QL8yEGW+3IN9lZ9JqSI3mJZ5z4lCxkFleZt7q7OGN8nFEkJEZjcPxz+ngzuiaiTBPqy7rysPz9nzpz26xERERGdl+yKbFVQT1LzjxQfMbcHeARgRuwMFdwPDh0Mp/p53DoGivZTXO/QUmDbfCDNannhoLj64no3AF68GHMuwb0sfyej9ktSspFZaAnuPVydMaGvBPeRmNQvDH4M7omos6buT5o0CevWrVPr1RMREZF9KK8tx4pjK1Rwvy17G4wwqnY3ZzdMiJ6ggvtxUePg5sJAxu6U59YX1/sYKD2htUnxwz4zgJG3A3GTAGcWQ2xtcL/reHH9UnjZOFlsmari6easgnoJ7if2DYOPB2eyElHH0+q/bImJiXjwwQeRkpKC4cOHw8fHp8H2yy67rC37R0RERM3QGXTYeHIjFqYtxNrja1GjrzFvGx4+XAX302Knwd/d36b9pGaK6x3fqo3e7/0RMNRnVXgHA8PmAMPnAoHdbd1Lh2IwGPHb8SIs3pONpalZOFVSbd7m7e5iDu5lBN/bncE9EXVsrf4rd9ddd6mfL7/88mnbJAVQr9cq9xIREVH7jFSm5Keokful6UtRVFNk3tYjoAdmx81GUlwSonyjbNpPakZtJZDyrRbgZ6dY2qNGAKOkuN4VgBtXO2hNcL/9WJEauV+amo3sUktw7+PugikDwpEYrwX3nm4uNu0rEZFdB/oGg6F9ekJERETNOl52XAX3Mvf+WOkxc3uQZxCSeiSpwnoDggaY592TnSk4Wl9c7wugukRrk+ULE67W5t93HWrrHjoMvcGIremFWJKqBfe5ZZZMFj8PVxXcy8i9VM1ncE9EnRXzloiIiOxUcXUxlh9bjoVHF2JX3i5zu6eLJybFTMLsnrNxUeRFcHXmf87tkkEPHFqmjd4fXW1pD4ytL653I+AdZMseOow6vUEF91Itf9nebOSX15q3+Xu6YuqACFUt/5LeIfBwZXBPRHRO3wykGN+LL76I/fv3q98HDBiA+++/H+PGjWvr/hEREXUqtfparDuxTi2J98vJX1BnqFPtzk7OGB0xWo3cT46ZDB+3hjVyyI5U5AM7PwW2fwSUZNY3OgG9p2np+T0ns7heC+j0BmxOK1DF9JbvzUZBhSW4D/Byw/SB4UhMiMTFPUPU0nhERHQegf7nn3+OuXPn4ne/+x3++te/qrYNGzZg8uTJ+Pjjj3HDDTe09imJiIg6NYPRgN9yf1Mj9zKCX1ZbZt7WN7CvGrlP7JGIMO8wm/aTzlJc7+QOYKsU1/sB0NcHpbIc3tCbgRG3AUE9bN1LhwjuNxzJV8vgLd+XjaJKy9KPgd4S3MvIfSTG9AyGmwuDeyKiNgv0n3nmGfz73//G3/72N3ObBPxSnO+pp55ioE9ERNRCaSVpauRe5t2fqjhlbpeAfmbcTFU1v09gH5v2kc5CVwWkfq8F+FmW6RVqzv3IeUD87wA3L1v20O7V1mnBvaTlr9iXg5IqS3Af7OOO6fERmJkQidE9guDK4J6IqH0C/bS0NMyePfu0dllW7+GHH27t0xEREXUq+VX5qlq+LIm3r2CfuV1S8ad2n6qq5svSeC7OnGds1wrTgG0LgN8+B6qLtTYXDyD+KmDUHUDUcFv30K7V1Omx/lA+klO14L6sWpuiIkJ8PZAYH4HEhAiM7hEMF2cWmCQiavdAPzo6GqtWrUKvXr0atK9cuVJtIyIiooaq6qqwOnO1qpq/6dQm6I3aUrSuTq64OOpiNXI/IXoCPKUKO9l3cb0jK7XRe/kJo9beJQYYcbuWou8TbOte2q1qnR7rDuVhSUoWVu7PRXmNJbgP89OCe0nLHxEbxOCeiOhCB/p///vfVar+rl27MHbsWPMcfZmf/9prr51vf4iIiDoEvUGPrdlbVXC/8thKVNZVmrclhCSo4H5GjxlqeTyyc5WFwG+faSP4xZalDdFripae33sqwAyMJlXVSnCfi8Up2Vi9PwcVtdpFLhHh76lG7SUtf1hMIJwZ3BMR2S7Q/9Of/oSIiAi89NJL+Oabb1Rb//798fXXX+Pyyy9vu54RERE5oIOFB1Vwn5yWjNyqXHN7lG+UCu7lFhsQa9M+Ugud3Als+0Cbg19XrbV5BliK6wX3tHUP7VJlbR3WHMhDckoWVh/IRZXOEtxHdfGqT8uPxNDoLgzuiYjsIdCvq6vDs88+i9tuuw2//vpre/WJiIjIoWRXZCM5PVkF+IeLDpvb/d39MSN2hloSb0joEDg5Maixe7pqrWq+BPhSRd8kYpC2NF781YC7ty17aJcqauqw6kCuSstfczAX1TqDeVu3QC+Vki+3wd0C+DkgIrK3QN/V1VVV3J8zZ0779YiIiMgBlNeWY2XmSlU1X1L0jfXztd2c3TC+23gV3I+LGgd3F3dbd5VaoigD2P4hsPMzoKpQa5NjN/BKLT2/2wiAAWoDZdU6NWK/eE+WmntfU2cJ7mOCvFVgL2n58VH+DO6JiOw9dX/y5MlYt24dYmOZdkhERJ2LzqBTxfRkvfs1x9egRl9j3jYsbJgK7qd1n4YAjwCb9pNayGAAjq4Gts0HDi2zFNcLiAZGzAWGzgF8Q23dS7siS9+t2p+j0vJ/OZSPWr0luO8R4oOkhAgkxkdiYFcG90REDhXoJyYm4sEHH0RKSgqGDx8OHx+f05bZIyIi6iiMRiNS81NVWv7SjKUorK4f7QUQ6x+L2T1nqzXvZQ4+OVBxvV1faMX1itIt7T0nASPvAPrMYHE9KyWVOizfl40lqdlYfzgPOr3RsstCfdSovcy57xfhx+CeiMhRA/277rpL/Xz55ZdP2yZ/3PV6S8EVIiIiR3Wi7IQK7henLUZGaYa5XarkJ/VIUkX1BgQPYGDjSE7t0kbvU6S4XpXWJtkXQ2/UlscLabh0cGdWVFGrgvvklGxsOJKPOoMluO8T7qtG7WcOikTvMF9+BoiIOkKgb5A0NyIiog6opKYEyzKWqQD/t9zfzO2eLp6YGDMRs+Nm46KuF6l5+OQg6mqAvT9qAf6JbZb28ARg1B1AwjWAe8PsxM6qoLwGy/dpafkbjxZAbxXcy2i9VlAvAr3C/GzaTyIiauNAX6fTwcvLC7t27UJ8fHxrHkpERGSXavW1+OXELyq4l58yD184wQmjI0erkfsp3afAx43BoEMpPl5fXO9ToDJfa5MLNAMu16rnR49mcT0AeWU1WLZX0vKzsDmtsEFwPyDSX43az4iPQM9QX5v2k4iI2jHQd3NzQ0xMDNPziYjIoRmMBjViL8G9jOCX1ZaZt/UN7KuC+8QeiQj3CbdpP6mVJOswfS2w9QPg0BLAWJ+F6B8FDJ8LDL8F8A1DZ5dbWo2leyUtPwtb0wthFdsjISoAiQkRSIqPRGwIL24REXWa1P1//vOfePjhh/HZZ58hKCiofXpFRETUDtJL0lXFfFnz/mT5SXN7mFeYKqgnVfP7BPaxaR/pHFQVA7u+BLYvAAqOWNp7jNdG7/skAi6t/srToWSXVGNpapaac7/tWCGMVsH94OguSIqPUKn50UHetuwmERG1kVb/V+/NN9/EkSNH0LVrV3Tv3v20qvs7d+5sq74RERGdt4KqAlUtXwL8vQV7ze3ert6Y2n2qCu5Hho+EC6usO57sFGCrFNf7FtBVam0e/sDg67Xq+aGd+6LNqeIqVSl/SUoWth8rarBtaEwXVS1f0vK7BTK4JyJCZw/0r7jiivbpCRERURupqqvCmsw1KjV/46mN0Bu1KWcuTi64OOpilZo/IXoCvFy9bN1Vaq26WmD/z1qAf3yzpT1sgBbcD7oO8Oi888lPFFViSUo2klOz8FtmcYNtI7oHqmXwEuMj0LULz30ioo6s1YH+448/3j49ISIiOg96gx7bcrapkfuVx1aisq5+hBdAfHC8GrmfETsDwV7BNu0nnaOSk8COj4AdnwAVuVqbsyvQfzYwch7QfWynLa6XWViJVSedsODdzdhzstTcLrtjZGyQSsufER+JiABPm/aTiIjsMNDfunUrhg8fDheXplMba2pq8NNPP+Haa69ty/4RERGd0cHCg2qt+8Xpi5FbWR8AAojyjdLm3cfNQo+AHjbtI50jmUievg7Y9gFwIBmoz8yAX6SluJ5fBDqjjPwKNWovBfVSVXAv389K4ewEjOoRpNLypw+MQJg/g3sios6oxYH+mDFjkJWVhbAwrVqtv7+/WmYvLi5O/V5cXIzrr7+egT4REbW7nIocVVBPUvMPFR0yt/u7+2N67HQV3A8NGwqnTjrC6/CqS4Hd/9UC/HzL8UXsOC09v99MwMUNnU1aXrkK7KWg3r4sy8i9BPe9/A24afxAJCZEIdTPw6b9JCIiBwr0jdblWZv4vbk2IiKitlChq8CKYytUcL81ayuM0P6b4+bshvHdxqvgfly3cXB3cbd1V+lc5ewDts0Hdn8N6Cq0NndfYPDvtQA/rD86myO5ZSqwlwD/QLZlGUgXZyeM7RmsKuVP7BOMLetWImlktFoKmYiIqE3XmuHICRERtSWdQYdNpzZh0dFFWHN8Dar11eZtw8KGqXn307pPQ4BHgE37SedBr9OK621bABzbYGkP6astjSfF9Tz90VnIoMmhHNPIfRYO55abt7k6O+GS3iFqjfupA8IR6KNd1NLpdDbsMRER2aPOvagsERHZZaAjy+DJyP2S9CUorC40b4v1j1Uj9zL3vptfN5v2k85T6Slgx8farTxHa3NyAfrP0orrxV7SaYrryTkvo/Wm4P5oXn02g2SsuDhhXO9QNXI/tX84Arw5Yk9ERG0c6O/btw/Z2dmW/ygdOIDycu1Kc35+fmueioiIqIETZSdUUT0J8DNKM8ztQZ5BSOyRqAL8gcEDmT3myGSKX8avWnr+/kWW4nq+4cDwW7Wbf1d0mgtap0qxRBXUy0Z6viW4d3dxxqV9JLiPwGQJ7r0Y3BMRUTsG+pMnT24wD3/WrFnqp3zpknZ++SIiotYoqSnBsoxlKsDfmbvT3O7h4oFJ0ZNUav6YrmPUPHxyYDVlwO6vtPT8vP2W9pixwCgprjcbcO34tRXku1LKyRIV2EuAf6zAsgSku6szJvQJxcxBkZjULwx+njzniYjoAgT66enp5/EyREREmlp9LdafWI+FaQvxy4lf1Dx84QQnjIocpUbup8RMga8UYSPHlntAq5wvQX5tfSE5Nx9g0LXa/PvwgegMwf3uEyXmtPwTRVXmbZ5uzpjYN0wrqNcvDL4enFFJRERto8X/RenevXsbvSQREXUUeoMe23O2Y3ftboTlhGFU11FwcZb1vE8Pdn7L/U2l5csIfmmtZWmw3oG9MTtutkrPj/DpnGuid7jiegcWawF+xnpLe3BvLbiXCvqeHbt4osFgxG/Hi1VgvzQ1GyeLLcG9l5sLJvUPUwX1JvYLhbc7g3siImp7/K8LERGdk5XHVuL5rc8jp1IrpPbtqm8R7h2OB0c9iCndp6i29JJ0FdxLav7J8pPmx4Z5hamCenLrG9TXZu+B2lBZNrDjE2DHR0BZltbm5Az0TdIC/B7jO3RxPQnud2QWmYP7rBLLChE+7i5qrr3MuR/fJwxe7qdfDCMiImpLDPSJiOicgvz71t5nXsveJLcyF39b+zdc2etKHC46jNSCVPM2b1dvdQFgds/ZGBk+ssmRf3IwUrcncxOwVYrr/QwY6rR2n1Bg2C3AiLlAQMddHUFvMGJ7RqEK7pekZiO3rMa8TdLwp8jIfUKkKqzn6cbznYiILhwG+kRE1Op0fRnJbxzkC1Pb/478T/10cXLB2K5j1bz7iTET4eXqdcH7S+2gphxI+QbY+gGQu9fSHj1aWxpvwGWAqwc6ojq9AVvrg/ulqTnIL7cE936ermp9e0nLH9cnBB6uDO6JiKgTB/pvvfUW/vOf/6il+wYPHow33ngDo0aNavb+3377LR599FFkZGSgd+/eeOGFF5CUlKS26XQ6PPLII0hOTkZaWhoCAgIwZcoUPP/88+ja9fQle2pqajB69Gjs3r0bv/32G4YMGdKu75WIyNFJdXxTuv6ZXN/vevxh0B8Q4hVyQfpFF0DeIWD7AmDXl0BNfZ0FN28g4Rpg5B1A5CB01OB+c1ohklOzsCw1GwUVteZtsvTdNAnuEyIxtlcwg3siIrILNg/0v/76a9x333149913VcD96quvYvr06Th48CDCwsJOu//GjRtx/fXX47nnnlPL+3355Ze44oorsHPnTsTHx6OyslL9Wy4EyEWDoqIi3HPPPbjsssuwffv2057vH//4h7oAIIE+ERGdXV5lXovuNyR0CIP8jkBfBxxaoqXnp6+ztAf11IL7ITcAXl3Q0ej0Bmw8WoAlKVlYtjcbRZXa6hCii7cbpg+IQNKgSIyJC1ZL4xERETlcoD906FA4tbCAjgTZrfHyyy9j3rx5mDt3rvpdAv7Fixfjww8/xIMPPnja/V977TXMmDED999/v/r9qaeewooVK/Dmm2+qx8oIvvxuTbZJhkBmZiZiYmLM7UuWLMHy5cvx/fffq38TEdGZHSo6hO8Ofdei+4Z6h7Z7f6gdlecCOz8Btn8MlJ6wFNfrM0ML8OMmAs4dK8CtrTNgw9F8JO/JwvJ9OSipsgT3QT7umD4wAjMTIjE6LghuLh3rvRMRUScM9GXE3KS6uhpvv/02BgwYgDFjxqi2zZs3Y+/evbjrrrta9eK1tbXYsWMHHnroIXObs7OzSrXftGlTk4+RdskAsCYZAD/++GOzr1NSUqIuVHTpYhlxyMnJURcY5HHe3t5n7auk+MvNpLS01DxVQG5kO6b9z+PgmHj8HMP+wv34IPUDrDmx5qz3dYITwrzDkBCYwOPqaJ/D2lo4ndgK5+0L4LT/ZzgZtHajdzAMQ26CYditQEC09iC9Xrs5uBoV3Bdg6d4crNqfi9Lq+oKCAEJ83TFtQBhmDAzHyO6BcDUF9wY9dAb7ee/8O+r4eAwdH4+h49M5yDFsaf9aFOg//vjj5n/fcccd+Otf/6pG0hvf5/jx463qZH5+PvR6PcLDwxu0y+8HDhxo8jEyj7+p+0t7U+TCxAMPPKDS/f39/c3rOd9666344x//iBEjRqi5/mcjUwWeeOKJ09olI6AlFwqo/TXO5CDHwuNnn47XHcfa6rU4WHfQHMQPcBuAaJdoLK1e2uRjpCDfJEzCsqXLLnBv6Vy56GvQvWgjat98BN5Vmeb2Qu+eSA+dglNdRsJQ5Q5sSAEgN8emMwAHip2wq8AJqUVOqNZbshb93YwYHGTEkGAD4vzr4OyUgaIDGVje9NcSu8K/o46Px9Dx8Rg6vhV2fgxlqnq7zNGXQnhNzXW/6aabVNAsKff2dLXj2muvVYH9O++8Y26XYn9lZWUNMgnORu5rnUkgI/rR0dGYNm2a+QIC2e44ywdy6tSpcHNzs3V3qJV4/Oy34J6M4G/O3qx+d3ZyxvSY6bg9/nbEBcSptsnHJ+M/O/6jltQzCfcOx/8N/z9Mjp5ss75TKxQehfOOD+G8779wqi+uZ3T1hHHgVdAPnwu/yCGQ8nodocRetU6PXw7nY0lqDtYczENFrWVEPtzfA9MHhCMxPhzDorvA2bll0xXtBf+OOj4eQ8fHY+j4dA5yDE2Z5W0e6Ht5eWHDhg2q2r01afP09GzVc4WEhMDFxUWl0VuT3yMiIpp8jLS35P6mIP/YsWNYvXp1g2BcfpcpAB4eDZf+kQsVN954Iz755JPTXlfu2/j+Qk4Cez4ROhMeC8fG42d7clF0S/YWvLf7PWzP2W5eHk+Wxrsj4Q7EBsQ2uP+MuBmYGjsVW09txYpNKzB1zFSM6joKLs6sOm7XJOX80DJg23zg6Gpzc7l7GLzG/Rkuw+fAyTsIHWEGemVtHdYezFNL4a0+kItKq+C+a4AnEhMikZQQgaHRgQ4X3DeFf0cdH4+h4+MxdHxudn4MW9q3Vgf69957L/70pz+ponumJfC2bNmiRvKl0n1ruLu7Y/jw4Vi1apW5DoDBYFC/33333U0+RuoCyHbph4lceTHVC7AO8g8fPow1a9YgODi4wXO8/vrrePrpp82/nzp1Ss3zlxUApPI/EVFnC/B/Pfkr3tvzHnbnaSuQuDq74opeV6gR/G5+3Zp9rAT1I8JHINc9V/1kkG/HKvKBnZ8C2z8CSkzp+U5A72moGzYXqw5WI+miWXCx4y83LVFRU6eC+iWpWVhzIA9VOktwH9XFCzMHRSIxPgKDuzneyD0REVFLtTrQl0r4cXFxqvr9559/rtr69++Pjz76SAXXrSXp8LfccosaTZcLB7K8XkVFhbkK/5w5cxAVFaXmyAtZKm/8+PF46aWXMHPmTHz11VdqKsH7779vDvKvvvpqdSFi0aJFqgaAaf5+UFCQurhgXXlf+Pr6qp89e/ZEt27Nf6ElIupoAf6a42vw/p73sbdgr2pzd3bH73r/Drcn3I4In6Yzq8iBGI3Aie3a6P3e/wH6+vXfvYKAYTcDI24DAmNhlMI+h5LhqMpr6rBqf44auZcRfCmwZxIT5I3EBK1afkJUQItXESIiIupUgb6QgP5cgvqmXHfddcjLy8Njjz2mAvIhQ4Zg6dKl5oJ7siSeVOI3GTt2LL788ks88sgjePjhh9UUAqmcHx8fr7afPHkSP//8s/q3PJc1Gd2fMGFCm/SbiMhRGYwGrDi2QgX4slye8HTxxDV9r8HcgXO5LF5HoKsCUr7TAvwsLUtD6ToMGDUPGHgl4OYFR1ZarVPB/eI92fjlcJ5aGs8kNtgbSSotPxIDu/ozuCciok7nnAL94uJifPfdd0hLS8P//d//qZFyGUGX4FxG31tL0vSbS9Vfu3btaW3XXHONujUlNjZWjVK1xrk8hojI0egNeizNWIr5e+bjaMlR1ebt6o3f9/s95gyYg2CvhtOcyAEVpgHbFgC/fQ5UF2ttLh5A/FXAqDuAqOFwZLKu/Yp9OViSkoX1h/NRq7cE93GhPmrUPjE+Ev0j/RjcExFRp9bqQH/Pnj1qnfuAgAC1LJ0styeB/g8//KBG3z/99NP26SkREZ0TnUGHxWmL8UHKBzhWeky1+bn54Yb+N+Cm/jehi2cXW3eRzre43pGVwNb52k/UX7juEgOMuB0YejPg47gXcYora7F8n5aWv+FIPnR6y4X53mG+qqCeBPh9wn0Z3BMREZ1roC9z6mUN+n//+9/w8/MztyclJeGGG25o7dMREVE70el1+PHoj1iQsgAny0+qtgCPANzc/2Zc3/96+LtzaVCHVlkI/PaZNoJfrF3AUXpNBUbeAfSeCjhoccTCilos35uNxSlZ2HS0AHUGS3DfN9yvPi0/Ar3DLd9DiIiI6DwC/W3btuG99947rV1S9k1F74iIyHZq9DX44fAPKsDPqdSWIw3yDMItA2/BdX2vg4+bj627SOfj5A5g6wdA6veAvkZrk6yMoTcBI28HguLgiPLLa7BsbzaWpGRjU1oB9FbBff9If8xMiMCM+Ej0CtMK6BIREVEbBvqylnxpaelp7YcOHUJoKAs4ERHZSlVdFb49+C0+3vsx8qryVFuoVyjmxs/F1X2uhperYxdf69R01cDeH7T0/FM7Le2Rg4GR87Q5+O7ecDS5ZdVYlpqN5JRsbEkvgFVsj/gofzVyL3Pue4Tw4hQREVG7BvqXXXYZnnzySXzzzTfqd5kPJ3PzH3jgAVx11VWtfToiIjpPFboKfHXgK3y671MUVheqNlka7/b423Fl7yvhIcXYyDEVZQDbPwR2fgZUaccWLu5a1XwJ8LuNkP8Qw5HklFZjaaqWlr8to1CtAGgyuFuAmnOfFB+JmGDHu3BBRETksIG+rF8v69SHhYWhqqpKrWkvKftjxozBM8880z69JCKi05TWluLL/V/i8/2fo6SmRLVF+UbhjoQ7cHnPy+Hm4mbrLtK5MBiAo6u1pfEOLbMU1wuIBkbMBYbOAXwdK4Muq6RKpeQvSc3C9mNFDYL7IdFdVDG9GfERiA5icE9ERGSTQF+q7a9YsQIbNmzA7t27UV5ejmHDhqlK/ERE1P6Kq4vx2f7PVJBfritXbbH+sSrAT4pLgpszA3yHLa636wutuF5RuqW95yRt9L7PdIcqrneyWIL7LFUtf2dm/VJ/9YZ3D0RifIQavY/qwiklRERENg30dTodvLy8sGvXLlx88cXqRkREF0ZBVQE+2fcJvj7wNSrrKlVbz4Ce+MOgP2B67HS4OFAQSFZO7dJG71O+A+qqtTaPAGDojdryeCG94CiOF1aqUfvFKdnYfdwS3MvsgpHdg5CYEKHm3EcEeNq0n0RERB1dqwJ9Nzc3xMTEQK/Xt1+PiIiogdzKXHyU+hG+O/QdqvVaINg3sC/uHHwnJsdMhrOTs627SK1VVwPs/VEL8E9ss7SHJwCj7gASrgHcHaMA3bGCClVMT0buU05qU0iEsxMwqkeQKqg3fWAEwv0Z3BMREdlt6v4///lPPPzww/jss88QFBTUPr0iIiJklWdhQeoC/O/w/1BrqFVt8cHxKsAf3228KoZKDqY4s7643qdAZYHWJlMtBl6hpedHj3KI4nrp+RLca2n5e0+VNgjuL4oLNgf3oX4sBElEROQQgf6bb76JI0eOoGvXrujevTt8fBqOOOzcabXsDxERtdrxsuNYkLIAPx39CXWGOtU2NGwo7hx0J8Z2HcsA3xGL66WtAbZ9ABxaChgNWrt/lFZcb9gtgG8Y7N2R3HI1516q5R/ILjO3uzg7YWzPYJWSP31gOIJ9GdwTERE5XKB/xRVXtE9PiIg6uYySDMxPmY/FaYuhN2pTpEZGjMQfB/1R/WSA72CqioFdX2oBfuFRS3uP8cAoKa6XCLi0+j/DF9ShnDLzyP2hHK3wo3B1dsLFvUKQlBCBqQMiEOTjbtN+EhERUUOt/obx+OOPt/YhRER0BkeKjuD9lPexLGMZDPWjvTJyLyP4w8KH2bp71FrZKcBWKa73LaDTiibCwx8YfD0w8g4gtA/sldFoxIHsUiTvyUJyarYaxTdxc3HCJSq4j8TUAeHo4s3gnoiIyF7Z91ACEVEHdqDwAN7f8z5WHFthbpO59xLgJ4Qm2LRv1Ep1tcD+n7UA//hmS3vYAC24H3Qd4OELew3u92WVYnGmM159bQPSC+ovTgBwd3HGpX1CVFr+lAHhCPDi0o1EREQdMtCXivuvvPIKvvnmG2RmZqK2VisQZVJYWNiW/SMi6nBS81Px3u73sPbEWnPblJgpapm8/sH9bdo3aqWSE8D2j4CdnwAVeVqbsyvQ/zItPT9mjF0W15PgPvVkKZJTs9S8+wwV3MvqDZVwd3XG+D6hmJkQiUn9w+DvyeCeiIiowwf6TzzxBD744AP8/e9/xyOPPKKq8GdkZODHH3/EY4891j69JCLqAH7L/U0F+BtObVC/O8EJ02OnY96geegTaL/p3NSI0Qikr9NG7w8uAerrKcAvEhg+Fxh+C+AXAXsM7nefKFGBvQT4xwurzNs8XJ3R178OcycPxtT4rvD1YMIfERGRI2v1f8m/+OILzJ8/HzNnzsS//vUvXH/99ejZsycGDRqEzZs3469//Wv79JSIyAFJcLU9Zzve3f0utmZvVW0uTi5I6pGEOwbdgbiAOFt3kVqqugTY/ZVWXC//kKU9dpyWnt9vJuBiX6PfBoMRu04Uqzn3S1KzcbLYEtx7ublgUr8wJCZE4JK4QKxbtRxJgyLh5sYgn4iIyNG1+r/m2dnZSEjQ5o76+vqipKRE/XvWrFl49NFH276HREQOGuBvOrUJ7+15DztztWVHXZ1ccVmvy3BH/B2I9o+2dReppXL2AdvmA7u/BnQVWpu7LzD491qAH9bf7oL7nZlFSE7JxpLULGSVVJu3ebu7YHL/cCTFR2BC3zB4ubuodp1OZ8MeExERkc0D/W7duiErKwsxMTFqJH/58uUYNmwYtm3bBg8Prp1LRJ2bBPi/nPhFBfgp+Smqzc3ZDb/r/TvcFn8buvp2tXUXqSX0Oq243rYFwDFtqoUS2s9SXM/TH/ZCbzBixzEJ7mXkPgs5pTXmbZKGP7l/mKqWL3PvPd204J6IiIg6rlYH+ldeeSVWrVqF0aNH4y9/+QtuuukmLFiwQBXm+9vf/tY+vSQisnOyLN7qzNWqiv7+wv2qzcPFA9f0uQa3DrwV4T7htu4itUTpKWDHx9qtPEdrc3IB+s8CRs4DYi+xm+J6EtxvTS9Uwf3SvdnIK7ME934ermoJvMSESIzrHcLgnoiIqJNpdaD//PPPm/993XXXqZH9TZs2oXfv3pg9e3Zb94+IyK7pDXq1PJ6M4B8pPqLavFy98Pu+v8ecgXMQ4hVi6y5SS4rrZfyqpefvX2QprucbDgy/Vbv520cmRp3egC31wf2yvdnIL7esfOPv6YppAyOQlBCBi3uFwMOVwT0REVFndd4Vd8aMGaNuRESdSZ2hDkvSl6gR/IzSDNXm6+aL6/tdj5sH3IxAz0Bbd5HOpqbMUlwv74ClvfvFWnp+/9l2UVxPpzdg09EClZK/bG8OCisswX0XbzdMGxCu0vLH9gxRS+MRERERtTrQ//TTT8+4fc6cOefTHyIiu6bT67AwbSE+SPkAx8uOqzY/dz/c3P9m3ND/BgR4BNi6i3Q2uQfqi+t9BdSWa21uPsDg67QAP3ygrXuI2joDNh7NVyP3y/floLjSUiwvyMcd0wdqwf1FccFwc2FwT0REROcZ6N9zzz0NfpdKvZWVlXB3d4e3tzcDfSLqkGr1tfjf4f9hQeoCZFVkqbZAj0CVni9p+r5ShZ3su7jegcXa6H3Gekt7SB8tuJcK+p62vUhTU6fHhiMS3Gdj+d5slFbXWbrpK8G9pOVHYnSPILgyuCciIqK2DPSLiopOazt8+DD+9Kc/4f7772/t0xER2bWquip8f+h7fJT6EXKrclVbsGcw5sbPVYX2vN28bd1FOpOybGDHJ8COj4Ay7QINnJyBvknAqHlAj/E2La5XrdNj/eF8LEnJwor9OSizCu5D/Twwoz64H9UjCC7O9lEEkIiIiDrBHH0hhfikSJ9U4D9wwGqeIxGRg6rUVeLrg1/j470fo7C6ULWFeYepJfKu6n0VPF09bd1FOlNxvWMbtdF7WSLPUB88+4QCw24BRswFArrZNLhfdyhPpeWv2p+L8hpLcB/u74HE+EgV3A/vHsjgnoiIiGwX6KsncnXFqVOn2urpiIhsoqy2DP898F98tu8zFNcUq7auPl1xe8LtuKLXFXB3cbd1F6k5NeXAnq+BbQuA3L2W9uiLtNH7/pcBrrY5flW1eqw9mIvk1Gys3p+Ditr6yv4AIgM864P7CAyLCYQzg3siIiK60IH+zz//3OB3o9GIrKwsvPnmm7j44ovPtz9ERDZRUlOCL/Z/gc/3f66CfRHjF4M7Eu7ArJ6z4OZs++rr1Iy8Q9ro/e7/AjWlWptMqUi4Rpt/HznIJt2qrK3D6gO5WJKSrX5W6SzBfVQXLxXYyzr3Q7p1YXBPREREtg30r7jiiga/Ozk5ITQ0FJMmTcJLL73Uln0jImp3kpYvo/cyil+hq1BtcQFxmDdoHmbEzoCrc5slPlFb0tcBh5YAW+cD6ess7UE9teB+yA2AV5cL3i1Jw5egPnlPFtYeykW1zmDeFh3khaT6tPxB3QLUfz+JiIiI2kOrv8EaDJYvLUREjiq/Kh8fp36Mbw59owruid6BvXHnoDsxJWYKXJxdbN1Fakp5LrDzE2D7x0DpCUtxvT4ztAA/biLgfGEr0pdV69Rc+8UpWWruvSyNZ9I92FsF9hLgx0f5M7gnIiKiC4JDVUTUqWRXZKsK+t8f/h41+hrV1j+oP+4cfCcmRk+EswSNZH/F9Y5v0dLz9/4IGOrXlPcOthTX6xJzQbtUUqXDyn05WJKahV8O5aNWbwnu40J8VHCfmBCBAZEM7omIiMgBAv377ruvxfd9+eWXW/v0RETt4mT5SSxIWYAfj/wIXX2gOCh0kBrBHxc1jsGYPaqtAFK+1QL87BRLe7eRwMh5wMArAFePC9ad4sparNiXo6rl/3okHzq90bytZ6gPZsrI/aBI9A334/lEREREjhXo//bbb+qm0+nQt29f1Xbo0CG4uLhg2LBh5vvxSw4R2YPM0kzMT5mPRUcXoc6oLWM2PHy4CvAviryIf6vsUf4RYPsC4LcvgJoSrU2WM0y4Wgvwuw65YF0pqqjF8n3ZSE7JxoYj+agzWIL7PuG+Wlp+QiT6hPtdsD4RERERtXmgP3v2bPj5+eGTTz5BYGCgaisqKsLcuXMxbtw4/P3vf2/tUxIRtbm04jS8n/I+lqQvgcGopVVLYC8B/oiIEbbuHjVm0AOHlmrF9dLWWNoDewAjbweG3Ah4B12QrhSU12DZXi0tf+PRAuitgvt+EX5q5F7S8nuFMbgnIiKiDhLoS2X95cuXm4N8If9++umnMW3aNAb6RGRTBwsP4v0972PFsRUwQgvQJDX/D4P+gCFhF24kmFqoIr++uN5HQMnx+kYnoM90bfS+56QLUlwvr6wGS/dmY0lKFjanFcAqtsfArv7anPv4CMSF+rZ7X4iIiIgueKBfWlqKvLy809qlraxMW3uaiOhC21uwF+/vfh+rj682t02KnoQ/DP4DBgYPtGnfqInieie2A9vmA3v/B+hrtXavIGDYzcCI24DA2HbvRm5ptQruF+/JwtaM/2/vPsCjLNa3gd+7mx5SSAIJCSEhpEJC6AgooPSiNJEmTUSOR47YkOKxfR7FAvxtKKBSFBCkCCihSpEiPUCAJCQBQk1CS++7+10zL2kSFDDJtvt3XevyPnl3dzaTxH3emXnmpmxWCbH9XS+5FZ4X/Nwdq70tRERERAZN9AcMGCCn6YuR/TZt2sjYgQMHMHnyZAwcOLBKG0dE9HeOXzuOecfnYffl3fJYBRW6+3fH+IjxCHFT6oiQkSjMBU6uVhL8q8fL4t4tgDaiuN5AwNquWpuQkpEvp+RvjEnBoeSKyX2kryv6RHjJBN/XzaFa20FERERkVIn+3Llz8dprr2H48OGyIJ98EisrjBs3Dp988kl1tJGI6A6HUw5j3ol52H91vzwW2+L1atgLz0U8hwDXAEM3z3LotFAl74HPzT+gSnYGAjoCak3Fc24kAYcXANFLgPx0JaaxvV1cbxzg07Jam3glPU9Wyt94MgVHkm9V+FqLBq5yWn7PcC/Ur83knoiIiCw00XdwcMBXX30lk/qkpCQZa9SoERwdObWRiKqXXq+Xib1I8I+kHpExK5UV+jbqi2cjnoWfs5+hm2hZTq8HNk2BVeYVyPKGyV8Dzt5Az4+A0D5AwlZl9D5xW9ljXP2U5L75yGotrnfxZi42nUzBhpirOHYxvdyOMEArv9py1F4U1KvnYl9tbSAiIiIymUS/hEjsmzZtiuTkZHkLDQ2FugYKJhGRZSb4ey7vwdwTc3Hi2gkZs1JbYUDgAIyLGAefWj6GbqJlJvk/jRK9UzGeeRX4SSTxdYDcknouKiCwqzI9X9z/ecS/ily4kYsoOS3/Ko5fyqiQ3Lfxdysdufd0rt7lAUREREQmk+gvWLAA6enpeOWVV0pjzz33HL777jv575CQEGzevBm+vr7V01IissgEf8fFHbKKvii2J9hqbDEoaBDGho+Fl6OXoZtouVvhbZpyZ5Iv3Y6JJN/WRSmuJ0bw3apnOcX56zly1F6suz95ObM0rlYBbRu6o3fTeujRxBN1nZjcExERkeW450R//vz5mDBhQunxpk2bsHDhQnz//fcICwvDxIkT8e677+Lbb7+trrYSkYUQ+96L7fFEgn/m1hkZs7eyx1PBT2FM+Bh42HsYuomWLXkfkHnl7897cgEQ1LXKXz7pWrYctd8Qk4LYq2XJvUatQrsAdzklv0cTL3jUsq3y1yYiIiIyq0Q/ISEBrVrJVZjSunXr0K9fP4wYMUIef/DBB7IaPxHRgyrWFWPT+U345sQ3OJtxVsYcrR0xLHQYRjYeCTe76lvTTfdIlKk/v/fezi0pvFcFElKzEBWTIovqxaeWbeVqpVahfaAHeod7oXsTL7g52lTZaxIRERGZqnteVJ+XlwdnZ+fS43379qFjx46lxwEBAUhJSXmgRsyZMwf+/v6ws7ND27ZtcfDgwb88f+XKlbImgDg/IiICUVFRpV8TOwFMmTJFxkUdAW9vb4waNQpXrpSNPp0/f17uEtCwYUPY29vLYoJvv/02Cgtv7+VMRDVKq9diXdI69FvbD9N2T5NJvpO1E56PfB6bB23GpBaTmOQbWs4N4I85wFcPAbtm3Ntjann+o2Ub8SlZmL31DLrN3oVu//c7/m/bGZnkW2tU6BxSBx8/2RSH3uiK759pg6FtGjDJJyIiIrrfEX0/Pz8cOXJE3l+/fh2nTp1Chw4dSr8uknwXFxfcrxUrVsh1/2LbPpHkf/rpp+jRowfi4+NRt27dO84XFxiGDRuGGTNmoG/fvli2bBn69++Po0ePIjw8HLm5ufLfb775JiIjI3Hr1i1MmjQJTzzxBA4fPiyfIy4uDjqdDvPmzUNgYCBOnjyJ8ePHIycnBzNnzrzv90BED6ZQW4jVCavxVdZXSD+gjP662LpgVONRchTfycbJ0E20bDodcG4XcHQxELcB0N6+GKqxA0Tx1aLcuzxQpVTf92t/38l97NUsud5erLs/ey2n9Gs2GjUeCfJAr4h66BbmCRcH63/yzoiIiIjM2j0n+qNHj8YLL7wgE/zt27fLEfWWLVtWSMBFon2/Zs+eLZPskmn/IuHfsGGDLP43derUO87/7LPP0LNnT0yePFkev/fee9i6dSu+/PJL+VhxsUEclye+1qZNG1y4cAENGjSQjxe38rMRxIWFr7/+mok+UQ3IL87HmoQ1WHByAVJzU2VMjNiPaTIGQ0KGwMGa+5kblFh/H70UiP4eSL9QFq/XDGg5GggfBJzddbvqPv5UlE+l3PX88J6q64vk/tSVzNJ97s9dL5fcW6nRKbgOekd4oUuYJ5ztmNwTERERVWmi//rrr8vR8jVr1sDLy0tOny9v7969cqT9foip8mKWwLRp00pjYou+rl274o8//qj0MSJevvK/IGYArF279q6vk5GRAZVKBVdX1788x83t7lODCwoK5K1EZmZm6VIBcSPDKfn+sx+MX15xnhzB/z72e1zPvy5jdezqoLWqNab0nAIne2UEn31pANoiqBK3Qn1sCVRJ26DS62RYb+sMXfhg6JqNALyalp0f1AuqQQuh2TIdqqyypVF6Z29ou70PfVAv0ZF3Te5PXsnExpOp2HQqFRdv5ZV+zdZKjY5i5D7cE52D68DJrux/U/y5qD78O2ra2H+mj31o+tiHpq/IRPrwXtun0otPXAYi1s37+PjI2QDt2rWrcFFh165dOHDgwB2PsbGxweLFiytcVPjqq69kxf/UVGVksLz8/Hy5xEDMQFi6dGml7UhMTJSzE8RovphdUJl33nlHvsafiaUDDg4cfST6KwX6Auwv2I+9BXuRq1eme7uoXNDRriNa2LSAtYojtYbiWJCKBjd+lze74rK956/XCkGye2dccW0Nnfrua9/FMqjCtDNQF6RDZ+sKm7rB8oLtn4n/0yRnA8duqHH8pgo3C26P/AOwVuvRxFWPZu56NK6th+3fTwQgIiIiski5ubkYPny4HKguX0PvgUf0TZG42vHUU0/J0SMxLb8yly9fltP4Bw8efNckXxCzDsrPJBAj+r6+vujevftffoOpZvpZLNfo1q0brK2ZMBqTrMIs/Bj/I5bFL0NmoTILpn6t+hjbeCz6NuwLa401+88QivOhivtVjt6rk/eUhvWOdaBrOhS6yOFwcQ+CGL8vN4Z/h82nUjEjKg4pmWXLtrxu2OK/vUPl3vU6nR7HLmXIUftNp1NxNSO/9DwHGw0eDa6DHk3qolOwBxxszPp/R0aPv4emjf1n+tiHpo99aPqKTKQPS2aW/x2DfrLy8PCARqO5YyReHIvlAZUR8Xs5vyTJT05OljUFKkvGxYyCRx99FO3bt8f8+fP/sq22trby9mfih8CYfxAsCfvCeKTnp+P709/jx7gfkV2ULWP+zv4Y33Q8ejfsDSv1nX962H81IPUUcPR74PjyclvfqYDArkCLUVAF94TGygb3MqC+6eRV/Gf58Qqr8+VLZBZg4vLjeDSkjiysl5JZltw72mjkWvveEfXk2nt7Gw7dGxv+Hpo29p/pYx+aPvah6bM28j6817YZNNEX0/DFlPnffvtNVs4vmQYqjidOnFjpY8QUf/H1l156qTQmrryUn/pfkuQnJCRgx44dcHd3r3QkXyT54vUXLlxY6VRTIro/1/Ou4/tT32N5/HK5Hl8IdA3Ec02fQ3e/7tDcQ3E2qmIFWcDJNUrl/MtHyuIuvkDzpwGx9t7V976eUqvT491fTt+R5AslsR3x1+S9k60Vujb2RK9wL3QMrgM7a/4MEBEREVU3g8+VFNPhRUX/Vq1aycr4Yns9sc1dSRX+UaNGyXX8Yjs9QWyV16lTJ8yaNQt9+vTB8uXL5bZ5JSPyIsl/8skn5RZ7v/76K7Rardz6TxDF9sTFBZHkd+7cWW4VKNblX7umfCAV7jaTgIjuLi03DQtPLsSqM6uQr1VGcEPdQjGh6QQ81uAxqFW8kFajxIJ4kdQfWaQk+UW3K9mLmRQhvZXK+QGP3lNV/MocPHezwjT8u5ncIxjPPhIAWysm90REREQWlegPGTJEJtpvvfWWTMibNWuGTZs2wdPTU35dbIlXfrRdTLMXBfD++9//Yvr06QgKCpIV90u29hNJ/Pr16+W/xXOVJ0b3RYIvZgCIAnziVr9+/QrnGLA2IZHJuZp9Fd+d/E5ulVekUyqARnhEyAS/Y/2OcrcLqkG5N4ETK5Tp+Wmny+LuQXJqPiKHAbXq/OOXScv6+yRfqF/bgUk+ERERkSkk+mKEfNGiRXL6fFpampxqX55YD3+/xDT9u03V37lz5x0xUThP3Crj7+//t8n6mDFj5I2IHszFrIv4LuY7rEtah2JdsYy1qNtCJvjtvNsxwa9J4m/w+d3K1PzYXwBtoRK3sgea9FcS/AbtgCrqkzOpWVi499w9nVvXya5KXpOIiIiIqjnRF1PnRaIvps2LUXR+oCeyHOcyzuHbmG+x4ewGaPVaGWvj1Qb/ivwXWnm24t+DmpR5FTi2FIj+Abh1vizuFQG0GA1EDAbsXavs5VIz8zF7yxmsPHIRur+Z+CR+Crxc7NCmoVuVvT4RERERVWOiL9bE//TTT+jdu/f9PpSITFTCrQR8c+IbbDq/Cfrb5dY6eHfAhMgJaF63uaGbZzm0xUDiVmVq/pnNwO2LLbB1VhJ7MXrvXXHJ0j+VXVCMebuS8M3us8gvUmZwicJ6DwW44531p+Rx+by/5FLP2483hkbNCz9EREREJpHoi2J2gYGB1dMaIjIqsTdiMf/EfGy7sK001rl+Z1lFP6JOhEHbZlFungOilygj+FlXy+JiSr5I7hv3A2wcq/Qli7Q6LD94AZ9uS8CNHGU5QEu/2pjeO0zeC57OtrL6fvnCfGIkXyT5PcPrVWl7iIiIiKgaE/1XX30Vn332Gb788ktO0yUyUzHXYjDvxDzsurSrNNbNr5tM8EU1faoBxQXKmnsxen+urB/g4K4U1RMJfp2QKn9ZUeNk86lUfLwpDmevK9X6G3o4YkrPUPRo4lnh775I5rs19sIfiWnYsvsAuj/SFu0C63Ikn4iIiMjUEv09e/bI6vUbN25EkyZNYG1tXeHra9asqcr2EVENOpp6VCb4+67sk8diW7we/j3wXMRzCKzNmTw1Ii1WSe6P/wjk3bodVAGNHlOSe7E9npVNtbz0keRbmBEVi8PJyuu6O9rgpa5BGNqmAaw1lW+RKJL6tg3dcCNWL++Z5BMRERGZYKLv6uqKAQMGVE9riKjGiRHcQymHMPfEXHkvaFQa9Anog/ER4+Hv4m/oJpq/gmzg1M9Kgn/pYFnc2Qdo/jTQbARQ26/aXv789Rx8vDkOUTEp8tjOWo3xjwTguY4BcLKreDGXiIiIiMww0V+4cGH1tISIajzBFyP3YgQ/Oi1axqzUVujXqB/GRYyDr5OvoZto3sQ2oFeOAkcWAydXA4XZSlxtBQT3VCrnB3YB1NW3D/2N7AJ8sT0RS/Yno1inhxiMH9zSFy93C5Zr7YmIiIjIQhJ9IjL9BF+svRdF9mKux8iYjdoGA4MG4pnwZ1CvFouoVavcm0DMSmX0PvVkWdytkTI1X6y/d/Ks1ibkF2nx3Z5zmLszCVkFxTL2aEgdTOkVilAv52p9bSIiIiIy0kR/1apVcou9CxcuoLBQqcZc4ujRo1XVNiKqQjq9Dr9d+E0m+HE342TMTmOHJ4OfxNjwsajrUNfQTTTv0fvze5Tk/vQ6QFugxK3slIr5IsH36wBUc4FTrU6PNUcvYfbWM6WV8sN9nDG9VxjaB3pU62sTERERkREn+p9//jneeOMNjBkzBuvWrcPYsWORlJSEQ4cO4YUXXqieVhLRA9PqtNiSvEUm+InpiTJmb2WPoaFDMbrxaLjbuxu6ieYrKxU4vkxJ8G+eLYt7hitT85sOBuyVreqq264z12ShvbiULHns42qPyT1C8ESkN9QsoEdERERk2Yn+V199hfnz52PYsGFYtGgRXn/9dQQEBOCtt97CzZs3q6eVRHTfinXFiDoXhW9OfIPzmedlrJZ1LQwPG46RYSPhaudq6CaaJ50WSNymJPfxGwG9Vonb1AIinlQSfO/m1T56X+LUlQx8uDEOuxOuy2NnOytMfCwQo9r5w866+tb/ExEREZEJJfpiun779u3lv+3t7ZGVpYwOjRw5Eg899BC+/PLLqm8lEd2zIm0R1ietx7cx3+JS9iUZc7ZxxsjGI2WSL/5N1eBWMhC9RLllXSmL+7ZVpuY37g/Y1qqx5lxOz8OsLfH4OfqyXDlgo1FjVDs/meS7OlTP9nxEREREZKKJvpeXlxy59/PzQ4MGDbB//35ERkbi3LlzssgXERlGgbYAPyf8jAUnF+BqzlUZc7Nzw6jGo+Q0fUdrR0M30fwUFwDxUUrl/LM7xWJ8JW7vphTVazESqBtWo03KyCvCVzsTsXDveRQW62RMTM8X0/R93RxqtC1EREREZCKJ/mOPPYb169ejefPmcn3+yy+/LIvzHT58GAMHDqyeVhLRXeUV52HVmVVYdHIR0vLSZMzD3gNjm4yVhfYcrJncVblr8crU/OM/Ark3yuIBnZXR+9C+gJVtjTZJJPVim7wvtifgVm6RjLVt6IbpvcMQ6ctlGkRERESW5L4TfbE+X6dTRolE8T13d3fs27cPTzzxBCZMmFAdbSSiSuQW5WJ5/HIsPrUYN/OV+hieDp4YFzFObpVnq6nZRNPsFeYAp9YqCf7F/WVxp3pA86eVW23/Gm+WmEm1IeYqPt4Ujws3c2UssG4tTOsVisdC60JVQ7UAiIiIiMiEE321Wi1vJYYOHSpvRFQzsgqzsCx2GX6I/QEZBRky5lPLRyb4/Rr1g42G66+rjFiOdPWYMjU/ZhVQqNQkgUoDBPdURu8DuwKaB9qp9B87eO4m3o+KxfGL6fK4jpMtXukWjMEt68NKU/Z3moiIiIgsywN9Ot29ezfmzZsnt9UT0/Z9fHzwww8/oGHDhnj44YervpVEJJP6JbFLsPT0UmQVKQmnn7Mfno14Fn0C+sBabW3oJpqPvHQgZiVwdDGQElMWr91QWXffbATg5GWw5iWmZctK+ttiU+Wxg40GEzo2wviODeFgY5iLDkRERERkPO77E+Hq1atlhf0RI0YgOjoaBQUFMp6RkYEPPvgAUVFR1dFOIoslpuV/f+p7/Bj3I3KLlanZjVwaYXzT8ejp3xMaNbdIq7LR++R9ytT802uB4nwlLmZIhD0BtBwN+D0spjUZrIlpWfn4bFsClh+6CK1OD41ahaGtffFS12A5mk9ERERE9ECJ/v/+9z/MnTsXo0aNwvLly0vjHTp0kF8joqpxLfcaFp1ahJVnVsqCe0JI7RA81/Q5dPXrCrWKU7OrRHaaUlRPJPg3EsvidRsre943fQpwcDNkC5FTUIxvdp/F/N/PIrdQK2PdGntiSs9QuR6fiIiIiOgfJfrx8fHo2LHjHXEXFxekpyvrRInowaXkpMgt8lafWY1CXaGMNXFvgglNJ6Czb2cWV6sKOi2QtF2Zmh+/EdAVK3GxBWHEIKDFGMCnBWDg73WxVoeVRy5h9tYzuJalzJ4SFfSn9wpF2wB3g7aNiIiIiMwo0ffy8kJiYiL8/StWl96zZw8CAgKqsm1EFuVS1iV8d/I7rE1ci+LbiWdknUj8K/Jf6ODdgQl+VUi/AEQvBaKXAJmXyuI+rZSp+U0GALZOMDRRSX97XJpch5+Qli1jDdwc8HrPEPSJqMefBSIiIiKq2kR//PjxmDRpEhYsWCA/bF65cgV//PEHXnvtNbz55pv3+3REFi85MxnfnPgGv579FVq9Mi27lWcrTIicgLZebZnU/VPFhcCZjcrU/MTfRBqtxO1rA02HKsX1PJvAWJy4lI73N8TiwDlly0RXB2u8+FgQnn7IDzZWXK5BRERERNWQ6E+dOhU6nQ5dunRBbm6unMZva2srE/3//Oc/9/t0RBYrKT0J80/Mx6bzm6DT62SsXb12MsFv6dnS0M0zfdcTlKn5x34Ecq+XxRt2VNbeh/YFrO1gLC7ezMXHm+Pxy/Er8lgk9c90aIjnOzeCiz13VCAiIiKiakz0xejiG2+8gcmTJ8sp/NnZ2WjcuDFq1WJBKKJ7EX8zXib4W5O3Qn97dLlj/Y6yyJ6Yqk//QGEucHqdMnp/YV9ZvJYX0HwE0PxpwM24lhil5xbii+2J+OGPZBRqdbIswIDmPni1ewh8XO0N3TwiIiIiMkEPvOGyjY2NTPCJ6N6cunEK847Pw46LO0pjXRp0kQl+Y3f+Lv0jV48ryf2JlUBBhhITuxIE9QBajAKCugMa49pfPr9Ii8X7zmPOjkRk5is1GR4J8sDUXqFo4u1i6OYRERERkQm750++zzzzzD2dJ9buE1GZY2nHMO/EPOy5vEceq6BCd//uMsEPrh1s6OaZrvwMIGalkuCLRL+Eq5+y7r7ZCMDZG8ZGp9Nj/fEr+GRzPC6nK9smhno5YXrvMHQMrmPo5hERERGRJSX6ixYtgp+fH5o3by4rQhPRXzuUckgm+AeuHpDHYt/73g17Y3zEeAS4Gtf0cZMh/vZc2K8k96d+BoqVRBkaG2XNvaic798RUBtn0bp9idfxwcZYnLycKY/rudjJKfpiqr5GzaKLRERERFTDif7zzz+PH3/8EefOncPYsWPx9NNPw83NrYqaQWQexEWw/Vf3ywT/SOoRGbNSWeHxRo/j2Yhn0cC5gaGbaJpyrgPHf1QS/OtnyuJ1QpXCek2HAI7Gu698fEoWZmyMxc74a/K4lq2VLLI37uGGsLPWGLp5RERERGSpif6cOXMwe/ZsrFmzRk7PnzZtGvr06YNx48ahe/fu3AKMYOkJ/u7Lu2WCf+LaCRmzVltjQOAAPBPxDHxq+Ri6iaZHpwPO7lAq58dFAboiJW7tAIQPVBL8+q1FhVAYq5SMfMzeGo9VRy5Bpwes1Cq5Td5/HguEey1bQzePiIiIiMzUfVWnEtvoDRs2TN6Sk5PldP5///vfKC4uxqlTp1h5nyyO2BZPFNcTVfRP3zgtY7YaWzwZ/CTGNBkDL0cvQzfR9GRcAqKXAtFLgIwLZXHvFsrU/CYDATtnGLOs/CLM23UW3+45i/wiZevE3hFeeL1HKPw9HA3dPCIiIiIycw9chlqtVstRfDGSqdVqq7ZVREZOq9Ni64WtMsFPuJUgY/ZW9hgSMgSjm4yGh72HoZtoUlT6YqjiNgAnlgKJ2wC9khzDzgVoOlQprucVAWNXpNXhx4MX8Nm2BNzIKZSxVn61Mb1PGFo0qG3o5hERERGRhbivRL+goKB06v6ePXvQt29ffPnll+jZs6dM/InMXbGuGBvPbcQ3Md/gXMY5GXO0dsTw0OEY2XgkatsxmbsvN5KgPrwI3U8uhtWx29viCf6PKNvihT0OWBv/XvLigufmUyn4aFM8zl3PkbEAD0dM6RWK7o09ubSJiIiIiIwz0RdT9JcvXw5fX1+51Z4ozOfhwVFLsgxFuiL8mvQrvo35FheylOnkTjZOGBk2EsPDhsPFlvue37OiPOD0eqWwXvIeiFJ04qZ3rAtVs+FKgu/eCKbiSPJNfBAVhyPJt+SxRy0bTOoajKGtfWGt4QVQIiIiIjLiRH/u3Llo0KABAgICsGvXLnmrjBjxJzIXhdpCrE1ci+9ivsOVnCsy5mrrilGNR2FY6DDUsmFdinuWEqMk9ydWAPm3R+9VaugadcEhbWO0GDIV1nYOMBVi5P7jTXHYeDJFHttZqzH+kQBM6NRIVtUnIiIiIjKUe/40OmrUKE4/JYuRX5yP1QmrseDkAqTlpsmYu527LLD3VMhTcBCV3+nv5WcCJ1crlfOvRJfFXRoo6+6bDYfWwRMpUVGAxhqm4EZ2AT7/LQFLD1xAsU4PtQp4qpUvXu4WDE9nO0M3j4iIiIjo3hN9UWGfyNzlFuVi5ZmVWHhyIW7k35Cxug518Uz4MxgUNAh2Vkzk/pZeD1w8qIzen1oDFOUqcbU1ENpHqZzfsLOo6KnEi25vm2fk8gq1WLD3HL7emYTsgmIZezSkDqb2CkOIl5Ohm0dEREREVIrzS4kAZBdmY3n8cnx/6nvcKlDWWns7emNcxDj0D+wPG42NoZto/HJuACeWKwn+tbiyuEewsud95FDA0fTqemh1eqw+egmzt5xBSma+jIX7OGN6rzC0DzS990NERERE5o+JPlm0jIIMLItdhiWxS5BZmCljvk6+GB8xHn0b9YW1GIWmu9PpgHO7lKn5Yns8rbKlHKzsgfCBSmE937aACS77EZX0d525hg83xiEuJUvGfFzt8XrPEDze1BtqMWefiIiIiMgIMdEni3Qr/xZ+OP0Dfoz7EdlF2TLW0KWhTPB7NewFKzV/Nf5S5hUgeikQ/T2QruxCINVrpiT3EU8Cdqa7E8HJyxmYsTEWexOV5RvOdlb4z2NBGNnOD3bWYo8AIiIiIiLjxWyGLMr1vOtYfGoxVsSvQF5xnowFugZiQuQEdGvQDRo1k7i70hYBCVuUqfniXq9T4mJrwaZPKcX16kXClF1Oz8OszfH4+dhlWWrARqPG6PZ+eOHRQLg6cPkGEREREZkGJvpkEVJzUrHw1EKsOrMKBdoCGQtzC8OEphPwaINHoVZxv/O7upEERC8Bji0FslPL4n4dlNH7sCcAG9PehSAjrwhf7UzEwr3nUVisXMDo18wbr3UPga+bab83IiIiIrI8TPTJrF3JviK3yFuTsAZFOqW6e1OPpnIE/xGfR7hl5N0U5QOxvyhr78/vLos7eMgt8WSC7xEEU1dQrMWS/RfwxfYEpOcqPx8PBbhheu8wNK3vaujmERERERE9ECb6ZJYuZl7Etye/xfrE9SjWK1uhtajbQib47eq1Y4J/N6mnlKn5x5cD+em3gyogsItSOT+4J2Bl+lPYRaG9X09cxceb43DxprKEI6huLUzrHYpHQ+ry54OIiIiITBoTfTIrZzPO4tsT3yLqXBS0eq2Mta3XVk7Rb+3V2tDNM04FWcDJNcro/eUjZXHn+sq6+2YjAFdfmIsDZ2/gg6hYHL+UIY/rOtnilW7BeLJlfVhpuISDiIiIiEyfUXyqnTNnDvz9/WFnZ4e2bdvi4MGDf3n+ypUrERoaKs+PiIhAVFRU6deKioowZcoUGXd0dIS3tzdGjRqFK1euVHiOmzdvYsSIEXB2doarqyvGjRuH7Gyl+jqZnlRtKqbumYr+a/vjl7O/yCT/YZ+H8UOvH/Bt92+Z5P+ZqDR38RCwbiIwMwT45UUlyRe7DYg19yNWAy+dADpPNZskPzEtC88uPoQh8/fLJN/RRiMT/J2TO2NomwZM8omIiIjIbBh8RH/FihV45ZVXMHfuXJnkf/rpp+jRowfi4+NRt27dO87ft28fhg0bhhkzZqBv375YtmwZ+vfvj6NHjyI8PBy5ubny32+++SYiIyNx69YtTJo0CU888QQOHz5c+jwiyb969Sq2bt0qLw6MHTsWzz33nHw+Mh2xN2Lx9bGvsSNrB6BsdY5HfR+VI/hNPJoYunnGJ/cmcGKFMj0/7XRZ3D1QWXcfORyoVQfmJC0rH59uS8CKQxeh1emhUaswrI0vJnUJRh0nW0M3j4iIiIjI/BL92bNnY/z48TLRFkTCv2HDBixYsABTp0694/zPPvsMPXv2xOTJk+Xxe++9J5P1L7/8Uj7WxcVFHpcnvtamTRtcuHABDRo0QGxsLDZt2oRDhw6hVatW8pwvvvgCvXv3xsyZM+UsgD8rKCiQtxKZmZnyXlwkEDeqWTHXY/DNyW+w58oeeayCCo/VfwzjI8YjuHawjLFfbtProEreA3X0D1DFb4BKW6iEreygD+sHXbOnofd9CChZl17D37eSfqrq/sopKMaCvcn4du955BYqyzi6hdXFa92CEFDHsVpe01JVVx9SzWEfmjb2n+ljH5o+9qHpKzKRPrzX9qn0oiqVgRQWFsLBwQGrVq2So/IlRo8ejfT0dKxbt+6Ox4hEXcwAeOmll0pjb7/9NtauXYvjx49X+jrbtm1D9+7d5XOKqfriIsKrr74qR/tLFBcXy6UAYlnAgAED7niOd955B+++++4dcTEDQLwHqhnni89jZ/5OJBYnlib4EdYR6GzXGXU1d84AsWR2Rbfge2M3/G78DsfCtNJ4un0DJLt3xqXa7VBspSS85kSrBw6kqbDxohqZRcrFC79aevTz06KRs6FbR0RERET04MQM9uHDhyMjI0PmtkY5on/9+nVotVp4enpWiIvjuLi4Sh+TkpJS6fkiXpn8/Hy5Zl9M9y/5Rohz/7wswMrKCm5ubnd9nmnTpskLDOVH9H19feUFhL/6BtM/J65FHUo9JKvoH05Xll9oVBr0btgb4xqPQz37enIWR7du3WBtbQ2LpiuGKnEb1MeWQJW4FarbBQn1tk7QNRkEXbORcKwXicaAvBnLVcmq6D/xc7I9/ho+2ZKApGs5MtbAzV6O4Pds4slK+ibQh2Q47EPTxv4zfexD08c+NH1FJtKHJTPLjX7qfnV31lNPPSUTgK+//vofPZetra28/Zn4ITDmHwRTJvpt75W9mHd8Ho5dOyZjVmor9A/sj3Hh41DfqX6F6SsW3Rc3zwHRS4BjS4Gsq2VxMSW/5WioGveDxsYRGhivf9J/xy+m4/2oWBw8d1Me13awxotdgjCirR9srFhkr6ZY9O+gmWAfmjb2n+ljH5o+9qHpszbyPrzXthk00ffw8IBGo0FqamqFuDj28vKq9DEifi/nlyT5ycnJ2L59e4VRd3FuWlrZVOaSqfuiEv/dXpdqNsHfeXEn5p+Yj5M3TsqYjdoGg4IH4ZnwZ+DlyD6SiguA2F+UwnrndpXFHdyByGFKcb06ITBnF27k4uPNcfj1hHJxw9ZKjWcebojnOzeCs53x/oEmIiIiIqpOBk30bWxs0LJlS/z222+la/R1Op08njhxYqWPadeunfx6+TX6YoqFiP85yU9ISMCOHTvg7u5+x3OI9fpHjhyRry+IiwHitUXlfzIMnV6HbcnbZIIffytexuw0dngq5CmMaTIGdRzMqxr8A0uLVZL74z8CeSV1JlRAo0eV5D6kD2BlA3N2K6cQX2xPxA/7z6NIq5d1BAc2r49XuwfD29Xe0M0jIiIiIjIog0/dF+veRfE9Uf1eVMYX2+vl5OSUVuEfNWoUfHx85HZ6gtgqr1OnTpg1axb69OmD5cuXy23z5s+fX5rkP/nkk3KLvV9//VXWAChZdy/W4IuLC2FhYbJyv6j2Lyr1i8eICwtDhw6ttOI+VS+tTovN5zfjm5hvkJiuFNlzsHLA0NChGNV4FNztK16osUgF2cCpn5UE/9LBsrizD9D8aaDZCKC2H8xdfpEWi/adx5wdicjKL5axR4I8MK1XGBp7s1YGEREREZFRJPpDhgzBtWvX8NZbb8mEvFmzZnLru5KCe2JLPLW6bI1t+/btZaX7//73v5g+fTqCgoJkxf3w8HD59cuXL2P9+vXy3+K5yhOj+507d5b/Xrp0qUzuu3TpIp9/0KBB+Pzzz2vwnVORrghRZ6Pwbcy3OJ95XsacrJ0wPGw4ng57Gq52rrBoYkOMK0eBI4uBk6uBwmwlrrYCgnsCLUYDgV0AtTGvvK8aOp0ea49dxqwtZ3A5PU/GQr2cML13GDoGc6YHEREREZFRJfqCSLjvNlV/586dd8QGDx4sb5Xx9/eXa7z/jhjdFxcMqOYVaYuwLmmdTPAvZ1+WMRdbF4wMG4lhYcPgbGPhI7O5N4GYlcrofapSo0ByC1Cm5kcOB5wq7jxhzvYkXMeMjbE4dUWpMFrPxQ6vdg/BgOY+0KhZSZ+IiIiIyCgTfbIMBdoCrElYgwUnFyAl5/ZyCjs3jG4yGkNChsDR2vz2dL9n4uLU+T1Kcn96HaAtUOIaW6BxP1k5H34dIBejW4jYq5n4cGMcdp25Jo+dbK3w/KON8EyHhrCzNv9ZDERERERED4qJPlW7vOI8rIxfiUWnFuFanpK01bGvg7HhY/Fk8JOwt7Lg4mlZqcqWeNE/ADfPlsU9w5Wp+U0HA/a1YUlSMvIxa0s8Vh29JK9/WKlVePohP7ldnpujeRcZJCIiIiKqCkz0qdrkFOVgedxyfH/6e9zMV/Y3F1vjjQsfhwFBA2ArRqstkU4LJG5TRu/jNwJ6rRK3qQVEPKlMz/duYVGj94Iorvfd9iR8t+cc8ot0MtYnoh4m9wiBv4cFz/YgIiIiIrpPTPSpymUWZmJZ7DIsiV2CjIIMGfOp5YNnI55Fv0b9YK2x0P3NbyUD0UuUW9aVsnj9NsrU/Mb9AdtasDRFWh1+v6rCO/+3G7dyi2SstX9tWWiveQPLms1ARERERFQVmOhTlRFJ/Q+nf5BJflZRloz5O/vLBL93QG9Yqy0wwS8uAOKjlMr5Z0VhyduFIu3dgMhhQIuRQN0wWCJRNHPTyRR8tCkO52+INfdFCKjjiKk9Q9GtsSdUFjajgYiIiIioqjDRp3/sRt4NOT1fTNPPLc6VsUYujfBc0+fQw78HNBaw/dsdrsUrU/OP/wjk3iiLB3RWpuaH9gWsLHTpAoAjyTfx/oZYHL2QLo9rWesxuWdjDH/IH9aasu00iYiIiIjo/jHRpwd2LfcaFp5aKAvt5WvzZSykdggmRE5AlwZdoFZZWMJWmAOcWqsk+Bf3l8Wd6gHNRgDNnwbcGsKSnb2WjY83xWPTKWXXBXtrDcZ18INv7hkMbOPLJJ+IiIiIqAow0af7JrbG+y7mO7lVXqGuUMbC3cNlgt+pfifLmnItysJfPaZMzY9ZBRQqSxag0gDBPZXR+8CugMayf9WuZxfg898SsOzABRTr9FCrgKda+eLlbsFws9cgKuqMoZtIRERERGQ2LDv7oPtyKesSvo35FuuS1qFYVyxjzes2x4SmE9Deu71lJfh56UDMSuDoYiAlpixe219J7iOHA871YOnyCrX4bs9ZzN11FtkFys9Ml9C6mNIrFMGeTvK4qEgpwEdERERERFWDiT79rfMZ5/FNzDfYcHYDtLe3gmvt1Rr/avoveW8xCb4YvU/ep0zNP70WKFaWK0BjA4Q9oST4/o8Aak4/1+r0WH3kEmZtjUdqZoGMRfi4YFrvULRv5GHo5hERERERmTUm+nRXibcSMT9mPjaf3wydXtnXXIzcixH8Fp4tYDGy04Bjy4DoH4AbiWXxuo2BFqOBpk8BDm6GbKFRVdLfeeYaPoyKQ3yqsoyhfm17TO4RgsebekMt5uwTEREREVG1YqJPd4i/GY95J+ZhW/I26G9vByfW3osEP6JOBCyCTgskbVem5sdvBG4vVYC1IxAxSEnwfVoCljKb4R6cvJyBGRtjsTdR2WXAxd4a/3ksECPb+cHWygJ3XiAiIiIiMhAm+lTq1PVTmHtiLnZeFPu9K7o26Cq3yQtzt5C93tMvANFLgeglQOalsrhPK2VqfvhAwFZZW06KS7dyMWvLGfwcfVke22jUGNPBHy90DoSLg7Whm0dEREREZHGY6BOOpR2TCf7ey3vlsQoq9PTvifFNxyOodhDMXnEhcGajsvY+8TcxAV2J27kCkcOAFiMBzyaGbqXRycgtwlc7E7Fw33kUFitLO/o388ar3UPg6+Zg6OYREREREVksJvpmTKvT4mjaUbnffR2HOmhRtwU06rIp1IdSDmHe8Xk4kHJAHmtUGvQJ6INnI55FQxcL2O/92hkg+nvg2I9A7vWyeMOOytT80L6AtZ0hW2iUCoq1+OGPZHyxPREZeUrF/HYB7pjeOwwR9V0M3TwiIiIiIovHRN9MifX1Hx78EKm5qaUxTwdPTGk9BY42jjLBFxcBBCuVFfoF9sO48HHwdfaFWSvMBU6vU0bvL+wri9fyBJqNAJo/Dbg3MmQLjZZOp8evMVfxyeY4XLyZJ2PBnrUwrVcYOofUsZzdF4iIiIiIjBwTfTNN8l/Z+UppIb0SIul/ZdcrpcfWamsMDBooE/x6tcx8z/erx5Xk/sRKoCBDianUQFAPZe19UHdAw1+Hu9l/9gZmRMXi+CXle1fXyRavdg/GoBb1YaXhdoJERERERMaEmY0ZTtcXI/l/TvL/bHjocDwT/gw8HT1htvIzgJiVSoIvEv0Srn7Kunsxgu/sbcgWGr2E1Cx8uDEOv8WlyWNHGw3+1akRxj3SEA42/PNBRERERGSM+EndzIjp+OWn699NV7+u5pnk6/XAhf1Kcn/qZ6BYmWIOjY2y5l6M3jfsBKg5Cv1X0jLz8X/bzmDFoYvQ6QGNWoXhbRrgxS5BqONka+jmERERERHRX2Cib2ZE4b2qPM9U2BRlQr1/DnB8KXD9TNkX6oQqyX3ToYCjuyGbaBJyCoox//ez+Gb3WeQWamWsRxNPvN4zFI3q1DJ084iIiIiI6B4w0Tczorp+VZ5n1HQ64OwOaA4vQo/4DVCfVBJTWDso+92Lyvn1WwMsEve3irU6LD90EZ9uS8D17AIZa97AVVbSb+3vZujmERERERHRfWCib2bEFnqiun5ablql6/RVUMmvi/NMVsYlIHopEL0EyLiAkkn4unrNoW45GggfBNg5G7iRpkGv12NbbBo+3BiLpGs5Mubn7oApPUPRK9yLlfSJiIiIiEwQE30zo1FrMLXNVFl1XyT15ZN9cSxMaTNFnmdStEXAmU3K2vvEbYBep8TtXKANH4zfs/zx8JP/gtra2tAtNRnHLqbjg6hYHDx3Ux67OdrgxccCMbytH2ysWMOAiIiIiMhUMdE3Q6LQ3uzOs2X1/fKF+cRIvkjyxddNxo0k4Ohi4NgyIKdcXQH/R5S192GPQwcrZEZFGbKVJiX5Rg4+3hyPDSeuymNbKzXGPdwQ/+rcCM52vFBCRERERGTqmOibKZHMP+r7qKzCLwrviTX5Yrq+SYzkF+UBp9cro/fJe8rijnWBZsOVBN+9UbnziwzSTFNzK6cQn29PwJL9ySjS6mXpgkEt6uPV7sGo52Jv6OYREREREVEVYaJvxkRS39qrNUxGSoyS3J9YAeRnKDGVGgjsqiT3wT0BDUec71d+kRYL957HVzsTkZVfLGMdg+tgas9QNPZmLQMiIiIiInPDRJ8MKz8TOLlamZ5/Jbos7tIAaDFSGcF3qW/IFposnU6Pn6MvY9aWeFzJyJexxvWcMa13KB4JMoNdF4iIiIiIqFJM9Knm6fXAxYPK6P2pNUBRrhJXWwOhfZTR+4BHATULwj2oPQnXZaG901cz5bG3ix1e7R6CAc19oFazkj4RERERkTljok81J+cGcGK5kuBfiyuLewQryX3kMMDRw5AtNHmxVzMxY2Mcfj+jFC50srXCvx8NxNgO/rCzNoH6DERERERE9I8x0afqpdMB53YpU/PjNgDaQiVuZQ80GQCIfe9920JWhqMHdjUjD7O2nMHqo5fkhAlrjQpPP+SH/zwWJLfNIyIiIiIiy8FEn6pHxmVlS7zo74H0C2Xxes2U0fuIJwE7F0O20Cxk5hdh7s4kfLfnHAqKdTLWp2k9vN4jBH7ujoZuHhERERERGQATfao62iIgYYsyNV/c65XEE7YuQNPBSoJfL9LQrTQLhcU6LDuQjM+3J+JmjjJLoo2/myy017xBbUM3j4iIiIiIDIiJPv1zN5KA6CXAsaVAdmpZvEF7ZWp+2BOAjYMhW2g29Ho9Np5Mwceb4nD+hlLEsFEdR0ztFYauYXWh4hIIIiIiIiKLx0SfHkxRPhD7i7L2/vzusriDh7Ilnhi99wgyZAvNzuHzN/F+VCyiL6TLY49aNnipazCGtvaFlYY7FBARERERkYKJPt2f1FPK1Pzjy4F8JeEEVEBgFyW5D+4FWLH4W1VKupYtR/A3n1JmS9hba/BcxwCM7xiAWrb8FSYiIiIiooqYJdDfK8gCTq5RRu8vHymLO9cHmj+t3Fx9DdlCs3Q9uwCfbUvAsoMXoNXpoVYBQ1r74uWuwajrbGfo5hERERERkZFiok+VE3u0XTqsJPciyS/KUeJqKyCkN9BiNNDoUUDNvdmrWm5hMb7bfQ5zdyUhp1ArY11C62Jqr1AEeToZunlERERERGTkmOhTRbk3gRMrlOn5aafL4u6BytT8yGFArbqGbKHZEqP2q45cxOytZ5CaWSBjTeu7YFqvMLRr5G7o5hERERERkYlgok+ATqcU1BOj96LAnlbZrg1WdkDj/krl/AbtAFZ0r7ZK+jvjr2HGxlicSc2Wsfq17fF6z1D0jagHtZizT0REREREdI+Y6JsznRZI3qdseVfLE/BrX3GqfeZVZUu86B+AW+fL4l4RytT8iMGAvatBmm4pYi5lyAR/X9INeexib43/PBaIke38YGvFZRFERERERHT/mOibq9PrgU1TgMwrZTFnb6D7B4C1nTI1/8xmQK+sAYeNE9B0sDI9v14zjt5Xs4s3czFzSzzWHVP6x8ZKjbHt/fHvzoFwcbA2dPOIiIiIiMiEMdE31yT/p1FiUnjFuEj6V42pGPN9SEnum/QHbBxrtJmWKCO3CHN2JmLR3vMo1OpkrH8zb7zWIwT1azsYunlERERERGQGmOib43R9MZL/5yS/PJUaaPsvoOUYoE5ITbbOYhUUa/HDH8n4YnsiMvKKZKx9I3dM7x2GcB8XQzePiIiIiIjMiNrQDZgzZw78/f1hZ2eHtm3b4uDBg395/sqVKxEaGirPj4iIQFRUVIWvr1mzBt27d4e7uztUKhWOHTt2x3OkpKRg5MiR8PLygqOjI1q0aIHVq1fDLIg1+eWn61dGr1O2yGOSX+10Oj3WHbuMLrN24X8bYmWSH+LphIVjW2Pps22Z5BMRERERkXkl+itWrMArr7yCt99+G0ePHkVkZCR69OiBtLS0Ss/ft28fhg0bhnHjxiE6Ohr9+/eXt5MnT5aek5OTg4cffhgfffTRXV931KhRiI+Px/r16xETE4OBAwfiqaeeks9p8kThvao8jx7YH0k30P+rvZi0/Bgu3cqDp7MtPh7UFFGTHsGjIXXlhSgiIiIiIiKzSvRnz56N8ePHY+zYsWjcuDHmzp0LBwcHLFiwoNLzP/vsM/Ts2ROTJ09GWFgY3nvvPTka/+WXX5aeI0bq33rrLXTt2vWurysuGPznP/9BmzZtEBAQgP/+979wdXXFkSNHYPJEdf2qPI/u25nULIxbdAjDvtmPE5cyUMvWCq91D8aO1zrjqda+0HC7PCIiIiIiMsc1+oWFhTKxnjZtWmlMrVbLBP2PP/6o9DEiLmYAlCdmAKxdu/a+Xrt9+/ZyNkGfPn1kgv/TTz8hPz8fnTt3vutjCgoK5K1EZmamvC8qKpI3o+HdGlZO3kDWVagqWaevh0pW3y/2bi0aD3NQ8v03dD+kZRXgs98SseroZej0gJVahaGt62Ni5wC417KV331Dt9EYGUv/0YNjH5o+9qFpY/+ZPvah6WMfmr4iE+nDe22fwRL969evQ6vVwtOz4siyOI6Li6v0MWJtfWXni/j9EIn9kCFD5Dp+KysrOYvg559/RmBg4F0fM2PGDLz77rt3xLds2SIfb0zqeQxC66wvZJpffuxYSfv1OOQ+EFc3bYa52bp1q0FeN18LbL+ixo4rKhTqlO94UzcdHm+gQ131ORz4/ZxB2mVqDNV/VHXYh6aPfWja2H+mj31o+tiHpm+rkfdhbm7uPZ1nkVX333zzTaSnp2Pbtm3w8PCQMwLEGv3du3fLAn+VETMPys8mECP6vr6+svCfs7MzjEtvaONaQrNlOpBVrjCfsw+03d5H89C+aA7zIa5qiV/Ibt26wdq65vagL9LqsPLIZXyxIwnXswtlrLmvC6b0CEZLv9o11g5TZ6j+o6rDPjR97EPTxv4zfexD08c+NH1FJtKHJTPLjTbRFwm2RqNBamrFonDiWFTDr4yI38/5lUlKSpJr+kUBvyZNmsiYKAIoknyxA4CoE1AZW1tbefsz8UNglD8IEQOAJk8oVfhF4b1anlD5tYeVWgNzVVN9odfrsfV0Kj7cFIez13JkzN/dAVN6hqJnuBeL7D0go/1donvGPjR97EPTxv4zfexD08c+NH3WRt6H99o2gxXjs7GxQcuWLfHbb7+VxnQ6nTxu165dpY8R8fLnC+Kqy93O/6upDqIeQHniooN4fbMikvqGjwARTyr3Zpzk15ToC7cwZN5+PPfDEZnkuzna4N0nmmDrK53QK6Iek3wiIiIiIjI4g07dF1PhR48ejVatWskK+J9++qncHk9U4S/ZBs/Hx0eujxcmTZqETp06YdasWbKQ3vLly3H48GHMnz+/9Dlv3ryJCxcu4MoVZcq62EZPEKP+4hYaGirX4k+YMAEzZ86U6/TF1H1xweDXX381yPeBjF/yjRx8vCkeG2KuymNbKzWefaQhJnRqBGc7473iR0RERERElsegib4oiHft2jW5HZ4oqNesWTNs2rSptOCeSNjLj7yLavnLli2T2+FNnz4dQUFBMkkPDw8vPWf9+vWlFwqEoUOHyvu3334b77zzjpzqEBUVhalTp+Lxxx9Hdna2TPwXL16M3r171+j7J+N3M6cQn/+WgKUHklGk1UMM2D/Zoj5e6R6Mei72hm4eERERERGR8RXjmzhxorxVZufOnXfEBg8eLG93M2bMGHn7K+ICwerVqx+gtWQp8ou0WLD3HL7ekYSsgmIZ6xRcB1N7hSKsnrEVXyQiIiIiIjKiRJ/ImGh1evwcfRmztsTjaka+jDWu54zpvcPwcJCHoZtHRERERET0t5joE922O+EaPoiKQ+xVZcsKbxc7vNYjBP2b+UCtZpE9IiIiIiIyDUz0yeKdvpKJGRtjsTvhujx2srPCC48GYkx7f9hZc6cCIiIiIiIyLUz0yWJdSc/DrC1nsCb6EvR6wFqjwsiH/PGfxwJR29HG0M0jIiIiIiJ6IEz0yeJk5hfh651JWLDnHAqKdTLWt2k9vN4jFA3cHQzdPCIiIiIion+EiT5ZjMJindwmT2yXdyu3SMba+Lthep8wNPN1NXTziIiIiIiIqgQTfTJ7er0eUTEp+HhzHJJv5MpYozqOmNorDF3D6kKlYqE9IiIiIiIyH0z0yawdOn8T72+IxbGL6fLYo5YtXu4WhCGtfGGlURu6eURERERERFWOiT6ZpaRr2fhoYxy2nE6Vx/bWGjzXMUDeHG35Y09EREREROaLGQ+ZlWtZBfjstzP48eBFaHV6qFXAkNYN8HLXINR1tjN084iIiIiIiKodE30yCwVa4MsdSfh2z3nkFGplTKy/n9orFIF1nQzdPCIiIiIiohrDRJ9MWrFWh58OX8JH0RpkFiXJWGR9F0zrHYaHAtwN3TwiIiIiIqIax0SfTLaS/o74NHy4MQ5nUrMBqFC/tj2m9AxFn4h6UIs5+0RERERERBaIiT6ZnJhLGfggKhZ/nL0hj13trfGoZz7eG90BtextDd08IiIiIiIig2KiTybj4s1czNwSj3XHrshjGys1xrb3x/iH/bB3x1bYWnG7PCIiIiIiIib6ZPTScwsxZ0ciFu9LRqFWJ2MDm/vgle7BqF/bAUVFRYZuIhERERERkdFgok9Gq6BYi+/3JePLHYnIyFOS+Q6B7pjWKwzhPi6Gbh4REREREZFRYqJPRken0+OXE1fwyeZ4XLqVJ2Mhnk6Y1jsUnYLrQKVioT0iIiIiIqK7YaJPRmVf0nXMiIpDzOUMeezpbItXu4dgUIv60LCSPhERERER0d9iok9G4Uxqltwqb3tcmjyuZWuF5zs3wjMdGsLeRmPo5hEREREREZkMJvpkUKmZ+Zi95QxWHrkInR6wUqswvG0DvNglCB61uFUeERERERHR/WKiTwaRXVCM+buS8M3uc8gr0spYr3AvTO4RgoA6tQzdPCIiIiIiIpPFRJ9qVJFWh+WHLuKzbWdwPbtQxlo0cMUbfcLQ0s/N0M0jIiIiIiIyeUz0qUbo9XpsOZ2KjzbG4ez1HBlr6OGIKT1D0KOJFyvpExERERERVREm+lTtjl64hRlRsTh0/pY8dne0waSuQRjWpgGsNWpDN4+IiIiIiMisMNGnanP+eg4+3hyHqJgUeWxnrcazDwdgQqcAONlZG7p5REREREREZomJPlW5mzmF+Py3BCzZn4xinR5iVv7glvXxcrdg1HOxN3TziIiIiIiIzBoTfaoy+UVafLfnHObuTEJWQbGMdQ6pg6m9QhHq5Wzo5hEREREREVkEJvr0j2l1eqw5egmzt57B1Yx8GWvi7YzpvcPQIdDD0M0jIiIiIiKyKEz06R/ZdeaaLLQXl5Ilj31c7fFaj2D0i/SBWs1K+kRERERERDWNiT49kNNXMjFjYyx2J1yXx052Vpj4aCBGt/eHnbXG0M0jIiIiIiKyWEz06b5cSc/DzC3x+Dn6MvR6wFqjwqh2/jLJr+1oY+jmERERERERWTwm+nRPMvOL8NWOJCzYew6FxToZezzSG5O7h6CBu4Ohm0dERERERES3MdGnvySSerFN3hfbE3Art0jG2jZ0k4X2In1dDd08IiIiIiIi+hMm+lQpvV6PDTFX8fGmeFy4mStjgXVrYWrPUHQJqwuVioX2iIiIiIiIjBETfbrDwXM38X5ULI5fTJfHdZxs8XLXYDzVqj6sNGpDN4+IiIiIiIj+AhN9KpWYlo2PNsVh6+lUeexgo8FzHQMw/pEAONryR4WIiIiIiMgUMHsjpGXl47NtCVh+6CK0Oj00ahWGtPbFS12DUNfJztDNIyIiIiIiovvARN+C5RYW45vfz2He70nILdTKWNcwT0ztFYLAuk6Gbh4RERERERE9ACb6ZkyMzov19mLEXozMt2noJkfri7U6rDxyCbO3nsG1rAJ5rqigP71XKNoGuBu62URERERERPQPMNE3U5tOXsW7v5zG1Yz80piXix0GNveRa/AT0rJlzNfNHq/3CEXfpvVYSZ+IiIiIiMgMMNE30yT/+SVHof9TPCUjH1/tTJL/dnWwxouPBWHEQw1ga6UxSDuJiIiIiIio6jHRN8Pp+mIk/89JfnmOthpsf7Uz3BxtarBlREREREREVBMMvin6nDlz4O/vDzs7O7Rt2xYHDx78y/NXrlyJ0NBQeX5ERASioqIqfH3NmjXo3r073N3d5VT0Y8eOVfo8f/zxBx577DE4OjrC2dkZHTt2RF5eHkydWJNffrp+ZXIKtIhPyaqxNhEREREREZGFJPorVqzAK6+8grfffhtHjx5FZGQkevTogbS0tErP37dvH4YNG4Zx48YhOjoa/fv3l7eTJ0+WnpOTk4OHH34YH3300V1fVyT5PXv2lBcExIWFQ4cOYeLEiVCrDX7d4x8Thfeq8jwiIiIiIiIyLQaduj979myMHz8eY8eOlcdz587Fhg0bsGDBAkydOvWO8z/77DOZoE+ePFkev/fee9i6dSu+/PJL+Vhh5MiR8v78+fN3fd2XX34ZL774YoXXCAkJgTm4133v7/U8IiIiIiIiMi0GS/QLCwtx5MgRTJs2rTQmRtS7du0qR9wrI+JiBkB5YgbA2rVr7/l1xWyBAwcOYMSIEWjfvj2SkpLkUoD3339fzgS4m4KCAnkrkZmZKe+LiorkzVg0r+8EL2dbpGYWVLpOX9TV93KxlecZU7v/iZL3YS7vx9Kw/0wf+9D0sQ9NG/vP9LEPTR/70PQVmUgf3mv7DJboX79+HVqtFp6enhXi4jguLq7Sx6SkpFR6vojfq7Nnz8r7d955BzNnzkSzZs3w/fffo0uXLnIJQFBQUKWPmzFjBt5999074lu2bIGDgwOMSW8vFRZklixDKL9lnl4m/708c7F500aYGzG7g0wX+8/0sQ9NH/vQtLH/TB/70PSxD03fViPvw9zc3Hs6z+Kq7ut0Onk/YcKE0iUDzZs3x2+//SaXDIiEvjJi5kH52QRiRN/X11eu8xfF/IxJbwAtTqXif1FxSMksm4VQz8UOb/QKRY8mFS+WmDpxVUv8Qnbr1g3W1taGbg7dJ/af6WMfmj72oWlj/5k+9qHpYx+aviIT6cOSmeVGm+h7eHhAo9EgNTW1Qlwce3l5VfoYEb+f8ytTr149ed+4ceMK8bCwMFy4cOGuj7O1tZW3PxM/BMb4g9C3WX30auojq/CLwntiTX6bhm7QqMuP8JsXY+0LujfsP9PHPjR97EPTxv4zfexD08c+NH3WRt6H99o2g5WZt7GxQcuWLeVIevnRdnHcrl27Sh8j4uXPF8RVl7udXxmxlZ+3tzfi4+MrxM+cOQM/Pz+YE5HUt2vkjn7NfOS9OSf5REREREREZART98VU+NGjR6NVq1Zo06YNPv30U7k9XsmU+lGjRsHHx6d0Ov2kSZPQqVMnzJo1C3369MHy5ctx+PBhzJ8/v/Q5b968KUfmr1y5Io9LEnox6i9uKpVKVu0XW/qJ7fzEGv3FixfLugCrVq0yyPeBiIiIiIiIyCwS/SFDhuDatWt46623ZEE9kXRv2rSptOCeSNjL720vquQvW7YM//3vfzF9+nRZOE9U3A8PDy89Z/369aUXCoShQ4fKe5HYiwJ8wksvvYT8/Hy5zZ64MCASfjEzoFGjRjX47omIiIiIiIiqnsGL8U2cOFHeKrNz5847YoMHD5a3uxkzZoy8/Z2pU6fKGxEREREREZE5MdgafSIiIiIiIiKqekz0iYiIiIiIiMwIE30iIiIiIiIiM8JEn4iIiIiIiMiMMNEnIiIiIiIiMiNM9ImIiIiIiIjMCBN9IiIiIiIiIjPCRJ+IiIiIiIjIjDDRJyIiIiIiIjIjTPSJiIiIiIiIzIiVoRtgqvR6vbzPzMw0dFMsXlFREXJzc2VfWFtbG7o5dJ/Yf6aPfWj62Iemjf1n+tiHpo99aPqKTKQPS/LPknz0bpjoP6CsrCx57+vra+imEBERERERkYXloy4uLnf9ukr/d5cCqFI6nQ5XrlyBk5MTVCqVoZtj0cRVLXHB5eLFi3B2djZ0c+g+sf9MH/vQ9LEPTRv7z/SxD00f+9D0ZZpIH4r0XST53t7eUKvvvhKfI/oPSHxT69evb+hmUDniF9KYfynpr7H/TB/70PSxD00b+8/0sQ9NH/vQ9DmbQB/+1Uh+CRbjIyIiIiIiIjIjTPSJiIiIiIiIzAgTfTJ5tra2ePvtt+U9mR72n+ljH5o+9qFpY/+ZPvah6WMfmj5bM+tDFuMjIiIiIiIiMiMc0SciIiIiIiIyI0z0iYiIiIiIiMwIE30iIiIiIiIiM8JEn4iIiIiIiMiMMNEnozNnzhz4+/vDzs4Obdu2xcGDB//y/JUrVyI0NFSeHxERgaioqDvOiY2NxRNPPAEXFxc4OjqidevWuHDhQjW+C8tW1X2YnZ2NiRMnon79+rC3t0fjxo0xd+7can4Xlut++u/UqVMYNGiQPF+lUuHTTz/9x89JxteHM2bMkH83nZycULduXfTv3x/x8fHV/C4sW3X8Hpb48MMP5XkvvfRSNbScqrMPL1++jKeffhru7u7y/4fi/5mHDx+uxndhuaq6/7RaLd588000bNhQ9l2jRo3w3nvvgXXRjaMPv/nmGzzyyCOoXbu2vHXt2vWO80VfvfXWW6hXr57sQ3FOQkICjBUTfTIqK1aswCuvvCK3tjh69CgiIyPRo0cPpKWlVXr+vn37MGzYMIwbNw7R0dHyw6e4nTx5svScpKQkPPzwwzKR3LlzJ06cOCH/0IpfejKNPhTPt2nTJixZskRetBEfTkXiv379+hp8Z5bhfvsvNzcXAQEBMnHw8vKqkuck4+vDXbt24YUXXsD+/fuxdetWFBUVoXv37sjJyanmd2OZqqMPSxw6dAjz5s1D06ZNq6n1VF19eOvWLXTo0AHW1tbYuHEjTp8+jVmzZsmkhIy//z766CN8/fXX+PLLL+VnGXH88ccf44svvqjmd2OZVtxnH4ocQXwe3bFjB/744w/4+vrK/8+Ji2slRH99/vnncrDpwIEDcvBQPGd+fj6Mkthej8hYtGnTRv/CCy+UHmu1Wr23t7d+xowZlZ7/1FNP6fv06VMh1rZtW/2ECRNKj4cMGaJ/+umnq7HVVN192KRJE/3/+3//r8I5LVq00L/xxhtV3n5Ld7/9V56fn5/+//7v/6r0Ock4+vDP0tLSxBCUfteuXf+4vVRzfZiVlaUPCgrSb926Vd+pUyf9pEmTqrTdVL19OGXKFP3DDz9c5W2lmuk/8VnnmWeeqRAbOHCgfsSIEVXUaqrKzx7FxcV6Jycn/eLFi+WxTqfTe3l56T/55JPSc9LT0/W2trb6H3/8UW+MOKJPRqOwsBBHjhyR02BKqNVqeSyurFVGxMufL4grayXn63Q6bNiwAcHBwTIuppyKqTtr166t5ndjmaqjD4X27dvL0XtxVVVMmxJXW8+cOSOvtJJh+88Qz0mG/35nZGTIezc3typ7Tqr+PhSzMvr06XPH31wyjT4U/x9s1aoVBg8eLD/PNG/eXE43JtPoP/FZ5rfffpOfX4Tjx49jz5496NWrV5W0m6q2D3Nzc+XstZL/z507dw4pKSkVnlMsCRZ5hbF+nmGiT0bj+vXrcv2Sp6dnhbg4Fr9YlRHxvzpfTM8R67vFVKqePXtiy5YtGDBgAAYOHCinopLx96EgprWJdflijb6NjY3sS7HuqmPHjtX0TizTg/SfIZ6TDPv9FhdQxfIZMYU4PDy8Sp6Tqr8Ply9fLqevinoLZJp9ePbsWTn1OygoCJs3b8bzzz+PF198EYsXL66CVlN199/UqVMxdOhQuZRULL8QF2rE39IRI0ZUQaupqvtwypQp8Pb2Lk3sSx5nSp9nrAzdAKLqJD6QCv369cPLL78s/92sWTO5Llysr+nUqZOBW0j3QiT6Ym2wGM3w8/PD77//Lkemyv8BJqKaIX73RA0NMRJFpuHixYuYNGmSrK/A+jSm/ZlGjOh/8MEH8lgkiuJ3UXyeGT16tKGbR3/jp59+wtKlS7Fs2TI0adIEx44dk4m++CzD/jMuH374obw4Ktbtm/LfTCb6ZDQ8PDyg0WiQmppaIS6O71bYRMT/6nzxnFZWVnI0uLywsDB+SDWRPszLy8P06dPx888/yymngigiJf4HOXPmTCb6Bu4/QzwnGe77LYpg/vrrr/Jim5hhQ6bRh2IKq5jh1qJFi9KYGO0S/SgKgxUUFMjXJOP+PRSVviv7PLN69eoHfk6quf6bPHly6ai+IHZMSE5OlrNsmOgbTx/OnDlTJvrbtm2rULS05HHiOcTvYvnnFIOIxohT98loiCnZLVu2lOuXyl+9Fsft2rWr9DEiXv58QYxYlJwvnlNsCfXnbaDE+igxMkzG34difZS4ibVV5Yk/4CUzNshw/WeI56Sa/36L2hgiyRcX3LZv3y63hyLT6cMuXbogJiZGXiAtuYmRYTFlWPybSb5p/B6K5TL8PGO6/SfWfPOzjHH34ccffyy3PBQ7PYm/keWJ/++JZL/8c2ZmZsrq+0b7ecbQ1QCJylu+fLmsXrlo0SL96dOn9c8995ze1dVVn5KSIr8+cuRI/dSpU0vP37t3r97Kyko/c+ZMfWxsrP7tt9/WW1tb62NiYkrPWbNmjYzNnz9fn5CQoP/iiy/0Go1Gv3v3boO8R3NXHX0oqkOLyvs7duzQnz17Vr9w4UK9nZ2d/quvvjLIezRn99t/BQUF+ujoaHmrV6+e/rXXXpP/Fr9r9/qcZPx9+Pzzz+tdXFz0O3fu1F+9erX0lpuba5D3aO6qow//jFX3Ta8PDx48KP9/+f7778v40qVL9Q4ODvolS5YY5D2as+rov9GjR+t9fHz0v/76q/7cuXPy86mHh4f+9ddfN8h7NHfL77MPP/zwQ72NjY1+1apVFf4/J3YrKX+OeI5169bpT5w4oe/Xr5++YcOG+ry8PL0xYqJPRkck4g0aNJC/bGJrjP3791f4YCL+UJb3008/6YODg+X5IhncsGHDHc/53Xff6QMDA2VyGBkZqV+7dm2NvBdLVdV9KP7QjhkzRm6LIvowJCREP2vWLLnVCRm2/8SHFXHN+M83cd69PicZfx9W9nVxExfdyHR+D8tjom+affjLL7/ow8PDZQITGhoqBzHINPovMzNT/s6J5xSfZQICAuQ2weIiARm+D/38/CrtQzEAVUJ87nzzzTf1np6e8newS5cu+vj4eL2xUon/GHpWARERERERERFVDa7RJyIiIiIiIjIjTPSJiIiIiIiIzAgTfSIiIiIiIiIzwkSfiIiIiIiIyIww0SciIiIiIiIyI0z0iYiIiIiIiMwIE30iIiIiIiIiM8JEn4iIiIiIiMiMMNEnIiKiaufv749PP/30vh+nUqmwdu3aamkTERGRuWKiT0REZEHGjBmD/v37w5K8//77aN++PRwcHODq6mro5hAREVU7JvpERERk1goLCzF48GA8//zzhm4KERFRjWCiT0RERKVmz56NiIgIODo6wtfXF//+97+RnZ1d+vVFixbJUfFff/0VISEhcpT8ySefRG5uLhYvXiyn6NeuXRsvvvgitFpthefOysrCsGHD5HP7+Phgzpw5Fb6ekJCAjh07ws7ODo0bN8bWrVvvaN+UKVMQHBwsXzcgIABvvvkmioqK/vI9vfvuu3j55Zfl+yIiIrIEVoZuABERERkPtVqNzz//HA0bNsTZs2dlov/666/jq6++Kj1HJPXinOXLl8vkfeDAgRgwYIC8ABAVFSUfN2jQIHTo0AFDhgwpfdwnn3yC6dOny8R78+bNmDRpkkzau3XrBp1OJ5/H09MTBw4cQEZGBl566aU72ufk5CQvNnh7eyMmJgbjx4+XMdFGIiIiUqj0er3+9r+JiIjIAtbop6en33OBu1WrVuFf//oXrl+/Lo9Fkj127FgkJiaiUaNGMia+/sMPPyA1NRW1atWSsZ49e8rR/blz58pj8e+wsDBs3Lix9LmHDh2KzMxMeXFgy5Yt6NOnD5KTk2USL2zatAm9evXCzz//fNe6AjNnzpQXHA4fPvy370W0XVw8EO+fiIjInHFEn4iIiEpt27YNM2bMQFxcnEzCi4uLkZ+fL0fxxXR5QdyXJPmCGIUXiXxJkl8SS0tLq/Dc7dq1u+O4pBJ/bGysXCpQkuRXdr6wYsUKOZsgKSlJLikQ7XN2dq7C7wAREZHp4xp9IiIiks6fP4++ffuiadOmWL16NY4cOVK6jl4UtCthbW19xxZ4lcXEdPyq9Mcff2DEiBHo3bu3rBEQHR2NN954o0LbiIiIiCP6REREdJtI7EVyPmvWLLlWX/jpp5+q7Pn3799/x7GYzi+I+4sXL+Lq1auoV69epefv27cPfn5+MrkvIab6ExERUUVM9ImIiCyMKHR37NixCjF3d3cEBgbKCvZffPEFHn/8cezdu7d0jX1VEM/38ccfy/X2oqL+ypUrsWHDBvm1rl27ysJ8o0ePlkX7xLKB8gm9EBQUhAsXLsg1+a1bt5aPFev3/454zM2bN+W92Amg5L2L91t+uQEREZG54NR9IiIiC7Nz5040b968wk1Uwo+MjJTb63300UcIDw/H0qVL5Xr9qvLqq6/Konni9f73v//J1+rRo4f8mphBIJL2vLw8tGnTBs8++yzef//9Co9/4okn5DZ5EydORLNmzeQIv9he7++89dZb8jXffvttua6/5D3fSwE/IiIiU8Sq+0RERERERERmhCP6RERERERERGaEiT4RERERERGRGWGiT0RERERERGRGmOgTERERERERmREm+kRERERERERmhIk+ERERERERkRlhok9ERERERERkRpjoExEREREREZkRJvpEREREREREZoSJPhEREREREZEZYaJPREREREREBPPx/wE8JmwozAlhvwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RUNNING FINAL ANALYSIS WITH BEST HYPERPARAMETERS\n",
      "==================================================\n",
      "\n",
      "Training final model with best hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 455 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating final forecasts...\n",
      "Generating BVAR forecasts for 40 years...\n",
      "BVAR forecast generation completed!\n",
      "\n",
      "ANALYSIS COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PlatinumBVARForecast:\n",
    "    def __init__(self, base_year=2017, lags=2, lambda1=0.1, lambda2=0.5, lambda3=1.0):\n",
    "        self.base_year = base_year\n",
    "        self.lags = lags\n",
    "        # Hyperparameters are now part of the class instance\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "        self.model = None\n",
    "        self.idata = None\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.forecast_df = None\n",
    "        self.var_names = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare platinum price and economic indicator data\"\"\"\n",
    "        # Data preparation remains the same\n",
    "        data = [\n",
    "            [1988, 523, 59.5, 4.6, 85.2], [1989, 507, 62.3, 3.7, 87.1],\n",
    "            [1990, 466, 65.6, 2.9, 88.3], [1991, 372, 68.4, 1.4, 86.9],\n",
    "            [1992, 357, 70.5, 2.2, 88.7], [1993, 373, 72.3, 2.6, 90.1],\n",
    "            [1994, 405, 74.8, 3.0, 92.4], [1995, 425, 76.8, 2.7, 94.2],\n",
    "            [1996, 397, 79.0, 3.4, 95.8], [1997, 394, 80.8, 3.8, 97.1],\n",
    "            [1998, 372, 81.5, 2.7, 95.3], [1999, 377, 83.4, 3.4, 96.8],\n",
    "            [2000, 544, 86.3, 4.8, 98.2], [2001, 533, 88.1, 2.5, 97.1],\n",
    "            [2002, 540, 89.6, 3.1, 98.9], [2003, 692, 91.8, 4.0, 101.3],\n",
    "            [2004, 844, 94.7, 4.5, 104.8], [2005, 897, 97.1, 4.3, 107.2],\n",
    "            [2006, 1142, 99.8, 4.5, 110.1], [2007, 1304, 102.6, 4.4, 112.8],\n",
    "            [2008, 1578, 104.2, 1.9, 108.9], [2009, 1205, 104.5, -1.3, 101.2],\n",
    "            [2010, 1613, 106.7, 4.3, 106.8], [2011, 1722, 109.7, 3.1, 109.4],\n",
    "            [2012, 1552, 111.4, 2.6, 108.7], [2013, 1487, 112.8, 2.8, 107.3],\n",
    "            [2014, 1385, 114.1, 2.9, 105.9], [2015, 1054, 115.4, 3.2, 102.1],\n",
    "            [2016, 990, 117.1, 3.1, 101.8], [2017, 954, 119.3, 3.0, 100.0],\n",
    "            [2018, 879, 121.7, 2.9, 98.7], [2019, 863, 124.0, 2.8, 97.9],\n",
    "            [2020, 883, 126.3, -3.5, 95.4], [2021, 1077, 129.6, 5.6, 98.2],\n",
    "            [2022, 1016, 133.8, 3.1, 99.1], [2023, 1077, 136.9, 2.9, 100.3],\n",
    "            [2024, 960, 139.5, 2.8, 99.8], [2025, 1020, 142.1, 2.7, 100.5]\n",
    "        ]\n",
    "        df = pd.DataFrame(data, columns=[\n",
    "            'Year', 'Nominal_Platinum_Price_USD_oz', 'US_CPI_2017_100',\n",
    "            'Global_GDP_Growth_pct', 'Industrial_Production_Index'\n",
    "        ]).set_index('Year')\n",
    "        df['Real_Platinum_Price'] = (df['Nominal_Platinum_Price_USD_oz'] / df['US_CPI_2017_100']\n",
    "                                      * df.loc[self.base_year, 'US_CPI_2017_100'])\n",
    "        df['Log_Real_Price'] = np.log(df['Real_Platinum_Price'])\n",
    "        df['Log_Industrial_Production'] = np.log(df['Industrial_Production_Index'])\n",
    "        df['Price_Growth'] = df['Log_Real_Price'].diff()\n",
    "        df['GDP_Growth_Rate'] = df['Global_GDP_Growth_pct']\n",
    "        df['Industrial_Growth'] = df['Log_Industrial_Production'].diff()\n",
    "        self.var_names = ['Price_Growth', 'GDP_Growth_Rate', 'Industrial_Growth']\n",
    "        self.train_df = df[df.index <= 2020].copy()\n",
    "        self.test_df = df[df.index > 2020].copy()\n",
    "        return df\n",
    "\n",
    "    def prepare_bvar_data(self, data):\n",
    "        \"\"\"Prepare data for BVAR estimation from a given DataFrame.\"\"\"\n",
    "        var_data = data[self.var_names].dropna()\n",
    "        n_obs, n_vars = var_data.shape\n",
    "        Y, X = [], []\n",
    "        for t in range(self.lags, n_obs):\n",
    "            Y.append(var_data.iloc[t].values)\n",
    "            x_t = [1.0]\n",
    "            for lag in range(1, self.lags + 1):\n",
    "                x_t.extend(var_data.iloc[t - lag].values)\n",
    "            X.append(x_t)\n",
    "        return np.array(Y), np.array(X)\n",
    "\n",
    "    def build_and_train_bvar(self, Y, X):\n",
    "        \"\"\"Build and train the BVAR model using the provided data.\"\"\"\n",
    "        n_obs, n_vars = Y.shape\n",
    "        n_params = X.shape[1]\n",
    "        with pm.Model() as self.model:\n",
    "            lambda1 = self.lambda1\n",
    "            lambda2 = self.lambda2\n",
    "            lambda3 = self.lambda3\n",
    "            coefficients, sigma_diag = [], []\n",
    "            for i in range(n_vars):\n",
    "                coef_prior_std = [1.0]\n",
    "                for lag in range(1, self.lags + 1):\n",
    "                    for j in range(n_vars):\n",
    "                        if i == j:\n",
    "                            std = lambda1 if lag == 1 else lambda1 * (lambda3 ** (lag - 1))\n",
    "                        else:\n",
    "                            std = lambda1 * lambda2 * (lambda3 ** (lag - 1))\n",
    "                        coef_prior_std.append(std)\n",
    "                beta_i = pm.Normal(f'beta_{i}', mu=0, sigma=coef_prior_std, shape=n_params)\n",
    "                coefficients.append(beta_i)\n",
    "                sigma_i = pm.HalfNormal(f'sigma_{i}', sigma=0.1)\n",
    "                sigma_diag.append(sigma_i)\n",
    "            beta_matrix = pm.math.stack(coefficients, axis=0)\n",
    "            mu = pm.math.dot(X, beta_matrix.T)\n",
    "            for i in range(n_vars):\n",
    "                pm.Normal(f'y_{i}', mu=mu[:, i], sigma=sigma_diag[i], observed=Y[:, i])\n",
    "            self.idata = pm.sample(1000, tune=500, chains=2, cores=1,\n",
    "                                   target_accept=0.85, random_seed=42, progressbar=False)\n",
    "        return self.idata\n",
    "\n",
    "    def generate_forecasts(self, forecast_years=None):\n",
    "        \"\"\"Generate forecasts using the trained BVAR model\"\"\"\n",
    "        if forecast_years is None:\n",
    "            forecast_years = list(range(2021, 2061))\n",
    "        if self.idata is None:\n",
    "            raise ValueError(\"Must train model first\")\n",
    "        print(f\"Generating BVAR forecasts for {len(forecast_years)} years...\")\n",
    "        posterior = self.idata.posterior\n",
    "        n_vars = len(self.var_names)\n",
    "        forecasts = {var: [] for var in self.var_names}\n",
    "        forecast_intervals = {var: {'lower': [], 'upper': []} for var in self.var_names}\n",
    "        \n",
    "        # Prepare the full data for getting the last observations\n",
    "        full_data = self.train_df[self.var_names].dropna()\n",
    "        current_state = full_data.iloc[-self.lags:].values\n",
    "        \n",
    "        for year_idx, year in enumerate(forecast_years):\n",
    "            forecast_dist = {var: [] for var in self.var_names}\n",
    "            for chain in range(len(posterior.chain)):\n",
    "                for draw in range(len(posterior.draw)):\n",
    "                    coeffs, sigmas = [], []\n",
    "                    for i in range(n_vars):\n",
    "                        beta_i = posterior[f'beta_{i}'].values[chain, draw]\n",
    "                        sigma_i = posterior[f'sigma_{i}'].values[chain, draw]\n",
    "                        coeffs.append(beta_i)\n",
    "                        sigmas.append(sigma_i)\n",
    "                    x_pred = [1.0]\n",
    "                    for lag in range(1, self.lags + 1):\n",
    "                        x_pred.extend(current_state[-lag])\n",
    "                    x_pred = np.array(x_pred)\n",
    "                    for i in range(n_vars):\n",
    "                        mu_pred = np.dot(x_pred, coeffs[i])\n",
    "                        y_pred = np.random.normal(mu_pred, sigmas[i])\n",
    "                        forecast_dist[self.var_names[i]].append(y_pred)\n",
    "            \n",
    "            new_obs_list = []\n",
    "            for i, var in enumerate(self.var_names):\n",
    "                point_forecast = np.median(forecast_dist[var])\n",
    "                lower_ci = np.percentile(forecast_dist[var], 2.5)\n",
    "                upper_ci = np.percentile(forecast_dist[var], 97.5)\n",
    "                forecasts[var].append(point_forecast)\n",
    "                forecast_intervals[var]['lower'].append(lower_ci)\n",
    "                forecast_intervals[var]['upper'].append(upper_ci)\n",
    "                new_obs_list.append(point_forecast)\n",
    "            \n",
    "            current_state = np.vstack([current_state, np.array(new_obs_list)])\n",
    "            if len(current_state) > self.lags:\n",
    "                current_state = current_state[-self.lags:]\n",
    "\n",
    "        last_log_price = self.train_df['Log_Real_Price'].iloc[-1]\n",
    "        price_levels, price_lower, price_upper = [], [], []\n",
    "        current_log_price = last_log_price\n",
    "        for i in range(len(forecast_years)):\n",
    "            current_log_price += forecasts['Price_Growth'][i]\n",
    "            price_levels.append(np.exp(current_log_price))\n",
    "            cumulative_growth = sum(forecasts['Price_Growth'][:i+1])\n",
    "            lower_growth = sum(forecast_intervals['Price_Growth']['lower'][:i+1])\n",
    "            upper_growth = sum(forecast_intervals['Price_Growth']['upper'][:i+1])\n",
    "            price_lower.append(np.exp(last_log_price + lower_growth))\n",
    "            price_upper.append(np.exp(last_log_price + upper_growth))\n",
    "\n",
    "        self.forecast_df = pd.DataFrame({\n",
    "            'Year': forecast_years,\n",
    "            'Forecasted_Price': price_levels,\n",
    "            'Lower_CI': price_lower,\n",
    "            'Upper_CI': price_upper,\n",
    "            'GDP_Growth_Forecast': forecasts['GDP_Growth_Rate'],\n",
    "            'Industrial_Growth_Forecast': forecasts['Industrial_Growth']\n",
    "        }).set_index('Year')\n",
    "        print(\"BVAR forecast generation completed!\")\n",
    "        return self.forecast_df\n",
    "\n",
    "    def cross_validate_hyperparameters(self, lambda1_vals, lambda2_vals, lambda3_vals):\n",
    "        \"\"\"Perform time series cross-validation to find the best hyperparameters.\"\"\"\n",
    "        print(\"Starting hyperparameter cross-validation...\")\n",
    "        \n",
    "        # Prepare the full dataset\n",
    "        df = self.prepare_data()\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Create a grid of all hyperparameter combinations\n",
    "        param_grid = list(itertools.product(lambda1_vals, lambda2_vals, lambda3_vals))\n",
    "        print(f\"Testing {len(param_grid)} hyperparameter combinations.\")\n",
    "        \n",
    "        for i, (l1, l2, l3) in enumerate(param_grid):\n",
    "            print(f\"Testing combo {i+1}/{len(param_grid)}: lambda1={l1}, lambda2={l2}, lambda3={l3}\")\n",
    "            self.lambda1, self.lambda2, self.lambda3 = l1, l2, l3\n",
    "            \n",
    "            # Use a rolling window for cross-validation\n",
    "            # We will forecast one step at a time\n",
    "            forecast_errors = []\n",
    "            \n",
    "            # Iterate through the test set\n",
    "            for year in self.test_df.index:\n",
    "                # Use data up to the year before the forecast year for training\n",
    "                train_data = df[df.index < year]\n",
    "                \n",
    "                # Prepare the training data\n",
    "                Y_train, X_train = self.prepare_bvar_data(train_data)\n",
    "                \n",
    "                # Train the model\n",
    "                self.build_and_train_bvar(Y_train, X_train)\n",
    "                \n",
    "                # Get the last observations from the training data to make a forecast\n",
    "                last_obs = train_data[self.var_names].dropna().iloc[-self.lags:].values\n",
    "                \n",
    "                # Generate a one-step-ahead forecast\n",
    "                posterior = self.idata.posterior\n",
    "                n_vars = len(self.var_names)\n",
    "                \n",
    "                forecast_dist = {var: [] for var in self.var_names}\n",
    "\n",
    "                for chain in range(len(posterior.chain)):\n",
    "                    for draw in range(len(posterior.draw)):\n",
    "                        coeffs = []\n",
    "                        for k in range(n_vars):\n",
    "                            beta_k = posterior[f'beta_{k}'].values[chain, draw]\n",
    "                            coeffs.append(beta_k)\n",
    "                        \n",
    "                        x_pred = [1.0]\n",
    "                        for lag in range(1, self.lags + 1):\n",
    "                            x_pred.extend(last_obs[-lag])\n",
    "                        \n",
    "                        x_pred = np.array(x_pred)\n",
    "                        \n",
    "                        y_preds = []\n",
    "                        for k in range(n_vars):\n",
    "                            mu_pred = np.dot(x_pred, coeffs[k])\n",
    "                            y_preds.append(mu_pred)\n",
    "                        \n",
    "                        for k, var in enumerate(self.var_names):\n",
    "                            forecast_dist[var].append(y_preds[k])\n",
    "                \n",
    "                # We are interested in the price forecast\n",
    "                price_growth_forecast = np.median(forecast_dist['Price_Growth'])\n",
    "                \n",
    "                # Get the actual price growth\n",
    "                actual_price_growth = self.test_df.loc[year, 'Price_Growth']\n",
    "                \n",
    "                # Calculate the squared error\n",
    "                forecast_errors.append((price_growth_forecast - actual_price_growth)**2)\n",
    "                \n",
    "            # Calculate the Mean Squared Error for this hyperparameter combination\n",
    "            mse = np.mean(forecast_errors)\n",
    "            results.append({\n",
    "                'lambda1': l1,\n",
    "                'lambda2': l2,\n",
    "                'lambda3': l3,\n",
    "                'mse': mse\n",
    "            })\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        best_params = results_df.loc[results_df['mse'].idxmin()]\n",
    "        \n",
    "        print(\"\\nCross-validation complete!\")\n",
    "        print(\"Best hyperparameters found:\")\n",
    "        print(best_params)\n",
    "        \n",
    "        return results_df, best_params\n",
    "\n",
    "def plot_cv_results(cv_results):\n",
    "    \"\"\"Plot the cross-validation results.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # We can plot the MSE for each combination\n",
    "    # For simplicity, we'll plot against lambda1 and use colors for lambda2\n",
    "    # This is a simplified visualization. For a more detailed one, you might need more complex plots.\n",
    "    \n",
    "    for l2 in cv_results['lambda2'].unique():\n",
    "        subset = cv_results[cv_results['lambda2'] == l2]\n",
    "        plt.plot(subset['lambda1'], subset['mse'], marker='o', linestyle='-', label=f'lambda2 = {l2}')\n",
    "        \n",
    "    plt.xlabel('Lambda 1')\n",
    "    plt.ylabel('Mean Squared Error (MSE)')\n",
    "    plt.title('Cross-Validation Results for Hyperparameter Tuning')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Perform Cross-Validation to find the best hyperparameters\n",
    "    \n",
    "    # Define the grid of hyperparameters to test\n",
    "    # You can make this grid larger for a more exhaustive search\n",
    "    lambda1_values = [0.05, 0.1, 0.2]\n",
    "    lambda2_values = [0.5, 0.7, 0.9]\n",
    "    lambda3_values = [1.0] # Often, lambda3 is kept at 1.0\n",
    "\n",
    "    # Instantiate the forecaster\n",
    "    cv_forecaster = PlatinumBVARForecast(lags=2)\n",
    "    \n",
    "    # Run the cross-validation\n",
    "    cv_results, best_hyperparams = cv_forecaster.cross_validate_hyperparameters(\n",
    "        lambda1_values, lambda2_values, lambda3_values\n",
    "    )\n",
    "\n",
    "    # Visualize the results\n",
    "    plot_cv_results(cv_results)\n",
    "\n",
    "    # 2. Run the final analysis with the best hyperparameters\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RUNNING FINAL ANALYSIS WITH BEST HYPERPARAMETERS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Instantiate a new forecaster with the best hyperparameters\n",
    "    final_forecaster = PlatinumBVARForecast(\n",
    "        lags=2,\n",
    "        lambda1=best_hyperparams['lambda1'],\n",
    "        lambda2=best_hyperparams['lambda2'],\n",
    "        lambda3=best_hyperparams['lambda3']\n",
    "    )\n",
    "    \n",
    "    # Prepare the data\n",
    "    final_forecaster.prepare_data()\n",
    "    Y_final, X_final = final_forecaster.prepare_bvar_data(final_forecaster.train_df)\n",
    "    \n",
    "    # Train the final model\n",
    "    print(\"\\nTraining final model with best hyperparameters...\")\n",
    "    final_forecaster.build_and_train_bvar(Y_final, X_final)\n",
    "    \n",
    "    # Generate and save the forecasts\n",
    "    print(\"\\nGenerating final forecasts...\")\n",
    "    final_forecaster.generate_forecasts()\n",
    "    \n",
    "    # You can add your saving functions here if you like\n",
    "    # For example:\n",
    "    # final_forecaster.save_forecast_to_csv('platinum_price_forecast_final.csv')\n",
    "    # final_forecaster.save_detailed_forecast_to_csv('platinum_detailed_forecast_final.csv')\n",
    "    \n",
    "    print(\"\\nANALYSIS COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6dff72-c12e-44ab-aa80-74e7e47025bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BVAR forecasts for 40 years...\n",
      "BVAR forecast generation completed!\n",
      "      Forecasted_Price    Lower_CI      Upper_CI  GDP_Growth_Forecast  \\\n",
      "Year                                                                    \n",
      "2021        808.518888  561.003991  1.185531e+03             2.524161   \n",
      "2022        858.291549  416.937193  1.826618e+03             2.722629   \n",
      "2023        861.884546  305.685041  2.499581e+03             2.781321   \n",
      "2024        868.470191  223.639051  3.376221e+03             2.740839   \n",
      "2025        870.236315  165.851444  4.547175e+03             2.723164   \n",
      "2026        863.746527  122.063880  6.204916e+03             2.717230   \n",
      "2027        864.156402   90.956455  8.505552e+03             2.770993   \n",
      "2028        862.203508   66.727712  1.166049e+04             2.762545   \n",
      "2029        862.570011   48.574985  1.597623e+04             2.781606   \n",
      "2030        869.349349   36.483773  2.199061e+04             2.780134   \n",
      "2031        867.768014   26.900260  2.972594e+04             2.769680   \n",
      "2032        877.007148   19.873869  4.050345e+04             2.778692   \n",
      "2033        882.007980   14.802554  5.464973e+04             2.764232   \n",
      "2034        888.835708   11.081225  7.380201e+04             2.762923   \n",
      "2035        888.383032    8.229077  9.905870e+04             2.750592   \n",
      "2036        890.500885    6.046499  1.337886e+05             2.757292   \n",
      "2037        896.359803    4.424369  1.851328e+05             2.742973   \n",
      "2038        905.863793    3.281583  2.515164e+05             2.750551   \n",
      "2039        910.319289    2.383137  3.444640e+05             2.786946   \n",
      "2040        914.492975    1.747628  4.697436e+05             2.740739   \n",
      "2041        918.195546    1.304372  6.435469e+05             2.756400   \n",
      "2042        914.196702    0.961735  8.715081e+05             2.753528   \n",
      "2043        908.744041    0.714741  1.177368e+06             2.756578   \n",
      "2044        912.070582    0.531034  1.620311e+06             2.738298   \n",
      "2045        908.795369    0.401198  2.193030e+06             2.751169   \n",
      "2046        908.157232    0.295106  2.990513e+06             2.742954   \n",
      "2047        909.706145    0.216139  4.085612e+06             2.735452   \n",
      "2048        909.305322    0.160157  5.506827e+06             2.748017   \n",
      "2049        910.909817    0.118068  7.530824e+06             2.755586   \n",
      "2050        914.343345    0.086575  1.021970e+07             2.764431   \n",
      "2051        915.815631    0.063746  1.380968e+07             2.756997   \n",
      "2052        915.020327    0.047802  1.878762e+07             2.767276   \n",
      "2053        914.130211    0.035681  2.539809e+07             2.738909   \n",
      "2054        913.108476    0.026266  3.412922e+07             2.740764   \n",
      "2055        921.038361    0.019169  4.754209e+07             2.788814   \n",
      "2056        927.455536    0.014389  6.474205e+07             2.770186   \n",
      "2057        933.511677    0.010754  8.807116e+07             2.741749   \n",
      "2058        932.660439    0.008009  1.185522e+08             2.706767   \n",
      "2059        942.421417    0.005873  1.611382e+08             2.744662   \n",
      "2060        940.802955    0.004308  2.207688e+08             2.798365   \n",
      "\n",
      "      Industrial_Growth_Forecast  \n",
      "Year                              \n",
      "2021                    0.011085  \n",
      "2022                    0.061965  \n",
      "2023                    0.007485  \n",
      "2024                    0.008760  \n",
      "2025                    0.005212  \n",
      "2026                    0.005476  \n",
      "2027                    0.006218  \n",
      "2028                    0.006578  \n",
      "2029                    0.006563  \n",
      "2030                    0.005952  \n",
      "2031                    0.005777  \n",
      "2032                    0.008191  \n",
      "2033                    0.005147  \n",
      "2034                    0.005495  \n",
      "2035                    0.007414  \n",
      "2036                    0.007551  \n",
      "2037                    0.005656  \n",
      "2038                    0.006013  \n",
      "2039                    0.006373  \n",
      "2040                    0.006728  \n",
      "2041                    0.006395  \n",
      "2042                    0.006716  \n",
      "2043                    0.004796  \n",
      "2044                    0.005581  \n",
      "2045                    0.006904  \n",
      "2046                    0.006377  \n",
      "2047                    0.006812  \n",
      "2048                    0.005668  \n",
      "2049                    0.005565  \n",
      "2050                    0.005767  \n",
      "2051                    0.005019  \n",
      "2052                    0.006223  \n",
      "2053                    0.004736  \n",
      "2054                    0.005827  \n",
      "2055                    0.006594  \n",
      "2056                    0.005113  \n",
      "2057                    0.006939  \n",
      "2058                    0.005624  \n",
      "2059                    0.007907  \n",
      "2060                    0.006552  \n"
     ]
    }
   ],
   "source": [
    "print(final_forecaster.generate_forecasts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f1730e-210c-4192-be26-a15d94112e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized Platinum BVAR Analysis ===\n",
      "\n",
      "Data prepared: 38 total observations\n",
      "VAR variables: ['Price_Growth', 'GDP_Growth_Rate', 'Industrial_Growth']\n",
      "Building and training optimized BVAR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 750 tune and 1_500 draw iterations (3_000 + 6_000 draws total) took 1005 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVAR model training completed!\n",
      "Generating optimized forecasts for 40 years...\n",
      "Training and forecasting completed!\n",
      "\n",
      "=== FORECAST SUMMARY ===\n",
      "Average price (2026-2060): $1,013,266.16\n",
      "Price range: $4,107.50 - $5,628,636.70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class OptimizedPlatinumBVARForecast:\n",
    "    def __init__(self, base_year=2017, lags=2, random_seed=42):\n",
    "        self.base_year = base_year\n",
    "        self.lags = lags\n",
    "        self.random_seed = random_seed\n",
    "        self.model = None\n",
    "        self.idata = None\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.forecast_df = None\n",
    "        self.var_names = None\n",
    "        self.posterior_samples = None  # Cache posterior samples\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare platinum price and economic indicator data\"\"\"\n",
    "        # Historical data with projections to 2025\n",
    "        data = [\n",
    "            [1988, 523, 59.5, 4.6, 85.2], [1989, 507, 62.3, 3.7, 87.1],\n",
    "            [1990, 466, 65.6, 2.9, 88.3], [1991, 372, 68.4, 1.4, 86.9],\n",
    "            [1992, 357, 70.5, 2.2, 88.7], [1993, 373, 72.3, 2.6, 90.1],\n",
    "            [1994, 405, 74.8, 3.0, 92.4], [1995, 425, 76.8, 2.7, 94.2],\n",
    "            [1996, 397, 79.0, 3.4, 95.8], [1997, 394, 80.8, 3.8, 97.1],\n",
    "            [1998, 372, 81.5, 2.7, 95.3], [1999, 377, 83.4, 3.4, 96.8],\n",
    "            [2000, 544, 86.3, 4.8, 98.2], [2001, 533, 88.1, 2.5, 97.1],\n",
    "            [2002, 540, 89.6, 3.1, 98.9], [2003, 692, 91.8, 4.0, 101.3],\n",
    "            [2004, 844, 94.7, 4.5, 104.8], [2005, 897, 97.1, 4.3, 107.2],\n",
    "            [2006, 1142, 99.8, 4.5, 110.1], [2007, 1304, 102.6, 4.4, 112.8],\n",
    "            [2008, 1578, 104.2, 1.9, 108.9], [2009, 1205, 104.5, -1.3, 101.2],\n",
    "            [2010, 1613, 106.7, 4.3, 106.8], [2011, 1722, 109.7, 3.1, 109.4],\n",
    "            [2012, 1552, 111.4, 2.6, 108.7], [2013, 1487, 112.8, 2.8, 107.3],\n",
    "            [2014, 1385, 114.1, 2.9, 105.9], [2015, 1054, 115.4, 3.2, 102.1],\n",
    "            [2016, 990, 117.1, 3.1, 101.8], [2017, 954, 119.3, 3.0, 100.0],\n",
    "            [2018, 879, 121.7, 2.9, 98.7], [2019, 863, 124.0, 2.8, 97.9],\n",
    "            [2020, 883, 126.3, -3.5, 95.4], [2021, 1077, 129.6, 5.6, 98.2],\n",
    "            [2022, 1016, 133.8, 3.1, 99.1], [2023, 1077, 136.9, 2.9, 100.3],\n",
    "            [2024, 960, 139.5, 2.8, 99.8], [2025, 1020, 142.1, 2.7, 100.5]\n",
    "        ]\n",
    "        \n",
    "        df = pd.DataFrame(data, columns=[\n",
    "            'Year', 'Nominal_Platinum_Price_USD_oz', 'US_CPI_2017_100', \n",
    "            'Global_GDP_Growth_pct', 'Industrial_Production_Index'\n",
    "        ]).set_index('Year')\n",
    "        \n",
    "        # Convert to real prices\n",
    "        df['Real_Platinum_Price'] = (df['Nominal_Platinum_Price_USD_oz'] / df['US_CPI_2017_100'] \n",
    "                                   * df.loc[self.base_year, 'US_CPI_2017_100'])\n",
    "        \n",
    "        # Log transform for stationarity\n",
    "        df['Log_Real_Price'] = np.log(df['Real_Platinum_Price'])\n",
    "        df['Log_Industrial_Production'] = np.log(df['Industrial_Production_Index'])\n",
    "        \n",
    "        # Growth rates (first differences)\n",
    "        df['Price_Growth'] = df['Log_Real_Price'].diff()\n",
    "        df['GDP_Growth_Rate'] = df['Global_GDP_Growth_pct']\n",
    "        df['Industrial_Growth'] = df['Log_Industrial_Production'].diff()\n",
    "        \n",
    "        # VAR variables\n",
    "        self.var_names = ['Price_Growth', 'GDP_Growth_Rate', 'Industrial_Growth']\n",
    "        \n",
    "        # Store full dataset\n",
    "        self.full_df = df\n",
    "        \n",
    "        print(f\"Data prepared: {len(df)} total observations\")\n",
    "        print(f\"VAR variables: {self.var_names}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_bvar_data(self, train_df):\n",
    "        \"\"\"Prepare data for BVAR estimation - optimized version\"\"\"\n",
    "        # Get clean data\n",
    "        var_data = train_df[self.var_names].dropna()\n",
    "        n_obs, n_vars = var_data.shape\n",
    "        \n",
    "        # Vectorized lag creation - more efficient\n",
    "        Y_list = []\n",
    "        X_list = []\n",
    "        \n",
    "        # Pre-allocate arrays\n",
    "        for t in range(self.lags, n_obs):\n",
    "            Y_list.append(var_data.iloc[t].values)\n",
    "            \n",
    "            # Build X row efficiently\n",
    "            x_row = [1.0]  # constant\n",
    "            for lag in range(1, self.lags + 1):\n",
    "                x_row.extend(var_data.iloc[t - lag].values)\n",
    "            X_list.append(x_row)\n",
    "        \n",
    "        Y = np.array(Y_list)\n",
    "        X = np.array(X_list)\n",
    "        \n",
    "        # Cache last observations for forecasting\n",
    "        last_obs = var_data.iloc[-self.lags:].values\n",
    "        \n",
    "        return Y, X, last_obs\n",
    "    \n",
    "    def build_minnesota_priors(self, n_vars, n_params):\n",
    "        \"\"\"Build Minnesota prior structure - improved with better hyperparameters\"\"\"\n",
    "        # Enhanced Minnesota prior parameters based on literature\n",
    "        lambda1 = 0.05  # Tighter overall shrinkage (was 0.1)\n",
    "        lambda2 = 0.3   # Stronger cross-variable shrinkage (was 0.5) \n",
    "        lambda3 = 1.2   # Slightly stronger lag decay (was 1.0)\n",
    "        \n",
    "        prior_means = []\n",
    "        prior_stds = []\n",
    "        \n",
    "        for i in range(n_vars):\n",
    "            # Priors for equation i\n",
    "            eq_means = [0.0]  # constant\n",
    "            eq_stds = [1.0]   # constant std\n",
    "            \n",
    "            # Lagged coefficients with Minnesota structure\n",
    "            for lag in range(1, self.lags + 1):\n",
    "                for j in range(n_vars):\n",
    "                    # Prior mean: unit root for own first lag, zero otherwise\n",
    "                    if i == j and lag == 1:\n",
    "                        mean = 0.9  # Near unit root for first own lag\n",
    "                    else:\n",
    "                        mean = 0.0\n",
    "                    \n",
    "                    # Prior standard deviation\n",
    "                    if i == j:  # Own variable\n",
    "                        std = lambda1 / (lag ** lambda3)\n",
    "                    else:  # Cross-variable\n",
    "                        std = lambda1 * lambda2 / (lag ** lambda3)\n",
    "                    \n",
    "                    eq_means.append(mean)\n",
    "                    eq_stds.append(std)\n",
    "            \n",
    "            prior_means.append(eq_means)\n",
    "            prior_stds.append(eq_stds)\n",
    "        \n",
    "        return prior_means, prior_stds\n",
    "    \n",
    "    def build_and_train_bvar(self, Y, X):\n",
    "        \"\"\"Build and train BVAR - optimized with better priors and sampling\"\"\"\n",
    "        print(\"Building and training optimized BVAR model...\")\n",
    "        \n",
    "        n_obs, n_vars = Y.shape\n",
    "        n_params = X.shape[1]\n",
    "        \n",
    "        # Get Minnesota priors\n",
    "        prior_means, prior_stds = self.build_minnesota_priors(n_vars, n_params)\n",
    "        \n",
    "        with pm.Model() as self.model:\n",
    "            # More efficient coefficient specification\n",
    "            coefficients = []\n",
    "            sigma_diag = []\n",
    "            \n",
    "            for i in range(n_vars):\n",
    "                # Use Minnesota prior means and stds\n",
    "                beta_i = pm.Normal(f'beta_{i}', \n",
    "                                 mu=prior_means[i], \n",
    "                                 sigma=prior_stds[i], \n",
    "                                 shape=n_params)\n",
    "                coefficients.append(beta_i)\n",
    "                \n",
    "                # Improved error variance prior\n",
    "                sigma_i = pm.HalfNormal(f'sigma_{i}', sigma=0.05)  # Tighter\n",
    "                sigma_diag.append(sigma_i)\n",
    "            \n",
    "            # Stack coefficients efficiently\n",
    "            beta_matrix = pm.math.stack(coefficients, axis=0)\n",
    "            \n",
    "            # Vectorized predictions\n",
    "            mu = pm.math.dot(X, beta_matrix.T)\n",
    "            \n",
    "            # Likelihood\n",
    "            for i in range(n_vars):\n",
    "                pm.Normal(f'y_{i}', mu=mu[:, i], sigma=sigma_diag[i], \n",
    "                         observed=Y[:, i])\n",
    "            \n",
    "            # Improved sampling with better parameters\n",
    "            self.idata = pm.sample(\n",
    "                draws=1500,      # Increased for better estimates\n",
    "                tune=750,        # Increased tuning\n",
    "                chains=4,        # More chains for better convergence\n",
    "                cores=1,\n",
    "                target_accept=0.90,  # Higher acceptance rate\n",
    "                random_seed=self.random_seed,\n",
    "                progressbar=True,\n",
    "                init='adapt_diag'  # Better initialization\n",
    "            )\n",
    "        \n",
    "        # Cache posterior samples for efficient forecasting\n",
    "        self._cache_posterior_samples()\n",
    "        \n",
    "        print(\"BVAR model training completed!\")\n",
    "        return self.idata\n",
    "    \n",
    "    def _cache_posterior_samples(self):\n",
    "        \"\"\"Cache posterior samples for efficient forecasting\"\"\"\n",
    "        posterior = self.idata.posterior\n",
    "        n_vars = len(self.var_names)\n",
    "        \n",
    "        # Flatten chains and draws for efficient sampling\n",
    "        coeffs_samples = []\n",
    "        sigma_samples = []\n",
    "        \n",
    "        for i in range(n_vars):\n",
    "            beta_samples = posterior[f'beta_{i}'].values.reshape(-1, posterior[f'beta_{i}'].shape[-1])\n",
    "            sigma_sample = posterior[f'sigma_{i}'].values.flatten()\n",
    "            \n",
    "            coeffs_samples.append(beta_samples)\n",
    "            sigma_samples.append(sigma_sample)\n",
    "        \n",
    "        self.posterior_samples = {\n",
    "            'coefficients': coeffs_samples,\n",
    "            'sigmas': sigma_samples,\n",
    "            'n_samples': len(sigma_samples[0])\n",
    "        }\n",
    "    \n",
    "    def generate_forecasts_optimized(self, forecast_years, last_obs):\n",
    "        \"\"\"Optimized forecast generation using cached samples\"\"\"\n",
    "        if self.posterior_samples is None:\n",
    "            raise ValueError(\"Must train model and cache samples first\")\n",
    "        \n",
    "        print(f\"Generating optimized forecasts for {len(forecast_years)} years...\")\n",
    "        \n",
    "        n_vars = len(self.var_names)\n",
    "        n_forecast = len(forecast_years)\n",
    "        n_samples = self.posterior_samples['n_samples']\n",
    "        \n",
    "        # Pre-allocate forecast arrays\n",
    "        forecast_samples = np.zeros((n_samples, n_forecast, n_vars))\n",
    "        \n",
    "        # Current state for each sample path\n",
    "        current_states = np.tile(last_obs, (n_samples, 1, 1))\n",
    "        \n",
    "        for t in range(n_forecast):\n",
    "            for sample_idx in range(0, n_samples, 100):  # Batch processing\n",
    "                batch_end = min(sample_idx + 100, n_samples)\n",
    "                batch_size = batch_end - sample_idx\n",
    "                \n",
    "                # Build X vectors for batch\n",
    "                X_batch = np.zeros((batch_size, self.X.shape[1]))\n",
    "                X_batch[:, 0] = 1.0  # constant\n",
    "                \n",
    "                # Fill lagged values\n",
    "                col_idx = 1\n",
    "                for lag in range(1, self.lags + 1):\n",
    "                    if lag <= current_states.shape[1]:\n",
    "                        lag_data = current_states[sample_idx:batch_end, -lag, :]\n",
    "                        X_batch[:, col_idx:col_idx + n_vars] = lag_data\n",
    "                    col_idx += n_vars\n",
    "                \n",
    "                # Generate forecasts for batch\n",
    "                for i in range(n_vars):\n",
    "                    coeffs = self.posterior_samples['coefficients'][i][sample_idx:batch_end]\n",
    "                    sigmas = self.posterior_samples['sigmas'][i][sample_idx:batch_end]\n",
    "                    \n",
    "                    # Vectorized prediction\n",
    "                    mu_pred = np.sum(X_batch * coeffs, axis=1)\n",
    "                    y_pred = np.random.normal(mu_pred, sigmas)\n",
    "                    \n",
    "                    forecast_samples[sample_idx:batch_end, t, i] = y_pred\n",
    "            \n",
    "            # Update states\n",
    "            new_obs = forecast_samples[:, t, :].reshape(n_samples, 1, n_vars)\n",
    "            current_states = np.concatenate([current_states, new_obs], axis=1)\n",
    "            if current_states.shape[1] > self.lags:\n",
    "                current_states = current_states[:, -self.lags:, :]\n",
    "        \n",
    "        # Calculate statistics efficiently\n",
    "        forecasts = {}\n",
    "        forecast_intervals = {}\n",
    "        \n",
    "        for i, var in enumerate(self.var_names):\n",
    "            var_samples = forecast_samples[:, :, i]\n",
    "            \n",
    "            forecasts[var] = np.median(var_samples, axis=0)\n",
    "            forecast_intervals[var] = {\n",
    "                'lower': np.percentile(var_samples, 2.5, axis=0),\n",
    "                'upper': np.percentile(var_samples, 97.5, axis=0)\n",
    "            }\n",
    "        \n",
    "        return forecasts, forecast_intervals\n",
    "    \n",
    "    def convert_to_price_levels(self, forecasts, forecast_intervals, forecast_years, last_log_price):\n",
    "        \"\"\"Convert price growth to price levels\"\"\"\n",
    "        price_levels = []\n",
    "        price_lower = []\n",
    "        price_upper = []\n",
    "        \n",
    "        current_log_price = last_log_price\n",
    "        for i in range(len(forecast_years)):\n",
    "            current_log_price += forecasts['Price_Growth'][i]\n",
    "            price_levels.append(np.exp(current_log_price))\n",
    "            \n",
    "            # Confidence intervals\n",
    "            cumulative_growth = np.sum(forecasts['Price_Growth'][:i+1])\n",
    "            lower_growth = np.sum(forecast_intervals['Price_Growth']['lower'][:i+1])\n",
    "            upper_growth = np.sum(forecast_intervals['Price_Growth']['upper'][:i+1])\n",
    "            \n",
    "            price_lower.append(np.exp(last_log_price + lower_growth))\n",
    "            price_upper.append(np.exp(last_log_price + upper_growth))\n",
    "        \n",
    "        return price_levels, price_lower, price_upper\n",
    "    \n",
    "    def train_and_forecast(self, train_end_year=2020, forecast_years=None):\n",
    "        \"\"\"Complete training and forecasting pipeline\"\"\"\n",
    "        if forecast_years is None:\n",
    "            forecast_years = list(range(train_end_year + 1, 2061))\n",
    "        \n",
    "        # Prepare training data\n",
    "        train_df = self.full_df[self.full_df.index <= train_end_year].copy()\n",
    "        Y, X, last_obs = self.prepare_bvar_data(train_df)\n",
    "        \n",
    "        # Store for later use\n",
    "        self.Y = Y\n",
    "        self.X = X\n",
    "        self.train_df = train_df\n",
    "        \n",
    "        # Train model\n",
    "        self.build_and_train_bvar(Y, X)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts, forecast_intervals = self.generate_forecasts_optimized(forecast_years, last_obs)\n",
    "        \n",
    "        # Convert to price levels\n",
    "        last_log_price = train_df['Log_Real_Price'].iloc[-1]\n",
    "        price_levels, price_lower, price_upper = self.convert_to_price_levels(\n",
    "            forecasts, forecast_intervals, forecast_years, last_log_price)\n",
    "        \n",
    "        # Create forecast dataframe\n",
    "        self.forecast_df = pd.DataFrame({\n",
    "            'Year': forecast_years,\n",
    "            'Forecasted_Price': price_levels,\n",
    "            'Lower_CI': price_lower,\n",
    "            'Upper_CI': price_upper,\n",
    "            'GDP_Growth_Forecast': forecasts['GDP_Growth_Rate'],\n",
    "            'Industrial_Growth_Forecast': forecasts['Industrial_Growth']\n",
    "        }).set_index('Year')\n",
    "        \n",
    "        print(\"Training and forecasting completed!\")\n",
    "        return self.forecast_df\n",
    "    \n",
    "    def run_analysis(self):\n",
    "        \"\"\"Run complete optimized analysis\"\"\"\n",
    "        print(\"=== Optimized Platinum BVAR Analysis ===\\n\")\n",
    "        \n",
    "        # Prepare data\n",
    "        self.prepare_data()\n",
    "        \n",
    "        # Train and forecast\n",
    "        forecast_df = self.train_and_forecast()\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n=== FORECAST SUMMARY ===\")\n",
    "        future_forecast = forecast_df.loc[2026:2060]\n",
    "        print(f\"Average price (2026-2060): ${future_forecast['Forecasted_Price'].mean():,.2f}\")\n",
    "        print(f\"Price range: ${future_forecast['Forecasted_Price'].min():,.2f} - ${future_forecast['Forecasted_Price'].max():,.2f}\")\n",
    "        \n",
    "        return forecast_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    forecaster = OptimizedPlatinumBVARForecast(lags=2)\n",
    "    results = forecaster.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a2c981-ae84-46ad-bb2b-1413a11b09a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Forecasted_Price      Lower_CI      Upper_CI  GDP_Growth_Forecast  \\\n",
      "Year                                                                      \n",
      "2021      9.465832e+02  6.608357e+02  1.345520e+03            -2.284587   \n",
      "2022      1.177366e+03  4.872775e+02  2.770975e+03            -1.279571   \n",
      "2023      1.554853e+03  3.409960e+02  6.813427e+03            -0.499580   \n",
      "2024      2.119045e+03  2.335769e+02  1.931860e+04             0.084503   \n",
      "2025      2.938190e+03  1.533050e+02  6.109761e+04             0.518433   \n",
      "2026      4.107497e+03  9.885055e+01  2.018296e+05             0.872605   \n",
      "2027      5.711998e+03  6.235015e+01  6.966925e+05             1.131611   \n",
      "2028      7.883691e+03  3.870451e+01  2.553222e+06             1.353327   \n",
      "2029      1.072470e+04  2.326509e+01  9.854880e+06             1.488595   \n",
      "2030      1.437398e+04  1.367239e+01  3.935220e+07             1.639562   \n",
      "2031      1.905937e+04  8.026754e+00  1.558002e+08             1.732506   \n",
      "2032      2.505866e+04  4.722728e+00  6.340769e+08             1.792752   \n",
      "2033      3.248852e+04  2.783688e+00  2.576278e+09             1.858474   \n",
      "2034      4.183871e+04  1.609054e+00  1.030434e+10             1.913638   \n",
      "2035      5.314142e+04  9.135461e-01  4.180257e+10             1.939435   \n",
      "2036      6.698639e+04  5.106929e-01  1.626747e+11             1.941490   \n",
      "2037      8.322502e+04  2.868894e-01  6.585434e+11             1.961458   \n",
      "2038      1.034686e+05  1.594733e-01  2.641928e+12             1.989275   \n",
      "2039      1.271336e+05  8.771911e-02  1.065872e+13             2.005670   \n",
      "2040      1.559062e+05  4.745216e-02  4.317397e+13             2.013983   \n",
      "2041      1.909650e+05  2.553065e-02  1.771101e+14             2.018862   \n",
      "2042      2.303155e+05  1.379500e-02  7.113251e+14             2.015680   \n",
      "2043      2.786365e+05  7.434605e-03  2.927549e+15             2.022934   \n",
      "2044      3.349806e+05  3.921387e-03  1.187081e+16             2.057410   \n",
      "2045      4.005819e+05  2.063789e-03  4.732303e+16             2.049257   \n",
      "2046      4.842031e+05  1.086932e-03  1.879094e+17             2.055119   \n",
      "2047      5.827319e+05  5.513386e-04  7.703470e+17             2.052436   \n",
      "2048      6.976415e+05  2.848978e-04  3.266875e+18             2.052913   \n",
      "2049      8.408102e+05  1.437567e-04  1.320074e+19             2.075083   \n",
      "2050      1.009062e+06  7.345882e-05  5.482291e+19             2.063988   \n",
      "2051      1.206938e+06  3.717114e-05  2.204580e+20             2.069498   \n",
      "2052      1.438267e+06  1.872284e-05  8.892389e+20             2.055122   \n",
      "2053      1.703494e+06  9.368242e-06  3.618885e+21             2.038022   \n",
      "2054      2.034776e+06  4.776553e-06  1.476977e+22             2.044824   \n",
      "2055      2.434913e+06  2.412262e-06  6.095544e+22             2.042966   \n",
      "2056      2.908148e+06  1.238732e-06  2.464480e+23             2.063734   \n",
      "2057      3.445614e+06  6.152649e-07  1.008086e+24             2.067893   \n",
      "2058      4.068331e+06  3.016202e-07  4.154828e+24             2.078231   \n",
      "2059      4.794162e+06  1.503628e-07  1.700002e+25             2.066690   \n",
      "2060      5.628637e+06  7.724996e-08  6.987182e+25             2.087484   \n",
      "\n",
      "      Industrial_Growth_Forecast  \n",
      "Year                              \n",
      "2021                    0.082488  \n",
      "2022                    0.165259  \n",
      "2023                    0.221795  \n",
      "2024                    0.255870  \n",
      "2025                    0.274798  \n",
      "2026                    0.286055  \n",
      "2027                    0.289327  \n",
      "2028                    0.287979  \n",
      "2029                    0.281444  \n",
      "2030                    0.275786  \n",
      "2031                    0.266036  \n",
      "2032                    0.256987  \n",
      "2033                    0.249233  \n",
      "2034                    0.238138  \n",
      "2035                    0.229872  \n",
      "2036                    0.221241  \n",
      "2037                    0.213345  \n",
      "2038                    0.206240  \n",
      "2039                    0.202690  \n",
      "2040                    0.192565  \n",
      "2041                    0.187126  \n",
      "2042                    0.184612  \n",
      "2043                    0.178297  \n",
      "2044                    0.175210  \n",
      "2045                    0.173390  \n",
      "2046                    0.169742  \n",
      "2047                    0.168272  \n",
      "2048                    0.166167  \n",
      "2049                    0.163543  \n",
      "2050                    0.160656  \n",
      "2051                    0.157855  \n",
      "2052                    0.157770  \n",
      "2053                    0.155464  \n",
      "2054                    0.153277  \n",
      "2055                    0.151150  \n",
      "2056                    0.151155  \n",
      "2057                    0.150693  \n",
      "2058                    0.148969  \n",
      "2059                    0.147260  \n",
      "2060                    0.146764  \n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77518654-babe-448f-9b64-55d1c1f7f836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized Platinum BVAR Analysis ===\n",
      "\n",
      "Data prepared: 38 total observations\n",
      "VAR variables: ['Price_Growth', 'GDP_Growth_Rate', 'Industrial_Growth']\n",
      "Building and training optimized BVAR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "NUTS: [beta_0, sigma_0, beta_1, sigma_1, beta_2, sigma_2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 750 tune and 1_500 draw iterations (3_000 + 6_000 draws total) took 960 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVAR model training completed!\n",
      "Generating optimized forecasts for 40 years...\n",
      "Training and forecasting completed!\n",
      "\n",
      "=== FORECAST SUMMARY ===\n",
      "Average price (2026-2060): $1,043,147.33\n",
      "Price range: $4,038.14 - $5,826,135.06\n",
      "=== BVAR MODEL CROSS-VALIDATION ===\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 402\u001b[39m\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cv, results\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# Example usage (uncomment when you have your BVAR forecaster ready):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m results_s = \u001b[43mrun_bvar_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 397\u001b[39m, in \u001b[36mrun_bvar_cross_validation\u001b[39m\u001b[34m(BVARForecaster)\u001b[39m\n\u001b[32m    390\u001b[39m cv = BVARCrossValidation(\n\u001b[32m    391\u001b[39m     forecaster_class=BVARForecaster,\n\u001b[32m    392\u001b[39m     train_ratio=\u001b[32m0.7\u001b[39m,\n\u001b[32m    393\u001b[39m     random_seed=\u001b[32m42\u001b[39m\n\u001b[32m    394\u001b[39m )\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# Run complete cross-validation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m results = \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv, results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 219\u001b[39m, in \u001b[36mBVARCrossValidation.run_cross_validation\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== BVAR MODEL CROSS-VALIDATION ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Initialize forecaster and prepare data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m forecaster = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforecaster_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m full_data = forecaster.prepare_data()\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Time series split (70% train, 30% test)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import seaborn as sns\n",
    "from typing import Dict, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BVARCrossValidation:\n",
    "    def __init__(self, forecaster_class, train_ratio=0.7, random_seed=42):\n",
    "        \"\"\"\n",
    "        Cross-validation framework for BVAR models\n",
    "        \n",
    "        Parameters:\n",
    "        - forecaster_class: The BVAR forecaster class\n",
    "        - train_ratio: Proportion of data for training (default 0.7)\n",
    "        - random_seed: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.forecaster_class = forecaster_class\n",
    "        self.train_ratio = train_ratio\n",
    "        self.random_seed = random_seed\n",
    "        self.results = {}\n",
    "        \n",
    "    def time_series_split(self, data, train_ratio=0.7):\n",
    "        \"\"\"\n",
    "        Time series split maintaining temporal order\n",
    "        \"\"\"\n",
    "        n_obs = len(data)\n",
    "        split_point = int(n_obs * train_ratio)\n",
    "        \n",
    "        train_data = data.iloc[:split_point]\n",
    "        test_data = data.iloc[split_point:]\n",
    "        \n",
    "        return train_data, test_data\n",
    "    \n",
    "    def calculate_mape(self, actual, predicted):\n",
    "        \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n",
    "        return mean_absolute_percentage_error(actual, predicted) * 100\n",
    "    \n",
    "    def calculate_tracking_signal(self, actual, predicted):\n",
    "        \"\"\"\n",
    "        Calculate Tracking Signal\n",
    "        TS = Running Sum of Forecast Errors / Mean Absolute Deviation\n",
    "        \"\"\"\n",
    "        errors = actual - predicted\n",
    "        running_sum_errors = np.cumsum(errors)\n",
    "        mad = np.mean(np.abs(errors))\n",
    "        \n",
    "        if mad == 0:\n",
    "            return np.zeros_like(errors)\n",
    "        \n",
    "        tracking_signal = running_sum_errors / mad\n",
    "        return tracking_signal\n",
    "    \n",
    "    def acf_residuals(self, residuals, lags=20):\n",
    "        \"\"\"Calculate ACF for residuals\"\"\"\n",
    "        acf_values = acf(residuals, nlags=lags, fft=True)\n",
    "        return acf_values\n",
    "    \n",
    "    def ljung_box_test(self, residuals, lags=10):\n",
    "        \"\"\"\n",
    "        Ljung-Box (Portmanteau) test for autocorrelation in residuals\n",
    "        H0: Residuals are independently distributed (no autocorrelation)\n",
    "        \"\"\"\n",
    "        result = acorr_ljungbox(residuals, lags=lags, return_df=True)\n",
    "        return result\n",
    "    \n",
    "    def residual_diagnostics(self, residuals, title_prefix=\"\"):\n",
    "        \"\"\"Comprehensive residual analysis\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle(f'{title_prefix} Residual Diagnostics', fontsize=16)\n",
    "        \n",
    "        # 1. Residual plot\n",
    "        axes[0, 0].plot(residuals, 'b-', alpha=0.7)\n",
    "        axes[0, 0].axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "        axes[0, 0].set_title('Residuals Over Time')\n",
    "        axes[0, 0].set_xlabel('Time')\n",
    "        axes[0, 0].set_ylabel('Residuals')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Histogram of residuals\n",
    "        axes[0, 1].hist(residuals, bins=20, density=True, alpha=0.7, color='skyblue')\n",
    "        \n",
    "        # Overlay normal distribution\n",
    "        mu, sigma = stats.norm.fit(residuals)\n",
    "        x = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "        axes[0, 1].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal fit')\n",
    "        axes[0, 1].set_title('Residual Distribution')\n",
    "        axes[0, 1].set_xlabel('Residuals')\n",
    "        axes[0, 1].set_ylabel('Density')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Q-Q plot\n",
    "        stats.probplot(residuals, dist=\"norm\", plot=axes[0, 2])\n",
    "        axes[0, 2].set_title('Q-Q Plot (Normal)')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. ACF of residuals\n",
    "        acf_vals = self.acf_residuals(residuals, lags=20)\n",
    "        lags_range = range(len(acf_vals))\n",
    "        axes[1, 0].bar(lags_range, acf_vals, alpha=0.7, color='green')\n",
    "        axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        # Confidence bounds for ACF\n",
    "        n = len(residuals)\n",
    "        axes[1, 0].axhline(y=1.96/np.sqrt(n), color='red', linestyle='--', alpha=0.7, label='95% CI')\n",
    "        axes[1, 0].axhline(y=-1.96/np.sqrt(n), color='red', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        axes[1, 0].set_title('ACF of Residuals')\n",
    "        axes[1, 0].set_xlabel('Lag')\n",
    "        axes[1, 0].set_ylabel('ACF')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Residuals vs Fitted\n",
    "        fitted_values = np.arange(len(residuals))  # Proxy for fitted values\n",
    "        axes[1, 1].scatter(fitted_values, residuals, alpha=0.6, color='purple')\n",
    "        axes[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "        axes[1, 1].set_title('Residuals vs Time Index')\n",
    "        axes[1, 1].set_xlabel('Time Index')\n",
    "        axes[1, 1].set_ylabel('Residuals')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Rolling statistics\n",
    "        window = min(10, len(residuals)//4)\n",
    "        if window > 2:\n",
    "            rolling_mean = pd.Series(residuals).rolling(window=window).mean()\n",
    "            rolling_std = pd.Series(residuals).rolling(window=window).std()\n",
    "            \n",
    "            axes[1, 2].plot(rolling_mean, label='Rolling Mean', color='blue', linewidth=2)\n",
    "            axes[1, 2].plot(rolling_std, label='Rolling Std', color='red', linewidth=2)\n",
    "            axes[1, 2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "            axes[1, 2].set_title('Rolling Statistics')\n",
    "            axes[1, 2].set_xlabel('Time')\n",
    "            axes[1, 2].set_ylabel('Value')\n",
    "            axes[1, 2].legend()\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 2].text(0.5, 0.5, 'Insufficient data\\nfor rolling statistics', \n",
    "                           ha='center', va='center', transform=axes[1, 2].transAxes)\n",
    "            axes[1, 2].set_title('Rolling Statistics')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistical tests\n",
    "        print(f\"\\n=== {title_prefix} RESIDUAL DIAGNOSTIC TESTS ===\")\n",
    "        \n",
    "        # Normality test\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "        print(f\"Shapiro-Wilk Normality Test:\")\n",
    "        print(f\"  Statistic: {shapiro_stat:.4f}, p-value: {shapiro_p:.4f}\")\n",
    "        print(f\"  {' Residuals appear normal' if shapiro_p > 0.05 else ' Residuals may not be normal'}\")\n",
    "        \n",
    "        # Ljung-Box test\n",
    "        ljung_result = self.ljung_box_test(residuals, lags=min(10, len(residuals)//4))\n",
    "        print(f\"\\nLjung-Box Test (Portmanteau Test):\")\n",
    "        significant_lags = ljung_result[ljung_result['lb_pvalue'] < 0.05]\n",
    "        if len(significant_lags) == 0:\n",
    "            print(\"   No significant autocorrelation detected\")\n",
    "        else:\n",
    "            print(f\"   Significant autocorrelation detected at {len(significant_lags)} lag(s)\")\n",
    "        \n",
    "        print(f\"  Summary: {ljung_result['lb_pvalue'].iloc[-1]:.4f} (p-value for lag {len(ljung_result)})\")\n",
    "        \n",
    "        return {\n",
    "            'shapiro_stat': shapiro_stat,\n",
    "            'shapiro_p': shapiro_p,\n",
    "            'ljung_box': ljung_result,\n",
    "            'acf_values': acf_vals\n",
    "        }\n",
    "    \n",
    "    def tracking_signal_analysis(self, tracking_signal):\n",
    "        \"\"\"\n",
    "        Analyze tracking signal for bias detection\n",
    "        Tracking signal should typically be between -4 and +4\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== TRACKING SIGNAL ANALYSIS ===\")\n",
    "        print(f\"Final Tracking Signal: {tracking_signal[-1]:.2f}\")\n",
    "        print(f\"Max Tracking Signal: {np.max(tracking_signal):.2f}\")\n",
    "        print(f\"Min Tracking Signal: {np.min(tracking_signal):.2f}\")\n",
    "        \n",
    "        # Check for bias\n",
    "        if np.abs(tracking_signal[-1]) > 4:\n",
    "            print(\"   WARNING: Tracking signal indicates potential forecast bias\")\n",
    "        else:\n",
    "            print(\"   Tracking signal within acceptable range\")\n",
    "        \n",
    "        # Plot tracking signal\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(tracking_signal, 'b-', linewidth=2, label='Tracking Signal')\n",
    "        plt.axhline(y=4, color='r', linestyle='--', alpha=0.7, label='Upper Control Limit (+4)')\n",
    "        plt.axhline(y=-4, color='r', linestyle='--', alpha=0.7, label='Lower Control Limit (-4)')\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        plt.title('Tracking Signal Over Time')\n",
    "        plt.xlabel('Time Period')\n",
    "        plt.ylabel('Tracking Signal')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'final_ts': tracking_signal[-1],\n",
    "            'max_ts': np.max(tracking_signal),\n",
    "            'min_ts': np.min(tracking_signal),\n",
    "            'bias_detected': np.abs(tracking_signal[-1]) > 4\n",
    "        }\n",
    "    \n",
    "    def run_cross_validation(self):\n",
    "        \"\"\"Run complete cross-validation analysis\"\"\"\n",
    "        print(\"=== BVAR MODEL CROSS-VALIDATION ===\\n\")\n",
    "        \n",
    "        # Initialize forecaster and prepare data\n",
    "        forecaster = self.forecaster_class(random_seed=self.random_seed)\n",
    "        full_data = forecaster.prepare_data()\n",
    "        \n",
    "        # Time series split (70% train, 30% test)\n",
    "        train_data, test_data = self.time_series_split(full_data, self.train_ratio)\n",
    "        \n",
    "        print(f\"Training period: {train_data.index[0]}-{train_data.index[-1]} ({len(train_data)} obs)\")\n",
    "        print(f\"Testing period: {test_data.index[0]}-{test_data.index[-1]} ({len(test_data)} obs)\")\n",
    "        \n",
    "        # Train model on training data\n",
    "        train_end_year = train_data.index[-1]\n",
    "        test_years = test_data.index.tolist()\n",
    "        \n",
    "        print(f\"\\nTraining BVAR model up to {train_end_year}...\")\n",
    "        forecast_df = forecaster.train_and_forecast(train_end_year, test_years)\n",
    "        \n",
    "        # Extract overlapping years for evaluation\n",
    "        eval_years = test_data.index.intersection(forecast_df.index)\n",
    "        if len(eval_years) == 0:\n",
    "            raise ValueError(\"No overlapping years between test data and forecasts\")\n",
    "        \n",
    "        # Get actual and predicted values\n",
    "        actual_prices = test_data.loc[eval_years, 'Real_Platinum_Price'].values\n",
    "        predicted_prices = forecast_df.loc[eval_years, 'Forecasted_Price'].values\n",
    "        \n",
    "        # Calculate residuals\n",
    "        residuals = actual_prices - predicted_prices\n",
    "        \n",
    "        # Performance metrics\n",
    "        print(f\"\\n=== CROSS-VALIDATION RESULTS ({eval_years[0]}-{eval_years[-1]}) ===\")\n",
    "        \n",
    "        # MAPE\n",
    "        mape = self.calculate_mape(actual_prices, predicted_prices)\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        # Other metrics\n",
    "        rmse = np.sqrt(np.mean(residuals**2))\n",
    "        mae = np.mean(np.abs(residuals))\n",
    "        mean_bias = np.mean(residuals)\n",
    "        \n",
    "        print(f\"RMSE: ${rmse:,.2f}\")\n",
    "        print(f\"MAE: ${mae:,.2f}\")\n",
    "        print(f\"Mean Bias: ${mean_bias:,.2f}\")\n",
    "        \n",
    "        # Tracking Signal\n",
    "        tracking_signal = self.calculate_tracking_signal(actual_prices, predicted_prices)\n",
    "        ts_results = self.tracking_signal_analysis(tracking_signal)\n",
    "        \n",
    "        # Residual diagnostics\n",
    "        diagnostic_results = self.residual_diagnostics(residuals, \"BVAR Model\")\n",
    "        \n",
    "        # Create forecast vs actual plot\n",
    "        self.plot_forecast_vs_actual(eval_years, actual_prices, predicted_prices)\n",
    "        \n",
    "        # Store results\n",
    "        self.results = {\n",
    "            'eval_period': (eval_years[0], eval_years[-1]),\n",
    "            'n_test_obs': len(eval_years),\n",
    "            'mape': mape,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'mean_bias': mean_bias,\n",
    "            'tracking_signal': ts_results,\n",
    "            'residual_diagnostics': diagnostic_results,\n",
    "            'actual_prices': actual_prices,\n",
    "            'predicted_prices': predicted_prices,\n",
    "            'residuals': residuals\n",
    "        }\n",
    "        \n",
    "        # Final summary\n",
    "        self.print_summary()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def plot_forecast_vs_actual(self, years, actual, predicted):\n",
    "        \"\"\"Plot actual vs predicted values\"\"\"\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(years, actual, 'bo-', label='Actual', linewidth=2, markersize=6)\n",
    "        plt.plot(years, predicted, 'ro-', label='Predicted', linewidth=2, markersize=6)\n",
    "        plt.title('BVAR Model: Actual vs Predicted Platinum Prices')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Real Platinum Price ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Residuals plot\n",
    "        plt.subplot(2, 1, 2)\n",
    "        residuals = actual - predicted\n",
    "        plt.plot(years, residuals, 'go-', linewidth=2, markersize=6, label='Residuals')\n",
    "        plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "        plt.title('Forecast Residuals')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Residual ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print comprehensive summary of cross-validation results\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"BVAR MODEL CROSS-VALIDATION SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results = self.results\n",
    "        \n",
    "        print(f\"Evaluation Period: {results['eval_period'][0]} - {results['eval_period'][1]}\")\n",
    "        print(f\"Number of Test Observations: {results['n_test_obs']}\")\n",
    "        print(f\"\\nFORECAST ACCURACY METRICS:\")\n",
    "        print(f\"   MAPE: {results['mape']:.2f}%\")\n",
    "        print(f\"   RMSE: ${results['rmse']:,.2f}\")\n",
    "        print(f\"   MAE: ${results['mae']:,.2f}\")\n",
    "        print(f\"   Mean Bias: ${results['mean_bias']:,.2f}\")\n",
    "        \n",
    "        print(f\"\\nTRACKING SIGNAL:\")\n",
    "        ts = results['tracking_signal']\n",
    "        print(f\"   Final Value: {ts['final_ts']:.2f}\")\n",
    "        print(f\"   Range: [{ts['min_ts']:.2f}, {ts['max_ts']:.2f}]\")\n",
    "        print(f\"   Bias Detected: {'Yes' if ts['bias_detected'] else 'No'}\")\n",
    "        \n",
    "        print(f\"\\nRESIDUAL DIAGNOSTICS:\")\n",
    "        rd = results['residual_diagnostics']\n",
    "        print(f\"   Normality (Shapiro-Wilk): p = {rd['shapiro_p']:.4f}\")\n",
    "        print(f\"   Autocorrelation (Ljung-Box): p = {rd['ljung_box']['lb_pvalue'].iloc[-1]:.4f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        print(f\"\\nMODEL VALIDITY ASSESSMENT:\")\n",
    "        \n",
    "        # MAPE interpretation\n",
    "        if results['mape'] < 10:\n",
    "            mape_rating = \"Excellent\"\n",
    "        elif results['mape'] < 20:\n",
    "            mape_rating = \"Good\"\n",
    "        elif results['mape'] < 50:\n",
    "            mape_rating = \"Acceptable\"\n",
    "        else:\n",
    "            mape_rating = \"Poor\"\n",
    "        print(f\"   Forecast Accuracy: {mape_rating} (MAPE = {results['mape']:.2f}%)\")\n",
    "        \n",
    "        # Bias assessment\n",
    "        bias_ok = not ts['bias_detected']\n",
    "        print(f\"   Forecast Bias: {' No significant bias' if bias_ok else ' Potential bias detected'}\")\n",
    "        \n",
    "        # Normality assessment\n",
    "        normal_ok = rd['shapiro_p'] > 0.05\n",
    "        print(f\"   Residual Normality: {' Normal' if normal_ok else ' Non-normal'}\")\n",
    "        \n",
    "        # Autocorrelation assessment\n",
    "        autocorr_ok = rd['ljung_box']['lb_pvalue'].iloc[-1] > 0.05\n",
    "        print(f\"   Residual Independence: {' Independent' if autocorr_ok else ' Autocorrelated'}\")\n",
    "        \n",
    "        # Overall assessment\n",
    "        checks_passed = sum([mape_rating in ['Excellent', 'Good'], bias_ok, normal_ok, autocorr_ok])\n",
    "        overall_rating = ['Poor', 'Fair', 'Good', 'Excellent'][checks_passed]\n",
    "        print(f\"\\nOVERALL MODEL RATING: {overall_rating} ({checks_passed}/4 checks passed)\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "# Usage example and integration with existing BVAR forecaster\n",
    "def run_bvar_cross_validation(BVARForecaster):\n",
    "    \"\"\"\n",
    "    Run cross-validation for BVAR model\n",
    "    \n",
    "    Parameters:\n",
    "    - BVARForecaster: Your BVAR forecaster class\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize cross-validation framework\n",
    "    cv = BVARCrossValidation(\n",
    "        forecaster_class=BVARForecaster,\n",
    "        train_ratio=0.7,\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    # Run complete cross-validation\n",
    "    results = cv.run_cross_validation()\n",
    "    \n",
    "    return cv, results\n",
    "\n",
    "# Example usage (uncomment when you have your BVAR forecaster ready):\n",
    "results_s = run_bvar_cross_validation(forecaster.run_analysis())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
